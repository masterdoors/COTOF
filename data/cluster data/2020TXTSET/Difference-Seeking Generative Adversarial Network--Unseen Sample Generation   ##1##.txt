Unseen data, which are not samples from the distribution of training data and are difficult to collect, have exhibited importance in numerous applications, ({em e.g.,} novelty detection, semi-supervised learning, and adversarial training). In this paper, we introduce a general framework called 	extbf{d}ifference-	extbf{s}eeking 	extbf{g}enerative 	extbf{a}dversarial 	extbf{n}etwork (DSGAN), to generate various types of unseen data. Its novelty is the consideration of the probability density of the unseen data distribution as the difference between two distributions and whose samples are relatively easy to collect. The DSGAN can learn the target distribution, , (or the unseen data distribution) from only the samples from the two distributions, and . In our scenario, is the distribution of the seen data, and can be obtained from via simple operations, so that we only need the samples of during the training. Two key applications, semi-supervised learning and novelty detection, are taken as case studies to illustrate that the DSGAN enables the production of various unseen data. We also provide theoretical analyses about the convergence of the DSGAN. generative adversarial network, semi-supervised learning, novelty detection