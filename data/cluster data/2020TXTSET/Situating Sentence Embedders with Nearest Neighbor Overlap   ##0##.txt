As distributed approaches to natural language semantics have developed and diversified, embedders for linguistic units larger than words (e.g., sentences) have come to play an increasingly important role. To date, such embedders have been evaluated using benchmark tasks (e.g., GLUE) and linguistic probes. We propose a comparative approach, nearest neighbor overlap (N2O), that quantifies similarity between embedders in a task-agnostic manner. N2O requires only a collection of examples and is simple to understand  two embedders are more similar if, for the same set of inputs, there is greater overlap between the inputs  nearest neighbors. We use N2O to compare 21 sentence embedders and show the effects of different design choices and architectures. sentence embeddings, nearest neighbors, semantic similarity