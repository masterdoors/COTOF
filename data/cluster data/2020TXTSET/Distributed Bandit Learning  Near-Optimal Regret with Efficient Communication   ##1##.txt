We study the problem of regret minimization for distributed bandits learning, in which agents work collaboratively to minimize their total regret under the coordination of a central server. Our goal is to design communication protocols with near-optimal regret and little communication cost, which is measured by the total amount of transmitted data. For distributed multi-armed bandits, we propose a protocol with near-optimal regret and only communication cost, where is the number of arms. The communication cost is independent of the time horizon , has only logarithmic dependence on the number of arms, and matches the lower bound except for a logarithmic factor. For distributed -dimensional linear bandits, we propose a protocol that achieves near-optimal regret and has communication cost of order , which has only logarithmic dependence on . Theory, Bandit Algorithms, Communication Efficiency