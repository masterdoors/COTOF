text	label
however this would need to be resolved in order to have a meaningful comparison to the epsilondelta values reported in related work.	0
the authors state that their current algorithm is too slow to be useful for larger models such as vgg19, but they do briefly report some results obtained for this model (but do not compare to related work).	0
overall, it is a nice extension of reed & de freitas, but i'm a bit surprised by the lack of discussion about the rest of the literature (beside reed & de freitas, most previous work are only lightly discussed in the related work).	0
cons: as the paper well recounts in the related work section, libraries of fixed policies have long been formally proposed for reuse while learning similar tasks.	0
theorem 2: 'a nash equilibrium ... exists' ' sec 3: should be 'several papers were presented' overall, i have some concerns with the related work and experimental evaluation sections, but i feel the model is novel enough and is welljustified by the optimality proofs and the quality of the generated samples.	0
on the downside, experimental evaluation does not allow for confident conclusions, and a recent closely related work by zhu et al. [1] is not discussed in enough detail.	0
my main concern are experiments  it would be nice to see a comparison to some of the neural networks mentioned in related work.	0
there has been lots of interests in similar area recently, authors do cite some of them in introduction and related work but the relationship and comparison are missing.	0
the related work section, although appearing systematic and thorough, is a little detached from the main body of the paper (related work section should not be a survey of the literature, but help readers locate your work in the relevant literature, and highlight the pros and cons.	0
9th), there are two strong weaknesses remaining: analysis of related work, and experimental evidence.	0
to the approach and results, the approach lacks novelty and the results are not convincing over related work and ablations.	0
pros: ' clear description ' well built experiments ' simple yet effective idea ' no overclaiming ' detailed comparison with related work architectures cons: ' idea somewhat incremental (e.g. can be seen as derivative from bell 2016) ' results are good, but do not improve over state of the art quality: the ideas are sound, experiments well built and analysed.	2
they conclude that the proposed approach is superior, but this seems unjustified as the cnns used to generate the features by the authors is different from the one used in related work.	0
the related work section, although appearing systematic and thorough, is a little detached from the main body of the paper (related work section should not be a survey of the literature, but help readers locate your work in the relevant literature, and highlight the pros and cons.	0
3) the answer to the prereview questions made the architecture details of the paper much more clear, but i still ask the authors to include the exact architecture details of all the experiments in the paper and/or open source the code.	0
3) suggestions for improvement static dataset bias: in response to the prereview concerns about the observed static nature of the qualitative results, the authors added a simple baseline consisting in copying the pixels of the last observed frame.	0
another possible concern, as pointed out by reviewer 3, is that the description of the model is extremely concise.	0
[1] https://github.com/bvlc/caffe/blob/master/examples/pycaffe/caffenet.py#l24 [2] https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/nets/alexnet.py#l92 ===================== update: the authors have revised their paper to address the concerns that i considered grounds for rejection in my review.	0
if i understand section 2.3 correctly, it's mostly a review of black box alpha divergence minimization.	0
my concerns about the paper more or less mirror my prereview questions.	0
2017/1/20: in light of my concerns being addressed i'm modifying my review to a 7, with the understanding that the manuscript will be amended to include the new comparisons posted as a comment.	0
__note__: an earlier version of the review (almost identical to the present one) for an earlier version of the paper (available on arxiv) can be found here: http://www.shortscience.org/paper?bibtexkey=journals/corr/1611.01838#csaba the only change concerns relation to previous work.	0
i do however agree with other reviewers that the tasks are very simple.	0
this review is only an informed guess  unfortunately i cannot assess the paper due to my lack of understanding of the paper.	0
a sentence from the paper 'but it has left us unsatisfied since we have not gained the insight needed to choose between them.” summarises my feeling about this paper: this is a nice 'unifying review’ type paper that  for me  lacks a novel insight.	0
this was asked in a prereview question but the answer did not fully clarify it for me.	0
my policy for interactive review is to keep an open mind and willingness to change my score, but a large revision is unlikely.	0
the authors point to a previous workshop submission (https://arxiv.org/abs/1604.02606) but the authors need more discussion about what this method entails and how it compares to other retraining methods (e.g. [1,2]) since this is the first peerreview of this work.	0
a comparison with a similar model, but with bagofwords reviews model would be nice in order to show the importance of the rnnbased review model, especially given previous literature.	0
unfortunately, even after reading the authors' response to my prereview question, i feel this paper in its current form lacks sufficient novelty to be accepted to iclr.	0
my primary concern is the one i expressed in my prereview question below, which i don't think the authors addressed.	0
see my concern above and in the prereview question below.	0
at present, i rate this paper as a borderline contribution but i'm open to revising my review pending further modifications.	0
the authors give a brief but sufficient review of the fundamentals of compressed sensing, present their main result relating feedforward networks and iht (a surprising result), and progress naturally to a detailed experimental section.	0
to make this apparent, i here summarise each paragraph of the conclusion section: paragraph 1: we do not benchmark / pruning methods do not fare well against bruteforce baseline / some evidence for hypothesis of mozer & smolensky, but further investigation needed paragraph 2: introduced 2nd order taylor method / does not fare well against baseline paragraph 3: retraining may help but is not fair paragraph 4: bruteforce can prune 4070% in shallow networks paragraph 5: bruteforce less effective in deep networks paragraph 6: not all neurons contribute equally to performance of network the title of the paper and answers of the authors to the prereview questions seemed to strongly suggest that the paper is not about the new secondorder method, is not about benchmarking pruning algorithms but is instead about the learnt representations.	0
3 paper is unfriendly to colorblind readers (or those with b/w printers) overall, this paper is a reasonable review of where we are in terms of sota vision architectures, but doesn't provide much new insight.	0
in the optimisation setting we are told that the functional form of the landscape function is part of a (in answer to the question of a reviewer) but what is part of the functional form ?	0
i was holding off on this review hoping to get the missing details from the code at https://github.com/alexnowakvilla/dp, but at this time it's still missing.	0
my prereview question articulated this same concern and has not been answered.	0
after the prereview comments, authors do mention that they compared against expected sarsa but i would really like to see these and other extensive baselines before accepting this paper.	0
the authors state in a prereview answer that they amended with some more results, but i can't see a revision in openreview (please let me know if i've missed it).	0
the paper lists some simple embeddings such as svd based ones, cca etc. but a more thorough review of other approaches including the vast array of nonlinear dimensionality reduction solutions should be mentioned.	0
also, eve only tries to estimate c, thus rendering the scenario not different in any way to the scenario considered in section 2. i have two more minor concerns: 1) as raised in the prereview, eve should actually be stronger then alice and bob in order to be able to compensate for the missing key.	0
the authors also only cite/compare to a basic rnn architecture, however there has been many contributions since a basic rnn architecture that performs vastly better.	0
there has been lots of interests in similar area recently, authors do cite some of them in introduction and related work but the relationship and comparison are missing.	0
the idea of an attention policy that takes advantage of expert knowledge is a nice contribution, but perhaps if limited novelty  for example the maddison and tarlow 2014 paper, which the authors cite, has scoping rules that track previously used identifiers in scope.	0
i have however, some concerns about the paper: 1) the paper fails to cite and discuss relevant literature and claims to be the first one that is able to learn interpretable parts.	0
you cite deepface and bell et al. 2015 but you don't compare on those benchmarks.	0
there are already more than four papers reporting better numbers than the one reported in this task, however the author did not cite them.	0
however, the novelty is relatively incremental given previous cited work on multistream networks, and it is not clear that this particular decoupling works well or is of broader interest beyond the specific task of future frame prediction.	0
one way to speed up mmd is to use a random fourier basis as was done in “fastmmd: ensemble of circular discrepancy for efficient twosample test” by zhao and meng, 2015. there are also linear time estimators, e.g., in “a kernel twosample test“ by gretton et al., 2012. i don’t think you need to compare against these approaches since you compare to the full mmd, but they should be cited.	0
comparison to literature is severely lacking; eg 'several automated structure learning techniques have been proposed' followed by 6 citations but no discussion of any of them, which one is most related, which ideas carry over from the offline setting to this online setting, etc. also since this work presents both joint structure & 'parameter' learning, comparison to the online parameter learning papers (3 cited) would be appreciated, specifically since these prior approaches seem to be more principled with bayesian moment matching in jaini 2016 for example.	0
first this paper has the style very similar to the sugiyama et al. papers that are cited (e.g. presenting in different perspectives that were all covered in those papers but in a different context), making me unsure about how to evaluate the novelty.	0
would be nice if the authors not only cited the previous work but summarized the actual differences.	0
3. not comparing to stateoftheart: the stateoftheart however is not the basic phog cited here, but “probabilistic model for code with decision trees”, (oopsla 2016) which appeared before the submission deadline for iclr’17: http://dl.acm.org/citation.cfm?id=2984041 on the same dataset, oopsla’16 has accuracy of 83.9%, and on the more difficult task than considered here (see above point).	0
although the paper establishes interesting measurement points and therefore it has the potential for being cited as a reference, its relative lack of originality decreases its significance.	0
“the underlying easiness of optimizing deep networks does not simply rest just in the emerging structures due to high dimensional spaces, but is rather tightly connected to the intrinsic characteristics of the data these models are run on.” i believe this perspective is already contained in several of the works cited as not belonging to this perspective.	0
this is partially true, but it neglects important parts of the discussion conducted in the cited papers.	0
pros  the paper is clearly written and easy to follow cons  the paper's two contributions are too minor to merit publication  experimental results should include at least the caltech pedestrian dataset but likely also the kitti pedestrian dataset  recent work from eccv 2016 [a], with superior results and much more experimental evaluation, is not cited or discussed my rating is due primarily to the lack luster contributions.	2
also, author claims stateofart on enwik8, but hypernetwork, already cited in the paper, achieves better results (1.34 bpc, table 4 in the hypernetworks paper).	0
in addition, the citation list is rather thin, for example reward shaping has a rich literature, as do incrementally more difficult task setups, dating back at least to mark ring’s work in the 1990s.	0
the authors keep referring to 'previously popular attention paradigms' without any citation and then, i believe, incorrectly describe whatever those are supposed to be by writing that these unknown but popular approaches 'summarize each modality into a single vector.'	0
3. not comparing to stateoftheart: the stateoftheart however is not the basic phog cited here, but “probabilistic model for code with decision trees”, (oopsla 2016) which appeared before the submission deadline for iclr’17: http://dl.acm.org/citation.cfm?id=2984041 on the same dataset, oopsla’16 has accuracy of 83.9%, and on the more difficult task than considered here (see above point).	0
the authors use the pass score through the paper, but only given an intuition  citation for it.	0
equation 4 is presented as a new invention, but this has been used in previous works and is well known in mathematics, so a citation should be added.	0
the paper is ambitious and claims to address a variety of problems, but as a result each segment of related work seems to have been shortchanged.	0
a weakness of this section however is that it makes no reference to related work whatsoever.	0
pros:  novel/original proposal justified both theoretically and empirically  well written, easy to follow  limited evaluation on a classification and regression task is suggestive of the proposed approach's potential  efficient implementation cons:  related work, in particular the first paragraph, should compare and contrast with the closest extant work rather than merely list them  evaluation is limited; granted this is the nature of the target domain presentation: while the paper is generally written well, the paper appears to conflate the definition of the convolutional and correlation operators?	2
while the idea is interesting, the paper felt quite verbose on introducing notations and related work, and a bit lacking on actual change that is being proposed and the experiment to back it up.	0
al.: image pivoting for learning multilingual multimodal representations, emnlp 2017 for a good set of references) 3) this omission of related work also weakens the experimental section.	0
in addition to giving the full paper a purge of unnecessary sentences, my recommendation would be to shorten section 1.1 to a couple of paragraphs (moving some material to the results section if necessary), reduce the bayesopt related work paragraph to a sentence or a most two, cut the lstm related work paragraph (i find the link strenuous at best but that might be my misunderstanding), and cut the intro the bayesopt and gps down to a short paragraph (just give the key highlevel idea then reference to existing work).	0
concerning the related work, the authors didn't mention the universal value function approximation (schaul et al, @icml 2015) which precisely extends v and q functions to generalize over goals.	0
for instance, borsa et al 2017 doesn't do inverse rl (as said in the related work section) but learn to perform a task only from the extrinsic reward provided by the environment (as said in the introduction).	0
2. complete lack of details for related work.	0
another concern is the novelty in relation to related work.	0
pros  the intuition is good that connects differential equation and resnetlike architecture, also explored in some of the related work.	0
strengths:  reasonable approach, quality is good  the dsl is richer than that of previous related work like balog et al. (2016).	2
the paper is easy to read and well organized  the advantage of the proposed regularization against the more standard l2 regularization is clearly visible from the experiments  the idea per se is not new: there is a list of shallow learning methods for transfer learning based on the same l2 regularization choice [crossdomain video concept detection using adaptive svms, acm multimedia 2007] [learning categories from few examples with multi model knowledge transfer, pami 2014] [from n to n 1: multiclass transfer incremental learning, cvpr 2013] i believe this literature should be discussed in the related work section  it is true that the l2spfisher regularization was designed for lifelong learning cases with a fixed task, however, this solution seems to work quite well in the proposed experimental settings.	0
the authors mention deep generative models and oneshot learning methods as related work but the way this section is constructed makes it hard for the reader to see the relation.	0
in total, the model seems clean and somewhat novel, but it has only been tested on unrealistic synthetic data, the framing with respect to related work is poor, and the contributions are overstated.	0
the related work discusses skip connections in the context of convolutional nets, but doesn’t mention previous works incorporating skip connections into rnn architectures, such as [1], [2], or [3].	0
overall, the combination of recurrent skip connections and attention appears to be novel, but experimental comparisons to other skip connection rnn architectures are missing and thus it is not clear how this work is positioned relative to previous related work.	0
the most serious problems are the extensive discussion of the fully unsupervised variant (rather than the semisupervised variant that is evaluated), poor use of examples when describing the model, nonstandard terminology (“concepts” and “context” are extremely vague terms that are not defined precisely) and discussions to vaguely related work that does not clarify but rather obscures what is going on in the paper.	0
"however the paper's list of related work on that toopic is a bit lacking as in section 3.1 it omits referencing the ""explaining and harnessing..."" paper by goodfellow et al., which presented the first convincing attempt at explaining crossmodel generalization of the examples."	0
"pros:  interesting tasks that combine imitation and reinforcement in a logical (but somewhat heuristic) way  good simulated results on a variety of pickandplace style problems  some initial attempt at realworld transfer that seems promising, but limited  related work is very detailed and i think many will find it to be a very valuable overview cons:  some of the claims (detailed below) are a bit excessive in my opinion  the paper would be better if it was scoped more narrowly  contribution is a bit incremental and somewhat heuristic  the experimental results are difficult to interpret in simulation  the realworld experimental results are not great  there are a couple of missing citations (but overall related work is great) detailed discussion of potential issues and constructive feedback: > ""our approach leverages demonstration data to assist a reinforcement learning agent in learning to solve a wide range of tasks, mainly previously unsolved."""	2
"to be an extensive discussion of ""text"", i would expect to see languagemodeling and seqtoseq tasks as well  the majority of the manuscript is taken up by overly long explanations of background concepts (e.g. half a page on risk minimization, half a page on ""different kinds of neural networks"" with vague and occasionally misleading descriptions of rnn vs cnn, containing zero citations)  the related work is significantly lacking, and it appears that the authors are unaware of results and published work which would be directly relevant to theirs (e.g. arpit et al. a closer look at memorization in deep networks ; advani and saxe generalization error dynamics in high dimensions)  in the introduction, generalization is not clearly explained, which seems kind of like an important thing to do...  vc is a measure/set, not a norm?"	0
comments:  the related work section is comprehensive but a bit unstructured, with each new paragraph seemingly describing a completely different type of work.	0
however, the current paper has some correctness issues, is missing some related work and lacks a clear statement of innovation.	0
the authors argue for the focus on stability over convergence, which is an interesting focus, but still i found the lack of connection with related work in this section a strange.	0
the related work section includes a number of relevant works, but should clearly explain the difference between the prior methods and the proposed method.	0
we are thus expecting related work post 2012 but it's not what is reviewed.	0
pros methodology 1. inductive ability: can generalize to unseen nodes without any further training 2. personalized ranking: the model uses natural ranking that embeddings of closer nodes (considers node pairs of any distance) should be closer in the embedding space, which is more general than prevailing first and second order proximity 3. sampling strategy: the proposed nodeanchored sampling method gives unbiased estimates of loss function and successfully reduces the time complexity experiment 1. evaluation tasks including link prediction and node classification are conducted across multiple datasets with additional parameter sensitivity and missinglink robustness experiments 2. compared with various baselines with diverse model designs such as gcn and node2vec as well as compared with naive baseline (using original node attributes as model inputs) 3. demonstrated the model captures uncertainties and the learned uncertainties can be used to infer latent dimensions related works the survey of related work is sufficiently wide and complete.	0
cons:  related work is not adequately referenced.	0
finally, the authors have admirably attempted a thorough comparison with existing work, in the related work section, but this section takes up a large chunk of the paper at the end, and again i would have preferred this section to be much shorter and more concise.	0
3) in contrast to the thin experiments and (lack of) technical novelty, the introduction & related work writeups are overdrawn and uninteresting.	0
3) treatment of related work is lacking.	0
my main concern is that while imitation learning and inverse reinforcement learning are mentioned and discussed in related work section as classes of algorithms for incorporating prior information there is no baseline experiment using either of these methods.	0
etc.  your related work section is lacking.	0
the authors mention that related work is generalized but fail to differentiate their work relative to even the cited references (kim & lane, 2016; hori et al., 2017).	0
evaluation pros: i like how this paper formalizes failure in representation learning as information loss in zalthough the formulation is not particularly novel, i.e. [zhao et al., arxiv 2017]), and constructs an explicit, penalized objective to allow the user to specify the amount of information retained in z. in my opinion, the proposed objective is more transparent than the objectives proposed by related work.	2
however, the related work discussion is significantly lacking.	0
weaknesses ========== the similarity and differences between the proposed method and related work is not made clear.	0
the related work section lacks important references.	0
cons: this is mostly an application of an existing method to a new domain  as stated in the related work section, effectively the same convnetrnn architecture has been in common use for image captioning and other vision applications.	0
pros  best description of mmd gans that i have encountered  good contextualization of related work and descriptions of relationships, at least among the works surveyed  reasonable proposed metric (kid) and comparison with other scores  proof of unbiased gradient estimates is a solid contribution cons  although the review of related work is very good, it does focus on ~3 recent papers.	2
pros  ' strong related work section that contextualizes this paper among current work ' very interesting idea to more efficiently find and train best architectures ' excellent and thought provoking discussions of middle steps and mediocre results on some experiments (i.e. last paragraph of section 4.1, and last paragraph of section 4.2) ' publicly available code cons  ' some very strong experimental results contrasted with some mediocre results ' the balance of the paper seems off, using more text on experiments than the contributions to theory. '	2
overall the paper is wellstructured and related work covers the relevant papers, but the details of the paper seem hastily written.	0
(p.2)  the related work section is wellwritten and interesting, but it's a bit odd to have it at the end.	0
"smaller ambiguities in wording are also in the paper : e.g. related work > long term prediction ""in this work"" refers to the work mentioned but could as well be the work that they are presenting."	0
cons and mainly questions: 1. missing related work.	2
one important contribution of the paper is about optimal batch sizes, but related work in this direction is not discussed.	0
there are many related works concerning adaptive batch sizes, such as [1] (a summary in section 3.2 of [2]).	0
the paper is quite poorly written in places, has poor formatting (citations are incorrect and half a bibtex entry is inlined), and is highly inadequate in its treatment of related work.	0
the authors do a good job of positioning their study with respect to related work on blackbox adversarial techniques, but overall, by working on the topic of noisy input data at all, they are guaranteed novelty.	0
pros: simple idea with impact; the problem being tackled is a difficult one cons: not many; real systems have constraints between physical dimensions and the forces/torques they can exert some additional related work to consider citing.	2
i also have a few other concerns: 1. there seems to be a related work: [1] perellonieto et al., background check: a general technique to build more reliable and versatile classifiers, icdm 2016, where authors constructed a classifier, which output k1 labels and the k1th label is the “background noise” label for this classification problem.	0
section 2 lacks discussions about related work but is more dedicated to emphasizing the contribution of the paper.	0
in other words, the evaluation is a bit lazy somewhat in the same sense as the writing and treatment of related work; the authors implemented the model and ran it on a collection of public data sets, but did not venture further into scientific reporting of the merits and limitations of the approach.	0
for me, it is not easy to judge the novelty of the approach, but the authors list related works, none of which seems to solve the same task.	0
more precisely, focusing on the comparison to rainbow which is the main competitor here, my concerns are the following:  there is almost no discussion on the differences between reactor and rainbow (actually the paper lacks a « related work » section).	0
in terms of clarity, the paper is overall easy to follow, however i am a bit confused by section 2 about what is related work and what is a novel contribution, although the section is called “our contribution”.	0
command of related work is ok, but some relevant refs are missing (e.g., kloft and laskov, jmlr 2012).	0
some related works are mentioned in the paper, but those are spread in different sections.	0
(the authors can even show the validation adversarial accuracy to show how/if it deviates from the test accuracy) lack of related work in nlp (see the anonymous comment for some examples).	0
since the authors have mentioned in the related work, it would also be more convincing if they show experimental results on cl conclusion:  i feel that the motivation is good, but the proposed model is too handcrafted.	0
"() pros / cons:  simple yet powerful method for text classification  strong experimental results  ablation study / analysis of influence of parameters  writing of the paper  missing discussion to the ""attention is all you need paper"", which seems highly relevant () typos: page 1 ""a support vectors machines"" > ""a support vector machine"" ""performs good"" > ""performs well"" ""the ngrams was widely"" > ""ngrams were widely"" ""to apply large region size"" > ""to apply to large region size"" ""are trained separately"" > ""do not share parameters"" page 2 ""convolutional neural networks(cnn)"" > ""convolutional neural networks (cnn)"" ""related works"" > ""related work"" ""effective in wang and manning"" > ""effective by wang and manning"" ""applied on text classification"" > ""applied to text classification"" ""shard(word independent)"" > ""shard (word independent)"" page 3 ""can be treat"" > ""can be treated"" ""fixed length continues subsequence"" > ""fixed length contiguous subsequence"" ""w_i stands for the"" > ""w_i standing for the"" ""which both the unit"" > ""where both the unit"" ""in vocabulary"" > ""in the vocabulary"" etc..."	0
with sufficient knowledge of related works from these areas, i find that the authors' proposed method lacks proper evaluation and sufficient novelty.	0
pros methodology 1. inductive ability: can generalize to unseen nodes without any further training 2. personalized ranking: the model uses natural ranking that embeddings of closer nodes (considers node pairs of any distance) should be closer in the embedding space, which is more general than prevailing first and second order proximity 3. sampling strategy: the proposed nodeanchored sampling method gives unbiased estimates of loss function and successfully reduces the time complexity experiment 1. evaluation tasks including link prediction and node classification are conducted across multiple datasets with additional parameter sensitivity and missinglink robustness experiments 2. compared with various baselines with diverse model designs such as gcn and node2vec as well as compared with naive baseline (using original node attributes as model inputs) 3. demonstrated the model captures uncertainties and the learned uncertainties can be used to infer latent dimensions related works the survey of related work is sufficiently wide and complete.	0
this paper is outside of my area of expertise, so i'll just provide a light review:  the idea of assuming that the opponent will take the worst possible action is reasonable in widely used in classic search, so making value functions follow this intuition seems sensible,  but somehow i wonder if this is really novel?	0
for now, i think the submission is good for a weak accept – if the authors address my concerns, and/or correct my potential misunderstanding of the issues, i'd be happy to upgrade my review to an accept.	0
"also, the paper never considers concatenations of large pretrained embedding sets with each other and/or with the new domain corpus  such concatenations often give a big boost to accuracy, see : ""think globally, embed locally—locally linear metaembedding of words"", bollegala et al., 2017 https://arxiv.org/pdf/1709.06671.pdf that paper is not peer reviewed to my knowledge so it is not necessary to compare against the new methods introduced there, but their baselines of concatenation of pretrained embedding sets should be compared against in the submission."	0
pros: i) detailed review of the existing work and comparison with the proposed work.	2
review: while the idea proposed in the paper is somewhat novel and there is nothing obviously wrong about the proposed approach, i thought the paper is somewhat incremental.	0
pnl ica is solvable and there are a number of algorithms proposed for it, some cited already in the above review, but also more recent ones.	0
i think there are many areas of further discussion that the authors can flesh out (as mentioned below and in other reviews), but overall the contribution seems solid.	0
i understand that sometimes it's tempting to minimize one's weaknesses in order to get a paper accepted because the reviewers may not understand the area very well and may get hung up on the wrong things.	0
pros:  good literature review.	2
i would encourage the authors to address the concerns raised on my review.	0
however, i hope that you address some of the concerns i have raised in this review.	0
i still think the novelty, significance of the claims and protocol are still perhaps borderline for publication (though i'm leaning towards acceptance), but i don't have a really high amount of experience in the field of adversarial examples in order to make my review with high confidence.	0
concerning the presentation, the paper dedicates two full pages on a review of the algorithm by yin et al. (2017).	0
the second page of the review seems to discuss the main part of the algorithm, but i could not follow it.	0
concerning the presentation, the paper dedicates two full pages on a review of the algorithm by yin et al. (2017).	0
the second page of the review seems to discuss the main part of the algorithm, but i could not follow it.	0
for example, there are several papers that frame the code migration problem as one of statistical machine translation (see sec 4.4 of [1] for a review and citations), but this paper makes no reference to them.	0
i do not have background in h_inf control theory, but i will review the paper to the best of my ability.	0
general review:  when only the first layer is free between generators, i think it is not suitable to talk about multiple generators, but rather it is just a multimodal prior on the z, in this case z is a mixture of gaussians with learned covariances (the weights of the first layer).	0
(emergency review—i have no special knowledge of the subfield, and i was told a cursory review was ok, but the paper was fascinating and i ended up reading fairly carefully) this paper does many things.	0
however i am willing to adjust my review according to author response and the evaluation of the experiment section by other reviewers (who are hopefully more experienced in this domain).	0
however, i have significant concerns regarding how the paper is written and final section of the proposed algorithm/experiments etc. introduction/literature review> i think paper significantly lacks literature review and locating itself where the proposed approach at the end stands in the given recent sr literature (particularly deep learning based methods) similarities to other techniques, differences from other techniques etc. there have been several different ways of using cnns for super resolution, how does this paper’s architecture differs from those?	0
update: i'm going to change my review to a 6 to acknowledge the substantial improvements you've made—i no longer fear that there are major errors in the paper, but this paper is still solidly borderline, and i'm not completely convinced that any new claim is true.	0
though the paper presents an interesting approach, but it relies heavily on heuristics (such as those mentioned in the initial review) without a thorough investigation of scenarios in which this might not work.	0
pros:   novel use of hypernetworks  promising results  good literature review cons:   far too much focus on gaussian noise  unconvincing argument/ lacking discussion  lack of clarity	2
"my original review had rating ""4: ok but not good enough  rejection""."	0
i have read the responses to the concerns raised by all reviewers.	0
"it is even not clear to me if the algorithm can be run asynchronously (as some of the other reviewers seem to imply) or if its a synchronous algorithm but analyzed asynchronously to accomodate for delay in the information coming from their ""continuouspropagation"" factorization? '"	0
as mentioned in the other reviews, key references are lacking, e.g., for ode interpretation, eq. (3) and (4).	0
pros  best description of mmd gans that i have encountered  good contextualization of related work and descriptions of relationships, at least among the works surveyed  reasonable proposed metric (kid) and comparison with other scores  proof of unbiased gradient estimates is a solid contribution cons  although the review of related work is very good, it does focus on ~3 recent papers.	2
as a review, it would be nice to see mention (even just in a list with citations) of how other models in the zoo fit in  connection between ipms and mmd gets a bit lost; a figure (e.g. flow chart) would help  wavers a bit between proposing/proving novel things vs. reviewing and lacks some overall structure/storyline  figure 1 is a bit confusing; why is kid tested without replacement, and fid with?	0
i have listed this review as a good for publication due to the novelty of ideas presented, but the accusation of misrepresentation below is a serious one and i would like to know the author's response.	0
i was not able to review all the proofs, but what i checked was sound.	0
if convenient, could the authors comment on a similarly motivated paper under review at iclr 2018: variancebased gradient compression for efficient distributed deep learning pros:  good use of intuition to guide algorithm choices  good compression with little loss of accuracy on best strategy  good problem for fa algorithm / well motivated  cons:  some experiment choices do not appear well motivated / inclusion is not best choice  explanations of algos / lack of 'algorithms' adds to confusion a useful reference: strom, nikko.	2
in this perspective, the proposed framework might be useful, but as noted in the original review, the presentation is not clear, and it's not convincing to me that the mi framework is indeed useful in the sense i described above.	0
the authors try to claim some novelty in that they apply this wellknown observation to pixellevel prediction networks, but the reviewer fails to see what in this application was nontrivial or surprising.	0
pros: (1) the paper is well written, the review of distillation and quantization is clear.	2
the mandatory literature review on the abundant recent uses of memory in neural networks is then followed by experiments on continual learning tasks involving permuted mnist tasks, imagenet incremental inclusion of classes, imagenet unbalanced, and two language modeling tasks.	0
original review ============= summary: the contribution of this paper is a method for training deep networks such that skip connections are present at initialization, but gradually removed during training, resulting in a final network without any skip connections.	0
summary of review: this is an incremental change of an existing method.	0
# summary of review i find the contribution to be incremental, and the validation weak.	0
the authors could have benefited from the feedback they obtained from the reviewers of their last submissions to improved their paper, but nothing has been done.	0
3. it lacks a necessary review of related works.	0
i have not verified the proofs in this paper (given short notice to review) but the scaling laws in the upper bounds found seem reasonably correct.	0
another reviewer's worry about why depth plays a role in the convergence of empirical to true values in deep linear networks is a reasonable worry, but i suspect that depth will necessarily play a role even in deep linear nets because the backpropagation of gradients in linear nets can still lead to exponential propagation of errors between empirical and true quantities due to finite training data.	0
al. iclr 2014 which could be cited to address that reviewer's concern.	0
i added a comment in light of the authors' response, but don't see it and so i am updating my review for completeness).	0
"added: 20news results still poor for hpd, but its probably the implementation used ... their online variational algorithm only has advantages for large data sets pros: ' interesting new prod model with good results ' alternative ""deep"" approach to a hdllda model ' good(ish) experimental work cons: ' could do with a competitive nonparametric lda implementation added: good review responses generally"	2
in nips, 2017. revised review: given the authors' thorough answers to my concerns, i have decided to change my score.	0
extensive experimentation on established toy datasets (usps<>mnist, svhn<>mnist, svhn, gtsrb) and other more realworld datasets (including the visda one) cons: ' literature review on domain adaptation was lacking.	0
this is all nice, interesting, and well written, but at the end of the day, the paper is not doing too much beyond being a nice review of all ideas.	0
i am unsure whether i should take it into account in this review, but in doubt i am choosing to, which is why i am advocating for acceptance in spite of the abovementioned concerns.	0
overall, strong application work, which i appreciate, but with several flaws that i'd like the authors to address, if possible, during the review period.	0
as strong points, the paper is easy to follow and does a good review of existing methods.	2
the research questions seems straightforward, but it is good to see those experiments review some interesting points.	0
review updates: rating 6 > 7 confidence 2 > 4 the rebuttal and update addressed a number of my concerns, cleared up confusing sections, and moved the paper materially closer to being publicationworthy, thus i’ve increased my score.	0
however, a few parts were poorly explained, which led to this reviewer being unable to follow some of the jumps from experimental results to their conclusions.	0
arxiv preprint arxiv:1610.06447. review update after reply: the authors have responded to most of my concerns and i think the paper is much stronger now and discuss the relation with regularized ot.	0
however, i think there are several main drawbacks, detailed as follows: 1. the paper lacks a coherent and complete review of the semisupervised deep learning.	0
the research itself seems fine, but there are some issues with the discussion of previous work.	0
the proposed idea is not exceptional original, but the paper has several strong points: ' the relation to previous work is made explicit and it is show that several previous approaches are generalized by the proposed one. '	2
cons:  overall, the approach seems to be an incremental improvement over the previous work resnext.	0
overall, the relative lack of novelty and comparison with previous work make me hesitant to recommend the acceptance of this paper.	0
the analysis in section 3 is decent (see however the minor comments below), but does not offer revolutionary new insights  it's perhaps more like a corollary of previous work (pascanu et al., 2013).	0
additionally, the functional form chosen for f() in the objective was chosen to match previous work but with no explanation as to why that's a reasonable form to choose.	0
it has a similar flavor as deepfusion (df), a previous work which also integrated an lm to a asr in a similar way, but where the fusion is also trained.	0
"(ii) the authors do not seem to address one of the main criticisms they make about previous work and in particular ""[a lack of evidence] of such specific 2d connectivity patterns""."	0
weaknesses:  there are now several papers on using a trained neural network to guide search, and this approach doesn't add too much on top of previous work.	0
especially since there is even previous work on using saliency methods to detect adversarial examples (e.g. fong et al, interpretable explanations of black boxes by meaningful perturbation, iccv 2017).	0
pros: 1. extend the input from disentangled feature to raw image pixels 2. employ “obverter” technique, showing that it can be an alternative approach comparing to rl 3. the authors provided various experiments to showcase their approach cons: 1. comparing to previous work (mordatch & abbeel, 2018), the task is relatively simple, only requiring the agent to perform binary prediction.	2
however, while the proposed ideas are interesting, there are concerns about the novelty in relation to a long line of previous work.	0
some previous work is cited, but i would point the authors to much older work of parr and russell on hams (hierarchies of abstract machines) and later work by andre and russell, which did something very similar (though, indeed, not in hybrid domains).	0
some previous work is cited, but i would point the authors to much older work of parr and russell on hams (hierarchies of abstract machines) and later work by andre and russell, which did something very similar (though, indeed, not in hybrid domains).	0
these are all novel contributions, but each one seems incremental in the context of previous work on this and similar algorithms (e.g. nokland, direct feedback alignment provides learning in deep neural networks, 2016; baldi et al, learning in the machine: the symmetries of the deep learning channel, 2017).	0
however, the work lacks justification for this particular way of encoding, and no comparison for any other encoding mechanism is provided except for the onehot encoding used in zhang & lecun 2015. the results using this particular encoding are not better than any previous work.	0
the idea of avoiding mode collapse by providing multiple samples to the discriminator is not new; the paper acknowledges prior work on minibatch discrimination but does not really describe the differences with previous work in any technical detail.	0
however, the main concerns are:  limited technical contribution: multimodal approaches to image geolocation were already proposed in previous work.	0
pros:  improvement of the modelfree method from previous work by incorporating information about previously observed states, demonstrating the importance of memory.	2
"(2) a similar concern about the baselines: the paper did not compare with any previous work on speeding up rnns, e.g. ""training rnns as fast as cnns""."	0
i would be slightly surprised if no previous work has used external resources for training word representations using an endtask loss, but i don’t know the area well enough to make specific suggestions  i’m a little skeptical about how often this method would really be useful in practice.	0
as with the earlier papers in this recent program, the paper is notationheavy but generally written well, though there is some overreliance on the readers' knowledge of previous work, for instance in presenting the evidence as above.	0
weaknesses  improvement in accuracy is small relative to previous work.	0
"the faces experiment is similar to previous work done by martin (2011) and kontsevich (2004) but unlike that previous work does not investgiate whether classification features have been identified that can be added to an arbitrary image to change the attribute ""happy vs sad"" or ""male vs female""."	0
in the previous work, the two agents share a set of initial conditions (the set of objects to be divided; this is required by the nature of the task: negotiation), but the goals of each agent are hidden and the negotiation process and outcome are only revealed through natural language.	0
for the most part it draws from a previous work which is my main concern.	0
pros:  well written and easy to read paper  interesting theoretical guarantees of the approximation cons:  a bit incremental  weak empirical evaluations  no support for the claim of efficient gpu implementation == incremental == while the theoretical justification of the methods are interesting, these are not a contribution of the paper (but of previous work by mussmann et al.).	2
other previous works have also proposed to use lsh to speed up computations in neural network, but are not discussed in the paper (see list of references).	0
1. the authors claimed that this is the first endtoend trainable hierarchical attention model, but there is a previous work that also addressed the similar task: seo et al, progressive attention networks for visual attribute prediction, in arxiv preprint:1606.02393, 2016 2. the proposed attention mechanism seems to be fairly domain (or task ) specific, and may not be beneficial for strong generalization (generalization over unseen category).	0
i'm glad you refer to former work (there is a very annoying tendency those days to refer only to very recent papers from a small set of people who do not correctly refer themselves to previous work), but you may nevertheless refer to john schulman's paper about gaes anyways... ;) appendix e.1 could be reorganized, with a common hat and then e.1.1 for one layer model(s?)	0
finally, the most striking flaw of this paper is the lack of references to previous works on word embeddings and feature representation, i would suggest the author check and compare themselves with previous work on this topic.	0
with an appropriate fix, lemma 4 gives a cleaner set of assumptions than previous work in the same space (nguyen  hein ’17), but yields essentially the same conclusions.	0
the experiments show clearly that a) the components of the proposed pipeline are important since they outperform ablated versions of it and b) the system is better than previous work in those tasks negative aspects: my main criticism to the paper is that the task learning achieved through self exploration seems relatively shallow.	0
"this is interesting (and novel compared to the ""order matters"" paper) but corresponds to known findings from most previous work on semisupervised learning: pretraining is only useful when only a very small supervised data exists, and quickly becomes irrelevant."	0
weaknesses:  a deeper analysis of previous work on the combination of image and text for sentiment analysis (both datasets and methods) and its relation with the presented work is necessary.	0
the paper addresses important shortcomings exhibited by previous work (sabour et al.), introducing a series of valuable technical novelties.	0
one that could be improved is p(p_x, p_g) where one loses the fact that the second random variable is y. this work contains plenty of novel material, which is clearly compared to previous work:  the main consequence of the use of wasserstein distance is the surprisingly simple and useful theorem 1. i could not verify its novelty, but this seems to be a great contribution.	0
however the results only show that the algorithm converges, in some cases, faster than the previous work reaching asymptotically to a same or worse performance.	0
given the chosen tasks, this work should be compared to the beermind system: http://deepx.ucsd.edu/#/home/beermind and the associated publication http://arxiv.org/pdf/1511.03683.pdf but the authors should also refer to previous work on their topic: https://arxiv.org/pdf/1107.1322 the above mentioned reference is really close to their work.	0
neuroimage 87 (2014): 96110. references ———— ledoit wolf regularization is used but not cited.	0
he is cited later, but in a misleading way.	0
"moreover, there are many papers known as ""learning with abstention"" and/or ""learning with rejection"" from nips, icml, colt, etc. (some are coauthored by dr. peter bartlett or dr. corinna cortes), but the current paper didn't cite those that are particularly designed to let the classifier be able to say 'i don't know'."	0
you cite nocedal & wright, but could you please provide a page number (or at least a chapter)?	0
(it is obviously good to cite results from prior work, but then it would be more clear if the results are invoked as is without modifications.)	0
originality: the idea of using a pointwise mutual information tensor for word embeddings is not new, but the authors fairly cite all the relevant literature.	0
not critical, but either cite one the original papers or maybe remove the cite altogether p4 par2: has multiple interests...: interests > purposes?	0
the authors cite (chapelle et al., 2000) and actually most of the equations are taken from there, but the authors do not justify why the proposed distribution is a good approximation for the true p(x, y).	0
the authors cite recent work by devries & taylor (2017) and pereyra et al. (2017), but the technique of combining multiple samples for data augmentation have been a popular approach.	0
please cite some work in that case) (3) to summarize points (1) and (2), block diagonal architectures are a nice alternative to pruned architectures, with similar accuracy, and more benefit to speed (mainly speed at runtime, or speed of a single iteration, not necessarily speed to train) [as i am not primarly a neural net researcher, i had always thought pruning was done to decrease overfitting, not to increase computation speed, so this was a surprise to me; also note that the sparse matrix format can increase runtime if implemented as a sparse object, as demonstrated in this paper, but one could always pretend it is sparse, so you never ought to be slower with a sparse matrix] (4) there is some vague connection to random matrices, with some limited experiments that are consistent with this observation but far from establish it, and without any theoretical analysis (martingale or markov chain theory) this is an experimental/methods paper that proposes a new algorithm, explained only in general details, and backs up it up with two reasonable experiments (that do a good job of convincing me of point (1) above).	0
cons:  using different embedding for computing attention weights and getting attended vector is not entirely novel but rather an expected practice for many memorybased models, and should cite relevant papers.	0
> we can, during training, exploit privileged information about the true system state >> this was done also in pinto et al. and many of the cited gps papers > our policies solve the tasks that the stateoftheart reinforcement and imitation learning cannot solve >> i don't think this statement is justified without much wider comparisons  the authors don't attempt any comparisons to prior work, such as chebotar '17 (which arguably is closest in terms of demonstrated behaviors), nair '17 (which is also close but doesn't use images, though it likely could).	0
please fix .cite calls to .citep, when authors name is not used as part of the sentence, for example: graph neural network nowak et al. (2017) should be graph neural network (nowak et al. (2017)) # after the update evaluation section has been updated threefold:  tsp experiments are now in the appendix rather than main part of the paper  kmeans experiments are lloydscore normalised and involve one cifar10 clustering  knapsack problem has been added paper significantly benefited from these changes, however experimental section is still based purely on toy datasets (clustering cifar10 patches is the least toy problem, but if one claims that proposed method is a good clusterer one would have to beat actual clustering techniques to show that), and in both cases simple problemspecific baseline (lloyd for kmeans, greedy knapsack solver) beats proposed method.	0
that work has been out for long enough that i'd urge you to cite it, but it was not published and it reports results that are far less impressive than yours, so that omission isn't a major problem.	0
this claim lacks scientific support, otherwise please cite proper references.	0
"the algorithm used for inference and learning is stochastic em with pmcmc but the authors do not cite important prior work such as: lindsten (2013) ""an efficient stochastic approximation em algorithm using conditional particle filters"" pros: the model is sound."	2
the paper makes use of the reparameterisation trick, but does not cite the relevant literature, e.g. [kingma 2013, rezende 2014, and another one i currently struggle to find].	0
"while optimizing over the unit sphere is manageable it is most definitely a constrained optimization problem, and it is far from clear that it is much easier than working under the nickel & douwe constraint, |x| < 1. other comments:  the sentence ""even infinite trees have nearly isometric embeddings in hyperbolic space (gromov, 2007)"" sounds cool (i mean, we all want to cite gromov), but what does it really mean?"	0
it would be interesting if it also turns out to be a good regularizer, but the authors do not say why nor cite anything.	0
authors selectively cite and compare sener et al. only in svhnmnist experiment in sec 5.2.3 but not in the office31 experiments in sec 5.2.2.	0
there has recently been this works on training imagenet in 1 hour, then in 24 minutes, latest in 15 minutes... you cite the former, but highlight different part of their work.	0
neuroimage 87 (2014): 96110. references ———— ledoit wolf regularization is used but not cited.	0
he is cited later, but in a misleading way.	0
the mdpwithinanmdp approach is quite similar to the pazis and lagoudakis mdp decomposition for the same problem (work which is appropriately cited, but maybe too briefly compared against).	0
pnl ica is solvable and there are a number of algorithms proposed for it, some cited already in the above review, but also more recent ones.	0
"# paper discussion: i think this is a nicely written paper, which gives a good explanation of the problem and their proposed innovations, however i am curious to see that the more recent ""plug & play generative networks: conditional iterative generation of images in latent space"" by nguyen et al. was not cited."	0
"these two papers need to be cited: rudolph et al., nips 2017, ""sturctured embedding models for grouped data"": this paper also presents a method for learning embeddings specific for subgroups of the data, but based on hierarchical modeling."	0
the tensor factorization setup ensures that the embedding dimensions are aligned  clustering by weights (4.1) is useful and seems coherent  covariatespecific analogies are a creative analysis cons:  problem setup not novel and existing approach not cited (experimental comparison needed)  interpretation of embedding dimensions as topics not convincing  connection to randwalk (aurora 2016) not stated precisely enough  quantitative results (table 1) too little detail: ' why is this metric appropriate? '	0
cons: 1. the authors did not relate the proposed evaluation metric to other metrics cited (e.g., the inception score, or a visual turing test, as discussed in the introduction).	0
"there is actually some prior work that includes some analysis on what is learnt in the earlier layers of convnets trained on raw audio: ""learning the speech frontend with raw waveform cldnns"", sainath et al. ""speech acoustic modeling from raw multichannel waveforms"", hoshen et al. ""endtoend learning for music audio"", dieleman & schrauwen only the first one is cited, but not in this context."	0
wavenet is mentioned (2.2.4) but not cited.	0
> we can, during training, exploit privileged information about the true system state >> this was done also in pinto et al. and many of the cited gps papers > our policies solve the tasks that the stateoftheart reinforcement and imitation learning cannot solve >> i don't think this statement is justified without much wider comparisons  the authors don't attempt any comparisons to prior work, such as chebotar '17 (which arguably is closest in terms of demonstrated behaviors), nair '17 (which is also close but doesn't use images, though it likely could).	0
some previous work is cited, but i would point the authors to much older work of parr and russell on hams (hierarchies of abstract machines) and later work by andre and russell, which did something very similar (though, indeed, not in hybrid domains).	0
some previous work is cited, but i would point the authors to much older work of parr and russell on hams (hierarchies of abstract machines) and later work by andre and russell, which did something very similar (though, indeed, not in hybrid domains).	0
prior work seem adequately cited and compared to, but i am not really knowledgeable in the adversarial attacks subdomain.	0
originality: acceptable, but a very similar idea of embedding contexts is presented in tu et al. (2017) which is not cited.	0
the funny thing is that many of these papers are actually cited by the authors, but they simply pretend that those works don't exist when discussing the results.	0
the work is original, but i would say incremental, and the relevant literature is cited.	0
i am not very familiar with the work related to lstms in generating melodies conditioned on harmony, so the work may be novel in that sense, but i suspect there is a plethora of related works, and likely several more closely related than the two cited in the paper as it now stands.	0
the authors mention that related work is generalized but fail to differentiate their work relative to even the cited references (kim & lane, 2016; hori et al., 2017).	0
i am not expert in the field but i think that there are recent references which could be cited for probablistic models of graphs. '	0
but one of the main ideas of this paper (truncating the planning horizon and replacing it with approximation of the optimal value function) is not new and has been studied before, but has not been properly cited and discussed.	0
also, [rabin et al., 2011] is cited in section 5 but i couldn't find it in the bibliography.	0
the only relevant work cited from this angle is mathieu et al. (2016), but even that is dismissed lightly by saying it is worse in generative tasks.	0
al. iclr 2014 which could be cited to address that reviewer's concern.	0
i do not think they reduce at all the contribution of this work, but they should be cited and maybe included in the tables: a. gordo, j. almazan, j. revaud, and d. larlus.	0
"the authors cited the no requirement of ""a predefined number of clusters"" as one of the contributions, but the tuning of alpha seems more concerning."	0
"however five of the words the authors retain: bored, annoyed, love, optimistic, and pensive are not in fact found in the panasx scale: reference: the panasx scale: https://wiki.aalto.fi/download/attachments/50102838/panasxscale_spec.pdf also the longer version that the authors cited: https://www2.psychology.uiowa.edu/faculty/clark/panasx.pdf it should also be noted that the panas (positive and negative affect scale) scale and the panasx (the “x” is for extended) scale are questionnaires used to elicit from participants feelings of positive and negative affect, they are not collections of ""core"" emotion words, but rather words that are colloquially attached to either positive or negative sentiment."	0
the cited paper by bengio et al., 2015 is among such, but by no means the only one.	0
i think the authors have the right intuition, but no evidence or citation is presented to motivate result 5. indeed, dcgans are known to have extremely sharp interpolations, suggesting that small jumps in z lead to large jumps in images, thus having the potential to assign low probability to tunnels.	0
given, questionable contribution and a lack of relevant citations, it is difficult to recommend for acceptance of the paper.	0
i understand that the authors are pasting in numbers from many places and just providing pointers to papers that provide more citation info, but i think this can lead to misattribution of methods.	0
this is just one example, but i hope the authors could carefully check the paper and make sure all the notations/terminologies are properly defined or referred with a citation when first introduced (e.g., pointwise, pairwise, and listwise loss functions).	0
a couple of mistakes like this would, of course, be fine, but when it is almost every citation it gets annoying.	0
"also in section 3, several references are made to a ""previous"" model, but no citation is given."	0
i think the right citation is “incorporating invariances in support vector learning machines “ scholkopf, burges, vapnik 1996, but also see decoste ' scholkopf 2002 “training invariant support vector machines.”	0
and a few typos:  just above 2.1.3: « increasing » => increasingly  in 3.1: « where v is a baseline that depend » => depends  p.7: « hight » => high, and « to all other sequences » => of all other sequences  double parentheses in bellemare citation at beginning of section 4  several typos in appendix (too many to list) note: i did not have time to carefully read appendix 6.3 (contextual priority tree) edit after revision: bumped score from 5 to 7 because (1) authors did many improvements to the paper, and (2) their explanations shed light on some of my concerns	0
6. not a big deal for me in terms of deciding acceptance, but for the sake of good principles in academics, related work could be stronger, though i can understand it must have been small purely due to page limits.	0
i like the notion of marginalizing over latent tree structures, but the related work section needs to make clear what is being contributed here that is different from the cited past work on this problem  on the mt eval, why are you missing values for zhen on the nmt models that are actually competitive?	0
if you need to cut space, move technical content to appendix, but don't compromise in related work.	0
if this is about rl great, if this is about compression, there is a lack of related work and proper comparisons to existing methods (at least concenptual)  claims about the benefits of not needed expertise are not clear to me as, from the results, seems like expertise is needed to set the hyperparameters.	0
"the related work section is good but in my opinion miss to give a position with respect to the work dedicated to extract rules from a net which are also way to ""interpret"" a rnns  as an example https://arxiv.org/abs/1702.02540 from iclr'17."	0
 the comparison to related work is really lacking.                 	0
pros and cons () interesting idea () diverse experimental results on six datasets including benchmark and realworld datasets () lack of related work on recent catastrophic forgetting () limited comparing results () limited analysis of feature regularizers detailed comments  i am curious how we can assure that svm's decision boundary is similar or same to nn's boundary  supportnet is a method to use some of the previous data.	2
following papers are omitted in related work: 1. lee et al. overcoming catastrophic forgetting by incremental moment matching, nips 2017.	0
reasons to accept the paper  novelty  works in an unsupervised setting  well written/structured reasons to reject  doubts concerning the experimental setting  (minor) related work is not complete  (minor) not all common performance measures are reported  [1] wang, peifeng, shuangyin li, and rong pan.	0
the paper goes to 10 pages but does so by adding redundant information (e.g. the intro is highly redundant) while some important details are missing the paper does not cite, discuss or compare with the related work “synthesizing images of humans in unseen poses”, by g. lalakrishan et al. in cvpr 2018. page.	0
in the related work section, it is stated that cohen et al. use isotropic filters, but this is not correct.	0
my primary concerns are a larger relation to past related work for unfamiliar readers, comparison to modern work (or any work outside this paper itself) in the results tables, and a focus on clarifying the take home message of the paper.	0
2. the major novelty of this approach is the use of annotations supporting images and textual (pretrained) embedding spaces, but no related work regarding wes was neither introduced in the related work section nor was it clearly explained in the text.	0
the setup in section 5.2 is potentially interesting, but needs more work, in particular a proper comparison to related work.	0
rewrite the related work section to scope it better: for instance, sabour et al. in adversarial manipulation of deep representations and wicker et al. in featureguided blackbox safety testing of deep neural networks explore adversaries operating in the feature space.	0
(b) mitigating unwanted biases with adversarial learning (which the authors cite, but do not offer any comparison or differentiation) to improve the paper, these related work should be discussed in related work section, and (if applicable) compared to the proposed method in the experiments, rather than a very brief mention of one of them in section 3.3 and no comparison.	0
the paragraph after eq 3 needs some rewriting  the explanations around and including equations 5 and 6 were quite poor: .pi is referred to but not used, it is not made clear that that g is the gradient of log p(z) instead of p(z), use brackets for the log in eq 6 to avoid ambiguity 2) the reference formatting is wrong (i.e. cite is used everywhere instead of citep) 3) i thought the motivation for the approach in the intro was very good 4) as the seemingly most related work, it would be good to elaborate more on the goyal et al paper and the differences of your approach to theirs.	0
minor note: the related work mentions grounding graphs which are core to work from tellex and roy, but omits existing fully neural endtoend models in grounding (e.g. referring expressions work).	0
while you have mentioned enas in the related work, the lack of a comparison makes it hard to evaluate the true benefit if this work compared with existing literature.	0
however, based on the discussions to date, i feel that i am not sufficiently familiar with related work on sat solvers to say whether the other reviewers' concerns have been fully addressed.	0
it is a surprising result that such a penalty on the lower bound can prevent mode collapse while also promoting diversity, since i would expect that upper bounding the generator gradient (i.e. lipschitz continuity which wasserstein gans and related work rely on but for their discriminator instead) makes sense if a smooth interpolation in latent space is desired.	0
weaknesses: the discussion of related work is deficient.	0
weaknesses: 4. related work: 4.1. the paper mentions the zeroshot vqa work from teney & hengel, however, given that is one of the most related works, i expect a more thorough discussion of the similarity in dataset and method.	0
conclusion: overall a great direction and interesting approach but requires more careful experimental setup and evaluation and discussion of related work for acceptance.	0
missing citations '' i believe two recent papers (this year's icml) should be mentioned in the related work section as they propose two representation learning algorithms for pomdps that, as far as i can tell, are not yet mentioned in the paper but quite relevant to the discussed topic.	0
in the related work, the author argues that methods such as dqfd require reward signal, but it would be great to demonstrate the advantages of sqil over these methods (including dqfd and nac (gao et.al, 2018)).	0
more details in terms of presentation:  section 2.1 and algorithm 1 reviewed gradient dropping which is the main related work to this paper but it is in the middle of the related work section.	0
however, it is poorly written, does not properly discuss the related works and does not present a convincing method or experimental results.	0
(6/10) === pros ===  extends a widely used model (pointernetworks) to the reranking setting  discusses practical issues in getting this to work at scale  shows that it works in a realworld setting  contextualization within existing research shows good understanding of related work === cons ===  is a fairly direct application of pointernetworks with the innovation being in the details (i.e., is more of an ‘industry’ paper)  additional experiments around ‘diverseclicks’ settings (to see how smooth the performance curve) and submodular comparisons may have been interesting in summary, i think there is room for improvement (some outlined in the conclusion), but is an interesting finding with promise that i plan to try myself.	2
abstract comments: trail and error > trial and error introduction comments: alternative reasons why pose estimation won’t work is because for any manipulation tasks, you can’t just detect pose of the agent, you also have to detect pose of the objects which may be novel/different few use image based inputs and none consider the importance of learning a distance function in time as well as space > missed a few citations (eg imitation from observation (liu, gupta, et al)) therefore we learned an rnnbased distance function that can give reward for out of sync but similar behaviour > could be good to emphasize difference from imitation from observation (liu, gupta, et al) and tcn (semanet et al), since they both assume some sort of time alignment missing related work section.	0
however, the reviewer has some concerns about the pertinence of the approach and the relationship with related work.	0
specific comments follow: 1. a major concern of the reviewer is that, given the related work mentioned in section 3, whether the proposed method exerts substantial enough contribution to be published at iclr.	0
it is easy to ask for additional experiments (i.e., other mechanisms of uncertainty such as the countbased discussed in related work, other settings in 2.2) — but the quality seems high enough that i basically trust the settings and findings.	0
cons:  low originality and missing comparison to related work  unconvincing experimental section minor remarks: ' the title is misleading in the sense, that the spatial part of the spatiotemporal representation is not related to actual space, and further, that the backpropagation is not spikebased ' the figures appear blurry, and in the case of fig. 2 is very hard to read. '	0
strengths:  the paper is almost well written, with comprehensive related works and it is easy to read except for few details (see below).	2
regarding the clarity, beside the use of the gallery, several small issues should be improved: ' the paper use the term deformed images (until sect ~4) and then synthetic images for the generated images; ' figure 2 is introduced early but explained late in the paper and it is not clear how the second and the third images should be interpreted; ' in the related work section, wang et al. 2018 is said to generate imaginary images in contrast to realistic images of the proposed method not synthetic, however the images are clearly not real and are synthetically generated from the heuristic and the weight of the network.	0
the related work discusses papers about state representation but even more directly related to this paper, other papers have also discussed the importance of disentangled representation or entropy maximization for deep rl: https://arxiv.org/abs/1707.08475, https://arxiv.org/abs/1809.04506, ... and papers that discuss expressiveness in deep learning such as https://arxiv.org/pdf/1606.05336.pdf should also be discussed.	0
originality novelty: there is a large body of work on disentanglement that the paper does not cite or compare to for instance, infogan, beta vae https://openreview.net/pdf?id=sy2fzu9gl and disentangled latent concepts https://arxiv.org/pdf/1711.00848.pdf note that for example that in beta vae it is a similar idea where but it is on z and z|x and the distance used is kl (since it is has closed form with gaussian) , min_phi loss beta kl (p(z), p(z|x)), a discussion of the previous related work in the paper is necessary.	0
in the related work the authors mention several alternative deidentification methods, but they only compare with a single method from 2014. i think the paper could be made much stronger if the authors could compare against more recent techniques, especially those that also utilize an adversarial component.	0
i am not entirely convinced that ad and mhp is a killer combination, but the experimental results are ok, nothing to complain here (except the usual bla: make it larger, more, etc), but honestly they really fine (maybe compare also again against more related work, e.g., ruff et al icml 2018).	0
"the paper mention that ""an underwhelming amount of reinforcement learning studies have focused on the settings with perturbed and noisy rewards"" but there are some works on the subject (e.g., https://arxiv.org/abs/1805.03359) and a discussion about the differences with the related work would be interesting."	0
this is an important issue, as other platforms allow for the definition of some baseline agents, including random agents, agents with simple policies, etc. the background and related work section covers mmo and artificial life, but has some important omissions, especially those ideas in the recent literature that are closest to this proposal.	0
weaknesses  the related work paragraph is extremely sparse.	0
weaknesses:  poorly written, incorrect grammar throughout that distracts from the content along with a number of factually incorrect statements about concepts and related work.	0
although i consider the related work well done, i can't help but wonder if there isn't older work on rbfs, etc., that might have been missed (i mostly want to encourage the authors to look once more and then come back and tell me i'm wrong).	0
few comments: a) in second equation in section 2 authors state speaker identity “s” is part of conditioning inputs “h” but it is not shown in the equation where “h” is replaced with “l, f_0” b) in related work, i think the speaker code work of abdelhamid et al., e.g. ossama abdelhamid, hui jiang, “fast speaker adaptation of hybrid nn/hmm model for speech recognition based on discriminative learning of speaker code,” icassp 2013 is worth citing.	0
cons:  there is very little comparison to related work.	0
"in addition, there is additional related work that the authors do not cite, but ought to: [1] yarin gal, jiri hron, alex kendall, ""concrete dropout,"" proc."	0
strong points  learning both weights and label predictions in ssl seems to be novel (provided that the author's claim in the related work section is right).	2
pros:  theoretical guarantees, elegant approach  good empirical results compared to other models  desirable properties: rotationequivariance, lower computational complexity, fewer parameters, robustness and guaranteed stability to deformations cons:  somewhat incremental technical novelty: combination of two previously published methods (qiu et al. 2018 & weiler et al. 2017) comments: 1. i believe the related work section can be improved by explaining more clearly the connection between your work and the cited ones and emphasizing the advantages and limitations of rotdcf compared to other methods in particular, a reader should be able to precisely understand what is the novelty of this work is and what were the technical challenges in combining previously published ideas (such as dcf and sfcnn) 2. how do you determine the truncation in practice?	2
cons: cnn was covered in previous related works (so weight sharing is not a new contribution); densenet is not explicitly covered in this work (i mean current densenet does not have n skipconnections to output; correct me if wrong).	0
experimental results also show improvement over two related works on incremental fewshot learning.	0
strengths  the paper thoroughly covers related work and provides context.	2
at the bottom of page 3 in the related work, a concrete application used in prior work is mentionedwhere crowd workers are shown single labels and vote y/n, leading to a mix of standard (if y) and complementlabeled (if n) datahowever this mixed setting is not considered explicitly in this paper.	0
strengths: well written paper, covers most of the relevant related work technique is conceptually easy to understand (~ adversarial training) weaknesses: unclear set of desiderata properties for a watermarking technique no formal guarantees are verified, the mechanism is only tested attacks tested are not tailored to the technique proposed feedback and rebuttal questions: this submission is easy to read and follow, and motivates the problem of watermarking well in light of intellectual property concerns.	2
they talk about metalearning in the related work but it is unclear precisely how they relate this to their own work.	0
i realise that the algorithms with decentralised actors won't scale here, but something like the mean field approaches described by the authors in the related work, or even less sophisticated algorithms using some (but not all) features of their own approach would show something interesting.	0
concerning unsupervised domain adaptation, the related work section is not complete, the authors only cite ganin et al. (icml2015) and tzeng et al. (cvpr2017), but the literature is not limited to these two works.	0
[cons] [quality] the major issue of this paper is the lack of connection to existing related work in the field of dealing with reward sparsity problem.	0
== related work == i like the related work discussion, but would emphasize more the connection to mdns and to mixup.	0
comments  the paper has a number of typos in the references  please carefully check and also complete missing information  i understand that you have to promote your approach but looking on the title your objective is to go from distances to kernels > although you go a different way (which is fine) you can also do this directly by using concepts as proposed by gisbrecht et al. 'metric and nonmetric proximity transformations at linear costs', neurocomputing which you should at least take into account  to sum up a bit your related work part you should refer to a recent review by tino et.	0
in terms of technical novelty, the work is relatively incremental: (a) the use of multitask objectives in sequence models [1] is relatively common nowadays (there is little mathematical details in the paper, so it’s hard to see how the approach of the paper really differs from extensive related work.).	0
originality: i am not familiar with the literature of generative models to judge this precisely, but according to the related work section it sounds like an original idea that is worth sharing. '	0
in the related work the authors mention modelling bias as a downside of prior work.	0
there is a significant related work section that does an ok job of describing many other works, but to my knowledge (camacho 2017) is the most similar to this one (minus the embedding), yet is not mentioned here.	0
"in introduction, para 3, ""must depend on other parameters""  this seems like an obvious statement but it is presented as being crucial  should ""related work"" start at 1 or 2?"	0
a few other minor comments:  in the related work section, the authors write: “on the other side of the spectrum, methods that optimize standard iterative learning algorithms, [...] are accurate but slow.” note however that neither maml nor metalearner lstm have been showed to be as effective as prototypical networks for example.	0
pros: the introduction and related work section is very well written, and motivation of why one should try adversarial loss for forward models is clear.	2
2. the related work is missing several papers, namely the entire category of work on using network morphisms to speed up the optimization process, bender et al's one shot model, and several early papers on neural architecture search (work on nas did not only start in 2017 but goes back to work in the 1990s on neuroevolution that is very similar to the evolution approach by real).	0
yes, they won’t use image data, but at least they can use the same amount of crowd label information, which would make a nice comparison with the presented related work and proposed nn: this is what you can get using just image data during test (crowd layer, maxmig, and others from the current paper), this is what you can get using just crowd labels during test (majority voting or, preferably, more advanced pure crowdsourcing aggregators), and this is what you can get using both image and crowd labels during test (the proposed forecaster and aggnet, for example) questions out of curiosity: i).	0
b) the approaches that this paper discusses for representation learning have been around for quite a long time, but it seems rather a misrepresentation of the related work to have all but two citations in the related work section 2017 and after.	0
the related work section (or lack thereof) can be improved.	0
however, and this is a critical weakness of the paper, no attempt is made to compare the proposed method with respect to any related work, beyond a short discussion in section 3. the experiments do include some baselines, but they are all very weak.	0
i am not an expert in the field and cannot judge the related work objectively but can say that the context for their approach is set appropriately.	0
this point is not really addressed in the experimental evaluation as benchmarking is performed against a robust and an adaptive policy but not explicitly against the (arguably) most closely related work in yu et al. it could be argued, of course, that yu et al. essentially use adaptive policy generation but they do explicitly learn dynamics parameters based on recent history of actions and observations.	0
my concerns are:  the paper should perform a literature search on related work from operations research, including especially principalagent problems, which are not currently surveyed, and perhaps also optimal scheduling problems.	0
the background and related work section covers most of the recent relu alternatives, but doesn't not clearly explain what an activation function is, and misses some references.	0
the related work section is pretty good, but reads a bit like a list of papers  it would be nice to have a bit more discussion of how related methods are similar/different to the proposed method.	0
the strengths of this paper are:  this work addresses an important problem and is well motivated  experiments on both simulated and on a real system are performed the weaknesses:  the related work section is biased towards the ml community.	2
according to the sparse 'related work' section, the contribution is novel, but i will leave it to the consensus of others who are more versed in this regard.	0
pros:  a simple, straightforward idea  a good topic  progress in modelbased rl is always welcome cons:  unclear how this is significantly different from other related work (such as imagination agents)  experimental setup is poorly executed.	2
i am not very familiar with the related work, but if i understood correctly, the paper seems to combine deep latent modeling (glo, bojanowski et al., 2018) and deep image priors (ulyanov et al., 2018).	0
cons: the major flaw is the lack of comparison with ``any'' of the related work on interpretability or the prior work on imposing structure upon hidden representations.	0
========== concerns: ========== [a] the discussion of differences to the closely related gail methodology is left until the related work after experiments.	0
pros:  the motivations for the work are clearly explained and highly relevant  comprehensive overview of related work  clear and consistent structure and notations throughout  convergence proof is provided under certain assumptions cons:  no intuition is given as to why rcpo isn't able to outperform reward shaping in the walker2dv2 domain minor remarks:  in table 2, it would be good if the torque threshold value appeared somewhere  in figure 3, the variable of the xaxis should appear either in the plots or in the legend  in appendix b, r_s should be r_step and r_t should be r_goal to stay consistent with notation in 5.1.1	2
pros:  nice approach for hierarchical deep rl  great use of her to improve subgoal learning  good empirical results showing benefit of approach over flat learning cons:  no empirical comparison to related work  subgoal testing phase seems a bit hacky.	2
in the related work the authors try to motivate their approach but i am afraid in a too handwavy manner.	0
i think that for many applications, this is not a serious problem, but it would still be nice to be transparent and mention this as a limitation of the method when comparing to related work.	0
the result itself may not be super novel as noted in the related work but it's still a strict improvement over previous results which is often constrained to relu activation function.	0
i can see the difference against that paper from the authors' argument in the related work, but that is the difference not comparison.	0
without stronger comparison to other closely related work, and lack of citation to several closely related models, the claim of novelty isn't defined well enough to be useful.	0
my primary concern is in relation to related work, clarification of the novelty claim, and more comparison to existing methods in the results tables.	0
the latter appears to be of less significance in this context, but i found robust offline policy evaluation underrepresented in the related work.	0
since the authors addressed my main concerns, i e. comparison to existing methods, clarifications of the proposed approach, adding references to related work, i will increase my score and suggest to accept the paper.	0
strengths:  good coverage of related work  clear presentation of the methods  evaluation using established semeval datasets weaknesses: 1. it is not entirely clear what is the connection between fuzzy bag of words and dynamax.	2
4) related work discussion is quite brief and misses some relevant work, for instance adversarial autoencoders (makhazani et al., iclr 2016, somewhat related) or adversarially constrained autoencoder interpolations (berthelot et al., arxiv 2018, it’s concurrent, but could be good to discuss).	0
to conclude, the paper presents quite good qualitative results on the celebahq dataset, but has problems with the thoroughness of the experimental evaluation, discussion of the related work, and presentation.	0
cons (quibbles): experiments: the authors didn't compare the proposed method against topic model (vanilla lda or it’s derivatives discussed in related work).	2
my main concerns about this paper are its related work and its writing.	0
minor comments: 1. i suggest adding the following papers to the related work section in the final version: https://arxiv.org/abs/1805.06523 https://arxiv.org/abs/1810.02054 https://arxiv.org/abs/1810.04133 https://arxiv.org/abs/1712.00779 these paper are relatively new but very relevant.	0
the last paragraph of the related works section mentioned some related work with shortcomings as working only on lowdimensional data and features of specific types, yet the experiments are also mostly done on lowdimensional datasets.	0
lack of baselines:  the authors mention social lstm and social gan in the related work, however, no comparison is provided.	0
"# paper strengths  the paper has a good coverage of related work  the proposed method is interesting and the results are encouraging  the authors argue and study the influence of multiple elements over their contribution: number of subgenerators, distance metric, choice of architecture # paper weaknesses  my main concern with this work is the incremental contribution with respect to the work by han et al. (2018), ""face recognition with contrastive convolution""."	2
cons:  related work is missing and some claims in the paper are wrong as a result.	0
i have to admit that i'm not familiar with the related work on attention, but i did not understand 'why' the results of the proposed method are supposed to be much better than that of previous work.	0
"maybe they are understandable in the context of related work, but i found many statements, such as the following, devoid of meaning:  ""without considering the uneven distribution of information in the corrupted images, [...]""  ""however, in this paper, we mainly focus on learning nonlocal attention to better guide feature extraction in trunk branch."""	0
strengths: the discussion of related work and comparison to baselines is pretty extensive.	2
my main concern is that the authors fail to compare their appproach to any of the modelling approaches discussed in the related works section.	0
although the connection with crps is interesting (first of the two equations in page 3), it is quite similar to an accelerated failure time formulation, which for a lognormal specification is standard and popular due to similar reasons to those highlighted by the authors, but not mentioned in the related work.	0
cons:  some recent works on structural node embedding are directly related to this work but missing in the related work section: struc2vec [1] and graphwave [2].	0
pros:  this work demonstrates, theoretically and empirically, a simple way to train generic models using only the known class balances of several sets of unlabeled data (having the same conditional distributions p(x|y))a very interesting configuration of weak supervision, an increasingly popular and important area  the treatment is thorough, proceeding from establishing the minimum number of u datasets, constructing the estimator, analyzing convergence, and implementing thorough experiments cons:  this is a crowded area (as covered in their related work section).	2
"for example, the introduction and related work sections take up a large portion of the paper, but are very dense and heavy with jargon that is not internally defined upfront; for example ""risk rewrite"" is introduced in paragraph 2 with no internal definition and then used subsequently throughout the paper (this defn would be simple enough to give: in the context of this paper, ""risk rewrite"" means a linear combination of the classconditional losses; or more generally, the expected loss w.r.t."	0
weak points: 1) although the ensemble idea is new, the idea of selective selftraining is not novel in selftraining or cotraining of ssl as in the following survey.	0
however the literature survey lacks survey of more relevant quantization techniques e.g. [1].	0
experimental results and survey studies demonstrate that autogen is able to leverage latent representation more effectively when comparing with vae without annealing, has better reconstruction overall, but at the same time lose some ability to generate good samples from prior  this is not too surprising considering the model objective balances between generation and reconstruction.	0
pros:  available source code  large number of experiments cons:  the exposition could be improved, in particular the description of the plots is not very clear, i'm still not sure exactly what they show  not clear what the target audience of the first part (section 2) is, it is too technical for a survey intended for outsiders, and discusses subtle points that are not easy to understand without more knowledge, but at the same time seems unlikely to give additional insight to an insider  limited amount of new insight, which is limiting as new and better understanding of gans and practical guidelines are arguably the main contribution of a work of this type some suggestions that i think could make the paper stronger  i believe that in particular section 2 goes into too many mathematical details and subtleties that do not really add a lot.	2
i sense that everyone has settled upon leakyrelus for internal layers, but a survey of that work and experimentation within the authors' framework would have been nice.	0
the first survey question asked would be more likely 9095% of the cost with each additional question some incremental percentage.	0
comparison with prior work: neural network based ondevice keyboard input is a research topic with a lot of previous contributions and the existing literature survey seems lacking.	0
weaknesses:  the paper is motivated in a confusing manner and neglects to thoroughly review the literature on weight uncertainty in neural networks.	0
i think the comparison between prior lifetimes and humans mastering a language doesn’t hold up and is distracting #### revision: the rebuttal does little to clarify open questions: 1. both reviewer 2 and i commented on the ablation study regarding the grid but received no reply.	0
these were easy tasks that could have been done during the review period but were not.	0
the work also lacks value in literature review, optimization and experiments.	0
overall, the direction in which the paper is taking us is very interesting, and i can imagine a rewritten version of the present paper in the previous years' iclr workshop format to be a very good candidate but for a paper that has no theory, that is very light on its experimental descriptions and details, that is very light on relevant research review, and that is very loaded with vague and imprecise descriptions, i can not recommend the submission for iclr as it stands.	0
in terms of quality: clear motivation; substantiated literature review; but the algorithms proposed are not novel and the question of whether the method will scale to more unknown parameters is not answered.	0
overall the amount of content in the paper feels lacking and there seems to be large amounts of review, repetitiveness, and unnecessary details.	0
in my initial review, my comment on the experiment on mnist is not on correlation between the maximum likelihood estimation and visual quality of generated images, on which the author feedback was based, but regarding the wellknown property of the kl divergence due to its asymmetry between the two arguments.	0
i would be willing to reconsider my review if the authors can address the above weaknesses.	0
i agree with the other two reviewers that the work is somewhat incremental, but the differences are well explained, the experimental results are interesting (particularly the differences of parameter vs representationbased sparsity, and the plots in appendix showing neuron importance over tasks), and the progression from sni to slnid is wellpresented.	0
also, the literature review has been done very lightly: chen et al. 2017b (and most cited above) do 'not' assume a single byzantine agent as said in the paper, but assume up to <50% malicious (potentially colluding) agents.	0
postrebuttal review i appreciate the authors' efforts in clarifying some of my concerns.	0
update after the author response: the author addressed some of the concerns raised in the review(thanks for the detailed response), in particular, the comparison to cudnn.	0
in a follow up response to anonymous public comments, some new tests using cifar10 data are presented, but to me, proper evaluation requires full experimental details/settings and another round of review.	0
"a lot of the shortcomings mentioned in the review are outright dismissed (e.g., ""de facto standard in rl""), downplayed (esp."	0
as there is no strong technical contribution beyond the experimental observations in the current submission, i suggest the authors try to address the gan shortcomings both mentioned in reviews and their reply, instead of just observing / reporting them.	0
r3 mentioned similar concerns in their review, saying that the paper lacks explanation for why rl would win over nonrl for e.g. sentiment analysis.	0
however, based on the discussions to date, i feel that i am not sufficiently familiar with related work on sat solvers to say whether the other reviewers' concerns have been fully addressed.	0
as for the concerns from my original review: the transferability experiments reported in the author comments below are quite informative, and i'd encourage the authors to incorporate them into the paper (or an appendix if space is an issue).	0
reviewer 1 and reviewer 2 both raised serious concerns about the types of sat instances that were used to evaluate the experimental setup, as well as about the use of z3 as a baseline for solving random sat instances.	0
at present this work lacks even the most rudimentary evidence to support the claims of robustness, and i hence refrain from providing a full review.	0
"i do feel however that the review could be improved, for example, by discussing the recent papers by chinmay hegde and piotr indyk on ""head"" and ""tail"" approximate projections to speed up recovery algorithms."	0
my main concerns are as follows: ' the review of the prior literature, in particular on scorebased and decisionbased defences (the latter of which are not even mentioned), is very limited and is framed wrongly.	0
for the reasons above i recommend rejection of the manuscript in the current state but i am confident that many of these issues can be resolved easily and if this is done i will update the review.	0
when the other points are addressed (as the authors say they will do) it may be a good paper  but the review must stick to the submitted version, not a future one.	0
being familiar but not an expert in either game theory or adversarial training, my review will focus on the overall soundness of the proposed method summary: the authors propose to tackle the problem of adversarial training.	0
brief review summary: there are some interesting ideas in this work but i feel that the some practical aspects lack formal justification and the comparison to existing work is inconclusive.	0
while i suspect that the first concern may be clarified with discussion i think that the second is more serious and is the primary factor behind my review score.	0
pros: the literature review is rich and complete.	2
the paper lacks a literature review in this area and a reasoning of why the proposed approach is preferred.	0
the authors addressed my concerns stated in my review above.	0
the authors have carried out an extensive review of the literature showing the evolution as well as the strengths and weaknesses of these methods.	2
revised review: the authors of this work has taken my concerns, and concerns of other reviewers, and revised their paper during the rebuttal period.	0
it was due to a technical error on my part (i thought the reviews had posted, but they had not).	0
it is not quite a review paper, but only compares previous methods.	0
there are e.g. datasets (protein data  see tino) get very bad classification models if the negativ contributions are removed  accordingly they are not just noise but contain valuable information to the problem  it would be good to add a few sentences at the beginning of the paper to (super brief) review the core idea/concept of siamese networks  the english is sometimes a bit bulky and it would be good to check it by a native speaker e.g ' proposal do not require'  proposal does not require ' unlike the our'  follow by a spellchecker 'embeddng', 'interms', 'simalry'  'followed by removing it by flipping'  with flipping the contribution is not 'removed' but mapped to the positive part of the spectrum  how does your approach compare to a classical embedding of the indefinite kernel matrix into a pseudo euclidean space (see e.g. tino or pekalska)?	0
strengths  i applaud the simplicity of the idea: this much simpler framework leverages many of the intuitions behind the gp adapter framework (gpgru) [4][5] with comparable performance and appears to train orders of magnitude faster (caveat: on one data set and task)  it likewise outperforms both commonly used preprocessing (gruf) [2][3] and the much more complicated neural net architecture (gruhd) from [6] (across two datasets and tasks)  the simplicity of this approach probably lends itself to additional customization and innovation  the literature review seems quite thorough and does an especially nice job of covering recent work on rnns for multivariate time series and irregular sampling or missing values  the experiments are thorough and welldesigned overall.	2
this paper tackles a very interesting subject but lacks sufficient clarity of presentation to allow me to do a proper review.	0
there is several interesting ideas and a new dataset introduced, but i would like to be more convinced that the problems tackled are indeed as hard as the authors claim and to have a better literature review.	0
experiments on realworld use cases rather than toy problems cons:  incomplete experiments according to footnote, thus results and conclusions might change after this review.	0
being familiar but not an expert in reinforcement learning, my review will focus on the overall soundness of the proposed method summary: the authors are interested in the problem of sample efficiency in reinforcement learning, i.e. how to learn a policy achieving good performance (discounted reward) in a rl setting using as little interaction with the environment as possible.	0
"the paper is easy to understand but several sections (starting from section 2) could use an english language review (e.g. ""search right"" > ""search for the right"", ""predict next word"" > ""predict the next word"", ...) in section 3, can you be more specific about the gains in training versus inference time?"	0
i also tried to reimplement the approach, but did not manage to finish before the review deadline.	0
other points:  the paper lacks a comprehensive literature review.	0
i did propose three comparison baselines in my initial review, but i am not satisfied with the authors' rebuttal on that.	0
in general, i feel the paper is interesting but would benefit from a major revision which makes the message of the paper more clear, and addresses these and other issues raised in the review phase.	0
also, i missed this in the original review, but the assumption that kl(.mu| p_d) = kl(.p_d| .mu) since .mu is close to p_d for mle training does not seem like a sensible assumption under model misspecification (as mle is mode covering).	0
in this case, the left inversion of is simply and so the weak loss is which corresponds to the loss (5) proposed in the paper under review (in fact, the loss (5) also adds a constant term (y2)/(y1) which however has no effect on the minimizer).	0
please forgive me if the concerns or issues i raise here already been asked by other reviewers.	0
i do let the clever model upvote my review, but not beyond borderline.	0
the results suggest that sn may not be good enough to be used as a fully autonomous forensic detector, but it can narrow down the pool of images which can be subjected to further human review or interventions.	0
overall the literature review is reasonably solid, but i am not sure the citations in the opening sentence are quite appropriate as modelbased drl has been around for longer than 2017 (see for example [13]).	0
disclosure: i reviewed this paper for a different conference but have read the new manuscript and noted the changes.	0
the empirical results are compelling, but i have a strong technical concern about the convergence issue noted by the authors (which was also communicated to the authors in a previous conference’s review session).	0
########################################### updated review: the authors have greatly improved presentation and have addressed concerns about the increase in parameters and computation time.	0
d2ke: from distance to kernel and embedding quality: average originality: original significance: relevant for iclr pros:  interesting idea  see detailed comments cons: some technical issues, validity of the results not clear  see detailed comments i have seen this paper already at icml as a review and i am happy to see that the authors have improved the paper.	2
comments  the paper has a number of typos in the references  please carefully check and also complete missing information  i understand that you have to promote your approach but looking on the title your objective is to go from distances to kernels > although you go a different way (which is fine) you can also do this directly by using concepts as proposed by gisbrecht et al. 'metric and nonmetric proximity transformations at linear costs', neurocomputing which you should at least take into account  to sum up a bit your related work part you should refer to a recent review by tino et.	0
to ensure reproducability of your results i ask you to provide the respective codes e.g. on github (can be done anonymous)  repeating myself from the last review: there is a lot of work addressing that making a kernel psd may not be good idea  you provide experiments for a small number of data where your kernel is now psd but what is with the other data (where e.g. in pekalska and followers it was shown that making them psd is bad ... )  is your approach solving this  or do we end with an approach which is not very performant (in accuracy) for the hard/crucial datasets?	0
i do not think the paper sufficiently motivates why a monotonic decay should be good, and while the new sota on permuted mnist is great, i'm concerned that the first experiments are not reproducable, as detailed previously in this review.	0
it provides a succinct review of dithered quantization and previous works, and figures provide a good insight into why the algorithm works, especially figure 3. theorems in this paper are mostly about plugging in properties of dithered quantization into standard results in stochastic optimization, but they are still useful.	0
the paper points to references to establish the existence of the problem, but for example the durugkar and stone paper is a workshop paper and the conference version of that paper was rejected from iclr 2018 and the reviewers highlighted serious issues with the paper—that is not work to build upon.	0
further the paper under review here claims this problem is most pressing in the nonlinear case, but the analysis in section 4.1 is for the linear case.	0
and i am still concerned about the countable x uncountable domain/image issue i raised in my review.	0
review: the paper brings up a number of important issues in empirical reinforcement learning and exploration, but fails to tackle them in a manner that convincingly isolates the problem nor proposes a solution that seems to adequately address the issue.	0
details (i am not including all my confusions here, but just a selection to keep review time manageable): ') references to figures appear to be incorrect.	0
6. the rating classifier (clf) is intriguing, but it's not clearly explained and its effect on the evaluation of the performance is not clear: one of the key metrics used in the evaluation relies on the output rating of a classifier, clf, that predicts reader ratings on reviews (eg on yelp).	0
"'detailed comments'' _paper strengths_  the idea to use a negative video example for unsupervised detection learning seems novel  the proposed method is simple and the needed data can be collected with widely available equipments  the paper addresses the problem of being robust with respect to moving distractor objects for cases in which those are present in both the positive and negative video example  the authors collected realworld data from different scenes with different objects, object counts and conditions (indoor/outdoor, still/moving camera)  the authors compare to a number of nonlearning approaches from opensource implementations (the reviewer cannot judge whether any relevant technique is missing)  the authors provide anonymized links to videos demonstrating a representative sample of the algorithm's performance on the considered scenes _paper weaknesses_  the authors clearly reduced the horizontal margins of the standard iclr style template leading to a wider text corpus, however, as the bottom margin seems to be increased the reviewer will review the paper nevertheless, but requires the authors to revert to the standard iclr style template upon update of their manuscript  the paper makes the relatively strong assumption that we have a video of the object of interest moving in the scene we plan to employ our algorithm on along with another video of the same scene with all relevant distractor objects but without the object of interest; given these assumptions the reviewer struggles to see a meaningful application of the approach (the only one provided by the authors, as tool for automated demonstration annotation, is not convincing, see below) that is outside of a very controlled setting in which more classic, e.g. makerbased approaches could be employed for detecting the object  the claimed robustness of the algorithm only holds for variations that were extensively present during training time (e.g. lighting differences on the car), in contrast the algorithm seems to be very sensitive to partial occlusion (as can be seen in the multiobject examples) and seems to heavily overfit on the color of objects (e.g. the car generalization to the new scene is easy as the car is the only red object in the scene, once the car moves away from the camera and the red front part is selfoccluded the detection fails, see e.g. minutes 1:15, 1:26 in the transfer video)  other than the single transfer example mentioned in the previous point the authors do not prove generalization to more challenging nontraining scenes with heavier clutter, nonseen lighting changes and occlusions to support their robustness claim  the proposed method cannot operate inthewild (e.g. youtube data) as it makes very strong assumptions about the required input data  the fact that the method needs to be trained from scratch for each new scene and object reduces the number of possible applications/scalability and makes comparison to classic baselines unfair which are not specifically tuned towards a certain object or scene  the authors make no comparison to other unsupervised detection approaches (e.g. to the selfcited jonschkowski et al. (2017)) to prove shortcomings of other methods on the newly generated dataset  as mentioned by the authors the method does not use any temporal information for the detection which surely could help, the reviewer cannot follow this design decision, especially because the fact that the encoder gets the difference image to the previous video frame as input in case of a moving camera (for egomotion estimation) makes applications to nonvideo data impossible, also none of the experiments exploit the nontemporal property of the approach to show single frame detection on a more varied set of scenes  the experiment showcasing the proposed application to ""learning from demonstration"" is not convincing as the method is only used to detect the goal location of the object but, critically, treats every object in the scene separately, missing any relational information in the target configuration, therefore in case of the sorting in a vertical line task the learned goal representation does not represent the actual goal of the task  the authors do not provide ablation studies proving the necessity of all three proposed objectives (slowness, variability, presence)  the reviewer cannot follow the references to objectcentric representation learning that are made in the paper, specifically because (as also noted by the authors themselves) the proposed method makes substantially stronger assumptions with respect to the input data and merely learns to detect the spatial coordinates of a single given object in a scene as opposed to learning an objectcentric scene representation that can be useful for downstream tasks, therefore the reviewer would strongly suggest to tone down the scope of the presented work, especially in the first paragraph of the introduction and the last paragraph of the conclusion  the ""random search optimization"" discussed in section 3.3 is not a valid method as it ""solves"" this problem of instable training by picking the best of n runs with varying random seeds  figure 2 is not very helpful for understanding, the details of the architecture (left part) could go to the appendix and be replaced with a figure that details the intended usage of the method for a concrete application to strengthen the motivation of the approach _reproducibility_  given the architectural information provided in the paper the reviewer believes it would be relatively straight forward to reproduce the results of the work.                  "	2
_conclusion_  overall, the reviewer appreciates the effort that went into the work but sees considerable need for improvement concerning the motivation and possible applications given the strong assumptions that are made about the input data.	0
==== updated review following rebuttal ==== the authors have addressed all of the concerns that i have mentioned above, and so i have updated my score accordingly.	0
many of the concerns in my original review were largely alleviate/addressed.	0
the paper is well written and easy to follow (i however found a few typos and small mistakes that i'll list at the end of this review).	0
the reasons for my recommendation, after discussion with other reviews, are  (1) lack of novelty and (2) weak theoretical results (some justification of which was stated in my initial review above).	0
i am willing to increase my review score if the authors successfully address the concerns mentioned above	0
i lean toward acceptance at the moment, but i am eager to discuss with the authors and other reviewers as i am not 100% confident that i fully understood the theory.	0
some questions are still remaining in my comment “review after rebuttal”, specifically, finetuning a pruned network may still get good performance if the hyperparameters are carefully tuned based on the pruning ratios, or in other words, the preserved weights is more essential for fast finetuning but less useful for significant pruning ratios.	0
cons:  experiments more preliminary  combines existing approaches, somewhat incremental minor comments:  grantee (typo), barely utilized > not fully realized?,  updated review: after reviewing the comments and the paper in more detail (whose story has evolved substantially) , i have revised my score slightly lower.	0
strengths  ' the paper does a pretty good job of reviewing relevant work from game theory. '	2
the review might have missed it, but what is the rationale behind the dotted link in figure 1a, or the dependence of the activation function on ?	0
in conclusion, the authors observe that quantizing weight/gradients systematically lead to a slight decrease in performance but provides promising improvement in term of training speed review  the paper is well written, documented and wellsectioned, with well written theoretical guarantees and thorough experiments, including one on a large dataset.	0
overall, although this paper is relatively incremental and has underwhelming experiments, it is a thorough work that is worthy of being presented at iclr 2019, in the reviewer's opinion.	0
(disclaimers: i am not not active in the subfield, just generally interested in the topic, it is easy however to find this paper in the wild and references to it, so i accidentally found out the name of the authors, but had not heard about them before reviewing this, so i do not think this biased my review).	0
cons  a review paper, which doesn't add much new to the existing suite of techniques.	2
novelty i’m not an expert on the literature of applying machine learning to the problems of reaction {product, mechanism} prediction but the paper appears to conduct a thorough review of the relevant methods and occupy new territory in terms of the modeling strategy while improving over sota performance.	0
i also found a similar paper on arxiv (submitted for review to ieee transactions on pattern analysis and machine intelligence, 2018): m. m. kalayeh, m. shah, training faster by separating modes of variation in batchnormalized models, arxiv 2018. i didn’t took the time to read this paper in details, but the mixture normalization they propose seems quite close to mn.	0
as many of the concerns were related to communication and have been addressed in the most recent draft, i think it is appropriate to move my review upwards.	0
the revisions make this paper quite different from the original, and i am happy to reevaluate on that basisthis is a peculiarity of the iclr open review procedure, but i consider it a strength.	0
review versions of papers often lack polished writing.	0
also i found the literature review is somewhat lacking.	0
i do not know of another paper using a similar proof, but i have not studied the proofs of the most closely related papers prior to doing this review, so i have limited ability to vouch for this paper's technical novelty.	0
cons: 1) the acknowledgement section was left in the review draft, violating anonymous review.	0
pros and cons:  clearly written  clearly motivated  nice review of literature  quite incremental (close to pathsgd / weight normalization), and missing actual comparison with weight normalization, which seems to be the direct competitor of enorm (see detailed comments)  some flaws in the experimental setup (see detailed comments), particularly in the fullyconnected experiment.	0
in my review i have listed several areas for improvement, but as mentioned, overall i think this is a solid paper.	0
"i give several references below, but i think the authors can include even more studies  there are several studies around ""zeroresource"" speech processing, and i would encourage the authors to work through the review papers [1, 6]."	0
due to the complexity of the algorithm and lack of access to authors code at review time, it is not feasible for me to validate empirical results.	0
'' review score incremented following discussion below '' strengths: well written and clear paper intuition is strong: not all sourcetarget class pairs are as beneficial to find adversarial examples for weaknesses: cost matrices choices feel a bit arbitrary in experiments cifar experiments still use very small normballs the submission builds on seminal work by dalvi et al. (2004), which studied costsensitive adversaries in the context of spam detection.	2
strengths:  substantial number of experiments (6 datasets), different domains  surprisingly simple methodological fix  substantial literature review  it has been argued that charlevel / pixellevel rnns present somewhat artificial tasks — even better that the authors test for a more realistic rnn application (reading comprehension) with an actually previously published model.	2
i am not giving too much weight to this issue in my review score since (unfortunately) the iclr reviewer guidelines do not explicitly mention code sharing as a criterion, but i strongly hope the authors will consider it.	0
“method more greatly resembles the original data than other ganbased methods” method does not resemble data  “due to their exact latentvariable inference, these architectures may also provide a useful direction for developing generative models to explore latentspaces of data for generating datasets for psychophysical experiments.” this is mentioned a few times, but never supported  acknowledgements should not be in the review version (can violate anonymity) 5) minor: why is a gaussian around the midpoint used for interpolations?	0
typo: conditionnning > conditioning  i would be inclined to boost the score up to 7 if the authors include some quantitative results along with more thorough comparisons to fader networks '''''''''''' revision ''''''''''' the authors' updates include further quantitative comparisons to fader networks and ablation studies for the different types of losses, addressing the concerns i had in the review.	0
interpretability is highlighted in the abstract and introduction as an important feature of the proposed approach but the evaluation of interpretability is limited to a few anecdotes from the authors’ review of the results.	0
my biggest concern with this paper is the lack of significant literature review, and that it is not placed in the context of previous work.	0
review  although improving optimization methods is certainly important for the machine learning community, the reviewer have strong concerns about this paper.	0
the review also have several concerns aout the correctness of the proposed arguments.	0
my biggest remaining concerns are with points (2) and (6) from my original review.	0
(5), (6) in my review i provided specific, objective criteria by which i have assessed the novelty of this paper: the lack of original written material, and the nearly identical experiments to the dice paper.	0
also variability of concerns raised by other reviewers does not motivate acceptance.	0
i should note — this reviewer lacks confidence in his review in so far as they have next to zero experience with dnns.	0
reviewer believes authors have a good line of research, but that it requires additional literature review and experiments before it is ready for publication.	0
reviewer encourages authors to continue this line of research, but carefully consider the feedback given to make the work stronger before publication.	0
however, my main concerns are: (1) the novelty of the main theorems given the literature, and (2) the carefulness of stating what is known in the literature review.	0
(') previous reviewers have already made this point  i think it’s crucial  and it’s also related to the previous concern: it is not clear how difficult the tasks facing these agents actually are, nor is it clear that solving them genuinely requires causal understanding.	0
easier to read if the figure appears as the paper reads / p7 equation 11 [0, 1]^m ''''''''' updated review ''''''''''''' based on the issues raised from other reviewers and rebuttal from authors, i started to share some of the concerns on applicability of thm 1 in obtaining information on low k fourier coefficients.	0
[end of standard review] [detailed comments] ''''technical concerns'''' notationwise, i would strongly encourage incorporating the dependence on network width into your notation, at the very least throughout the appendix.	0
postrebuttal update: the review process has identified several issues such as missing citations and lack of clarity with respect to aims of the paper.	0
major concerns: 1, as said in related work, a soft version of this paper’s method has been proposed in the previous work, and the major seems to be that there is no initialization in the previous work which only leads to local convergence.	0
so, the overall the paper has some new ideas, but is not highly novel compared to previous work.	0
(ii) the idea of reaching as many states as possible has been explored in count based visitation (bellemare et al, tang et al) — but no comparisons have been made to any previous work.	0
i understand that some previous work such as the cited [weinshall et.all 2018] also used the same setting: however it does not mean such settings give 'clear and convincing' results of whether cl plays significant role in training dnn.	0
this idea is not novel but the authors report that there is no previous work that jointly trains sentiment aware embeddings with a sentiment classifier specifically, and makes use of an unlabeled corpus to improve both.	0
the paper is lacking in clarity only when discussing some results/concepts from previous work (see detailed comments below). '	0
they do a very solid exposition of previous work, and one of the strengths of this paper comes in presenting their findings in the context of previously discovered adversarial attacks, in particular that of the spheres data set.	2
pros importance of the issue exposition and relation to previous work experimental results (although these were for smaller data sets) appendices really helped aid the understanding cons real world usefulness clarity	2
i have several questions: one concern that i have is the relationship/difference between this work and previous work on style transfer, especially universal/zeroshot style transfer as in [1,2].	0
however this has been done by a number of authors:  vlachos and clark (2014): http://www.aclweb.org/anthology/q141042  berant and liang (2015): https://nlp.stanford.edu/pubs/berantliangtacl2015.pdf while the idea of using such oracles for structured prediction tasks in nlp was first proposed by daume iii et al. 2009: https://arxiv.org/abs/0907.0786 furthermore, it has been applied for rnn decoding in nlp, see: https://arxiv.org/abs/1511.06732 apart from this, some further comments:  the subset of sql tackled in this paper is less expressive than what has been done in previous work on atis and geoquery datasets.	0
the learning of edges for each relation, described in section 3.1, is also a straightforward formulation/reuse of previous work (the papers cites velickovic et al. (2018) as an example), and i do not exactly what is novel here: velickovic et al. use the same equation to predict coefficients, as claimed in the paper, but how is this different from learning a weight for all edges as in eq. 7?	0
i understand that many of the thresholds were inherited from previous work, but it would nevertheless help if the authors showed some example adversarial images to help baseline this figure.	0
their implementation of ewc seems suboptimal as it is only applied to fully connected layers, and thus the ewc baseline performs much poorly than what are reported in many of the previous work, and performs comparable to pgd.	0
strengths: ' quality of the paper, although some points need to clarified and expanded a bit more (see #2) ' nice diversity of experiments, datasets and tasks that the method is tested on (see #4) weaknesses: ' the paper do not present substantial novelty compared to previous work (see #3) # 2. clarity and motivation the paper is in general clear and well motivated, however there are few points that need to be improved: ' how is the importance mask (eq. 1) is defined?	2
my main concern is that some of the contributions claimed were already shown in previous work (see method 1 below for details), and the novelty feels a bit limited.	0
i think a higher score is justified if the authors address the following points:  relation to previous work, originality in contrast to what the authors claim, what is predicted here is not exactly the reaction mechanism, but an implementation of the principle of minimal chemical distance, which was already described by ugi and coworkers in 1980 [see jochum, gasteiger, ugi, the principle of minimum chemical distance angew.	0
"while a good general approach, it is not new (exactly the same general approach that was used in the ""discrete autoencoders for sequence models"" [1] paper, https://arxiv.org/abs/1801.09797, for generating diverse translations, which is not cited directly but a followup work is cited, though without mentioning that a previous work has tackled the same problem)."	0
"the performance of the proposed method is worse than the previous work but they claimed ""stateoftheart"" results."	0
each piece of the algorithm seems to draw heavily on previous work; biclustering, diffusion maps, but overall the idea is novel enough.	0
even leaving aside the previous concern, it seems very difficult to put this work in the context of previous work on the same tasks.	0
summary: this is a simple and intuitively appealing idea, but i find the evaluation to be quite lacking because the tasks already use a language specification (such that actrce seems to be vanilla her in application) and there are no comparisons to previous work.	0
i understand that some of the previous work might have done that, but this application scenario is quite limited.	0
in particular, the paper's contributions and novelty compared with previous work seem limited, and no author response was provided to address this concern.	0
the authors say they use a setup similar to previous work by mcmahan et al. (2017), but it seems like that paper uses a model with a much lower error rate (less than 1% based on a cursory inspection), which makes direct comparisons difficult. '	0
all in all, the paper presents a method that is simple while having potential for impact but needs to frame it more in the context of previous work.	0
a previous work: icarl: incremental classifier and representation learning, rebuffi et al. 2017, gives way to select representative samples.	0
however, the novelty of the method is a concern given the previous work of fan et al. (2017), and the manuscript is not upfront about the differences between the two works.	0
detailed comments: 1. i have concerns about the novelty of the paper: it builds heavily upon previous work on modeling sgd as a stochastic differential equation to understand its noise characteristics.	0
cons:  it is still difficult to believe that most of the previous work and previous experiments (as in zhu & gupta 2018) are faulty.	0
"technically however i take issue with the framing of previous work in the last paragraph of the ""deep neural nets"" subsection of section 2. technically achille & soatto explicitly formed a variational approximation to the posterior over the weights of the neural network and so was not a ""single bottleneck layer"" as stated in the paper."	0
for example in section 5, the claim of “cnns learn semantics from images” is mainly proposed in a previous work, but the way of presentation sounds like this is a contribution of this work.	0
the extension of the previous work is trivial and the combination of the two ideas lack of any motivation.	0
in summary: pros  new extension of capsule networks, tackling a more challenging problem than previous work cons  novelty is incremental  paper lacks clarity and is hard to read  results are underwhelming for these reasons, i'm afraid i can't recommend this paper be accepted.	2
using this for universal attack is interesting, however the experiments are not that convincing: 1. to show this is a good way for universal attack, i think the authors should compare with previous work in (moosavidezfooli et al).	0
the overall approach closely follows merrer et al. (2017), but extends this previous work to multibit watermarking.	0
this idea is basically similar to nested pitmanyor language models (mochihashi et al. 2009) and twostage language models (goldwater et al. 2011), but the authors seem not to notice these previous work.	0
pros:  sizable improvement on imagenet1k benchmark relative to previous work.	2
results are particularly good on 1shot miniimagenet classification, but may not be entirely comparable with previous work.	0
the algorithmic machinery in the paper is poorly justified, as it is presented as a series of steps without providing much intuition why these steps are useful (especially compared to previous works).	0
in summary, it is unclear to me if there is any novelty in the approach (missing references, lack of motivation of the algorithm) and if the results show any improvement over previous works (only one previous work has been compared and the qualitative examples do not show anything particularly interesting).	0
weaknesses: ' the paper do not present substantial novelty compared to previous work.	0
in fact, this paper reads a lot like a more elaborated (or incremental) version of the preliminary paper of sogaard et al. (acl 2018), with the paper structure and some descriptions borrowed from the previous work (e.g., the focus on the muse algorithm, the description of kisospectrality), with two main enhancements compared to the prior work: 1) the introduction of procrustes fit as a means to diagnose and anticipate (im)possibility of unsupervised embedding learning.	0
i might miss something, but it seems totally possible to me that some semantic information will shift to f rather than to m, because f has access to the whole input, and that's why previous work used a categorial vector.	0
one concern i had was that improvement in performance was due to working with 224 x 224 images in this paper (rather than resized 84 x 84 images as most previous work does with miniimagenet); however, additional comparison was performed with learning to compare where that model also uses 224 x 224 images but there was no improvement there just by using larger image input, thus establishing that larger image input is not a reason for the improved performance.	0
1) matching real and fake with postprocessing by an additive noise model is attained when the real and fake distributions are the same (thus there is a priori no need to anneal the noise like in previous work), however while a necessary condition for pr = pg, it is not sufficient.	0
edit: however, the current manuscript lacks a proper comparison with (cited) previous work, such as 1806.08047.	0
pros:  well written and interesting  good experiments, results, and analysis cons:  perhaps slightly more similar to previous work than is argued update after author response: thanks for your response; i think the revised paper largely addresses my comments and those of the other reviewers, and i continue to hope it is accepted.	2
originality: 3.5/5 as the empowerment subroutine is existing work, as is airl, combining previous work, but effectively.	0
pros:  extension of airl which utilizes empowerment to advance the soe in reward learning  well written, related previous work well explained.	2
strengths:  motivation: the natural extension of previous work on differentiable plasticity based on existing knowledge from neuro science is an important next step  cue reward experiment exemplifies limitations of current plasticity approaches and clearly shows the potential benefits of neuro modulation  maze navigation shows incremental benefits over nonmodulated plasticity  thorough experimentation  clippingtrick is a neat observation weaknesses:  evaluation: only on toy tasks (which includes ptb), no real world tasks  very incremental improvements on ptb over a very simple baseline (far from sota)  evaluated models (feedforward nns and lstms) are very basic and far from current sota architectures  no qualitative analysis on how modulation is actually use by the systems.	2
compressability is evaluated, but that was already present in the previous work.	0
ultimately, i think the idea is a nice generalization of previous work, and the experiments seem to indicate that the model is effective, but the limited scope of the experiments prevent me from being entirely convinced.	0
closely related previous work (neyshabur 2017) scaled to 128x128 resolution on a much more difficult dataset  imagenet dogs but the authors did not compare in this case.	0
pros:  the work provides a clear overview of previous work on approaches using multiple discriminators.	2
the abstracts and introduction promising for a novel hierarchical clustering algorithm, but i can only understand that they are using an agglomerative algorithm with the intercluster similarity of eq. 10. they show that their similarity metric reduces to the previous work by setting .pi = p or uniform.	0
"closely related to ""neural processes"" work, but this happened roughly at the same time  significance: the fewshot learning results are competitive, in particular given they use a simpler model setup than most previous work."	0
"pros: ' the problem is interesting and well explained ' the proposed method is clearly motivated ' the proposal looks theoretically solid cons: ' it is unclear to me whether the ""efficient method for sn in convolutional nets"" is more efficient than the power iteration algorithm employed in previous work, such as miyato et al. 2018, which also used sn in conv nets with different strides."	2
if the results were significantly different from previous work, these differences would indeed be interesting to discuss, but they didn't seem to change much vs. previously published work.	0
my biggest concern with this paper is the lack of significant literature review, and that it is not placed in the context of previous work.	0
strengths: ' nice extensive experimentation on video prediction and early activity recognition tasks and comparison with recent papers ' each choice in the model definition are motivated, although some clarity is still missing (see below) weaknesses: ' novelty: the proposed model is a small extension of a previous work (wang et al., 2017) # 2. clarity and motivation in general, the paper is clear and general motivation makes sense, however some points need to be improved with further discussion and motivation: a) page 2 “unlike the conventional memory transition function, it learns the size of temporal interactions.	2
nevertheless there is value in novel results that may follow from previous works in a straightforward but nontrivial fashion, as long as it is wellpresented and thoroughly researched and implication wellhighlighted.	0
pros:  the authors consider an interesting problem of learning from complementary labels  they propose an approach that, assuming that the complementary label is selected uniformly at random, provides an unbiased estimate for any loss function, which is an improvement over the previous work.	2
i have to admit that i'm not familiar with the related work on attention, but i did not understand 'why' the results of the proposed method are supposed to be much better than that of previous work.	0
while rigorous guarantees are lacking for some previous work, previously introduced techniques were shown to be extremely effective in practice and across a spectrum of tasks.	0
(3) the experimental evaluation is against previous work which tried to solve a different problem (black box based attacks).	0
the paper is technically solid and relatively easy to follow and the results are good, but comparisons with previous work (descriptive and experimental) are rather weak.	0
"negative:  unclear novelty: previous work also gives the goal of preserving input meaning in attacks, even if the attacks themselves do not preserve meaning effectively (ie zhao et al)  unclear attack effectiveness: the chrf scores for charswap and knn methods have higher chrf scores than the ""unconstrained"" method, but it is unclear what this means in context."	0
while the work achieves a bound that is superior than a previous work, i personally find the work less inspiring and somewhat incremental.	0
however, it lacks sufficient context with previous work and benchmarking to prove the speedup.	0
important experimental details lack adequate descriptions  tables and figures are not written with adequate details details of negative feedback: major:  unclear baselines and questionable improvement on sota:  previous work (the neural density functions of ostrovski et al or the cts scheme of bellemare et al.) used significantly fewer (~100 million and ~150 million respectively vs ~2 billion) frames of experience in solving montezumas revenge, which makes this method’s benefit somewhat incomparable to previous methods given the sampling regime it operates in.	0
you cite natural gradient methods and lbfgs as two examples, but natural gradient descent involves preconditioning the gradient with the inverse fisher information matrix, and is therefore typically not derivative free.	0
i like the notion of marginalizing over latent tree structures, but the related work section needs to make clear what is being contributed here that is different from the cited past work on this problem  on the mt eval, why are you missing values for zhen on the nmt models that are actually competitive?	0
some of these papers are cited, but only the comparison to ramachadran et.	0
the paper goes to 10 pages but does so by adding redundant information (e.g. the intro is highly redundant) while some important details are missing the paper does not cite, discuss or compare with the related work “synthesizing images of humans in unseen poses”, by g. lalakrishan et al. in cvpr 2018. page.	0
"note: the authors cite a paper in the introduction ""hierarchical attention transfer network for crossdomain sentiment classification"" (li et al 2018) which also achieves state of the art results on the amazon reviews dataset, but do not compare against it."	0
in addition to the above major concerns, the paper does not cite any papers from the vast body of literature on coresets and model compression.	0
"the authors only compare to relatively simple approaches (support vector regression and logistic ordinal regression), yet they cite many previous works in this area but do not compare against them, instead just leaving a pretty generic statement of ""the regression assumption of this method between eeg signals and rt is not correct""; they do not elaborate on this aspect."	0
(b) mitigating unwanted biases with adversarial learning (which the authors cite, but do not offer any comparison or differentiation) to improve the paper, these related work should be discussed in related work section, and (if applicable) compared to the proposed method in the experiments, rather than a very brief mention of one of them in section 3.3 and no comparison.	0
the paragraph after eq 3 needs some rewriting  the explanations around and including equations 5 and 6 were quite poor: .pi is referred to but not used, it is not made clear that that g is the gradient of log p(z) instead of p(z), use brackets for the log in eq 6 to avoid ambiguity 2) the reference formatting is wrong (i.e. cite is used everywhere instead of citep) 3) i thought the motivation for the approach in the intro was very good 4) as the seemingly most related work, it would be good to elaborate more on the goyal et al paper and the differences of your approach to theirs.	0
the submitted paper does cite these papers but does not directly discuss the similarities between them.	0
the authors cite such models in the appendix (melor et al), but claim that “much larger models” are needed, potentially with other mechanisms, such as dropout.	0
for example, when the authors introduce gail, they mention gans and cite goodfellow et al. 2014, but do not cite gail.	0
there is also a lot of good research on behavioral cloning, and where it can go wrong, that the authors mention, but do not cite.	0
in fig. 1 you cite todorov et al. for mujoco but not trpo and acktr, the same in fig. 2. then in fig. 3 you cite ddpg also with todorov et al.  some parts of the text is a bit unorganized.	0
the authors cite many interesting, realistic and practical setups (zhang et al., 2016; jaderberg et al., 2017; mirowski et al., 2017; papoudakis et al., 2018), but do not use any of these setups in their experiments.	0
previous applications of these tests in gans and generative models include bounliphone et al. (iclr 2016, https://arxiv.org/abs/1511.04581 ), lopezpaz and oquab (2016  which you cite without a venue but which was at iclr 2017), sutherland et al. (iclr 2017, https://arxiv.org/abs/1611.04488 ), huang et al. (2018), and more, using a variety of schemes.	0
originality novelty: there is a large body of work on disentanglement that the paper does not cite or compare to for instance, infogan, beta vae https://openreview.net/pdf?id=sy2fzu9gl and disentangled latent concepts https://arxiv.org/pdf/1711.00848.pdf note that for example that in beta vae it is a similar idea where but it is on z and z|x and the distance used is kl (since it is has closed form with gaussian) , min_phi loss beta kl (p(z), p(z|x)), a discussion of the previous related work in the paper is necessary.	0
not sure if there's anything anyone can do about that, but perhaps it would be helpful to briefly cite/compare to some of the shen/zhou work.	0
i don't doubt this, but you should cite some papers, please.	0
(a related paper from overlapping authors to papers you do cite that maybe should have been included is chang et al. https://arxiv.org/abs/1710.00880 – which is a bit different in trying to learn hyponyms from text not wordnet, but still clearly related.)	0
the paper does cite some of these papers (such as those based on synthesized examples) but doesn't provide any comparison.	0
1. comparison with previous methods: the authors cite (bohte 2002) and (lee 2016) as alternate backpropagation schemes, however their performance is not compared.	0
"in addition, there is additional related work that the authors do not cite, but ought to: [1] yarin gal, jiri hron, alex kendall, ""concrete dropout,"" proc."	0
if instead of attempting to comment on networks as they are designed today they aim to proposed a new information bottleneck inspired objective they really ought to directly compare other attempts along those lines (such as the ones they themselves cite alemi et al. 2018, kolchinsky et al. 2017, chalk et al. 2016, achile & soatto 2018, belghazi et al. 2018) but there are no comparative studies.	0
the experiments are extremely lacking, not only are any of their cited alternatives compared, they don't compare to what would be an equivalent network to their but where they did utilize the noise at every layer and actually made the network stochastic.	0
the authors cite the information bottleneck literature, but we shouldn’t need to read all these papers, the main ideas should be summarized here. '	0
there is also work concurrently submitted to this forum (which i obviously don't expect the authors to cite or take into account, but want to mention for the sake of completeness) such as https://openreview.net/forum?id=hyfyn30qt7 which achieves the same or better results, and does not require 8bit bn scale factors and 32bit bias.	0
similar works can be found but missed to cite: [1] proposes a general framework to selfattention to exploit sequential (timedomain) and parallel (featuredomain) nonlocality.	0
the submission makes heavy use of kronecker factorization, but neglects to cite works that use a similar factorization of the covariance matrices for neural network applications (e.g., https://arxiv.org/abs/1503.05671, https://arxiv.org/abs/1712.02390).	0
please double check the references should be updated to reflect the latest information, for example, it might be better to cite the aaai17 version of the optioncritic architectures between mdps and semimdp: a framework for temporal abstraction in reinforcement learning should use the 1999 version 7. minor issues: task it is > task is z^l .in r^{n.times n} howver > however	0
it is worth noting, that critic training was showed to be outperformed by sobolev training in the same paper authors cite, but its performance is not reported despite looking like a well defined baseline.	0
concerning unsupervised domain adaptation, the related work section is not complete, the authors only cite ganin et al. (icml2015) and tzeng et al. (cvpr2017), but the literature is not limited to these two works.	0
if not a direct comparison, this requires at least some discussion, but the current version does not even cite it.	0
sestorain et al. (2018) (https://arxiv.org/abs/1805.10338) also seems like a very relevant reference, but it is not even cited.	0
however, i have two major concerns: (1) there is a very related and uncited paper from icml 18 with a similar name and method: tempered adversarial networks from sajjadi et al., and (2) there is a gap between the theory and practice, in particular the discriminator should depend on the noise being added and vary for different noise types.	0
the authors' cite recent works on metalearning that take into account uncertainty in the local latent variables (e.g., grant et al. (2018), finn et al. (2018), kim et al. (2018)), but do not compare to these methods.	0
the authors could convince me that i'm mistaken by pointing out closely related iclr papers (e.g. with a similar mix of techniques in their methods, or similarly proposing a handdesigned performance metric); as far as i can tell, none of the papers cited in the references are from iclr, but rather from e.g. nips, aistats, and ieee tpami, which i believe would be better fits for this kind of work.	0
3. experiments: the authors cite the hierarchical attention transfer work of li et al (https://www.aaai.org/ocs/index.php/aaai/aaai18/paper/download/16873/16149) and claim their approach is better, but do not compare with them in the experiments.	0
the authors cite this paper but do not compare against it, which should to be rectified.	0
pros:  a work in an area with very view contributions and a certain lack of theoretical results theoretical results that are actually used in the algorithmic implementation and that allow to define the regularisation parameter based on the size of the available samples improved empirical results 'cons: an incomplete stateoftheart section that does not cite several important contributions on the subject; lack of baselines due to the incomplete stateoftheart section; lack of clear comparison with lipton et al. both in terms of the proposed method and the obtained theoretical guarantees.                  	2
with respect to the third proprietary diabetes dataset, the costs are real and relevant, however there discussion of these are given except to say that you had a single person familiar with medical billing create them for you (also the web address you cite is a general address and does not go to the dataset you are using).	0
for example in theorem 2 the authors do cite klusowski and barron in the beginning of section but not in the theorem header.	0
2017. typos/suggested grammar edits: “skills learned through (deep) reinforcement learning often generalizes poorly across tasks and retraining is necessary when presented with a new task.” —> often generalize poorly “we present a framework that combines techniques in formal methods with reinforcement learning (rl) that allows for convenient specification of complex temporal dependent tasks with logical expressions and construction of new skills from existing ones with no additional exploration.” —> sentence kind of difficult to parse and is a runon “policies learned using reinforcement learning aim to maximize the given reward function and is often difficult to transfer to other problem domains.” —> ..and are often.. “by authors of (todorov, 2009) and (da silva et al., 2009)” —> by todorov (2009) and da silva et al. (2009) also several other places where you can use .citet instead of .cite	0
thus this work connects to many areas both in noisy learning, as they cite heavily, but also in methods (in e.g. crowdsourcing and multisource weak supervision) where several sources label unlabeled datasets with unknown accuracies (which are often estimated in an unsupervised fashion).	0
(a short discussion in the paper on this topic would be good as well) and finally some suggestions for small improvements:  please try to find another name than “target” network since it is already widely used in the deep rl literature for something completely different (suggestions: “random”, “distillation”, “feature”, “reference”)  in 2.1 (last paragraph) there are various papers cited regarding forward or inverse dynamics, but several of them contain both, while the way they are cited suggests they deal only with one.	0
some papers which could be cited are (1) unsupervised perceptual rewards (though it uses alexnet pretrained), (2) time contrastive networks (which also uses alexnet and doesn't really work on singleview tasks but is a good citation to add), (3) original uvfa (definitely has to be there given you even use the abbreviation for the keywords description of the paper) 7. some slightly incorrect facts/wording in the paper: the two papers cited in modelbased methods (oh and chiappa) are not really unsupervised.	0
it is similar to cited work by nash et al., however both works are concurrent and so far unpublished and should be considered as complementary point of views on the same problem.	0
i like the notion of marginalizing over latent tree structures, but the related work section needs to make clear what is being contributed here that is different from the cited past work on this problem  on the mt eval, why are you missing values for zhen on the nmt models that are actually competitive?	0
some of these papers are cited, but only the comparison to ramachadran et.	0
in particular i'd like more positioning wrt what is proposed by the work of petrik&all (https://papers.nips.cc/paper/6294safepolicyimprovementbyminimizingrobustbaselineregret.pdf the paper is cited but the first author is incorrect).	0
i understand that some previous work such as the cited [weinshall et.all 2018] also used the same setting: however it does not mean such settings give 'clear and convincing' results of whether cl plays significant role in training dnn.	0
the application of 3d convlstms to video might be new, but the mentioned paper by choy et al. (2016) should be cited.	0
"minor points: the reference entitled ""a proposal on machine learning via dynamical systems"" would be better cited not as ""e (2017)"" but rather as ""weinan (2017)""."	0
eslami et al. 2018 have been cited, but some very important and related earlier works like: [1] kulkarni et al. 2015, deep convolutional inverse graphics network [2] cheung et al. 2015, discovering hidden factors of variation in deep networks were not discussed at all.	0
also, the literature review has been done very lightly: chen et al. 2017b (and most cited above) do 'not' assume a single byzantine agent as said in the paper, but assume up to <50% malicious (potentially colluding) agents.	0
pros: i was very excited by the ideas in section 5, this work is the first to my knowledge to attempt at interpreting poisoning attacks.	2
the key idea in this paper (using principal shared directions of perturbations, computed on a small subset of data points) has unfortunately already been proposed and tested in classical (nonequivariant) neural networks  see for example fig 9 in moosavidezfooli, 2017, cited in the paper, and published in cvpr 2017. the present paper proposes however a few additional bits of information with a nice theoretical analysis, while the previous works were mostly based on heuristics.	0
"while a good general approach, it is not new (exactly the same general approach that was used in the ""discrete autoencoders for sequence models"" [1] paper, https://arxiv.org/abs/1801.09797, for generating diverse translations, which is not cited directly but a followup work is cited, though without mentioning that a previous work has tackled the same problem)."	0
li et al 2016 was cited but not tested, and gilmer et al 2017 and veličković et al 2017 weren't cited or tested), but there's a reasonable chance they'd outperform the treetransformer.	0
given the approach is based on dynamically adding parameters or modules, progressive networks and dynamically expandable networks (both cited) are especially relevant and should be compared (i believe the former may be related to the “adapter” baseline, but this should be made explicit).	0
i’ve seen work using a reducedmnist dataset, which is probably created by random subsampling, but still more relevant than many of the aspects of embeddings cited in this section (the paragraph about arithmetic operations for instance).	0
for instance, in table 2 there is a footnote that leads nowhere, “introduced in sif” is cited incorrectly, “in recent times jet (2014)” is cited incorrectly, and the figures are grainy (this isn’t really an error, but do try to make figures crisp in the future, e.g. with pdf images).	0
"i would recommend:  ""derivable"" i guess you mean ""differentiable""  oliphant and hunter are cited for numpy/scipy and matplotlib but the reference to pedregosa et al. for sklearn is missing."	0
you cited some of stanley's talks on openendedness, but i wonder if you considered their work [1] where they proposed that having a minimum criteria condition might encourage diversity of solutions.	0
to be clear, both of these past works (and several similar ones) are of course cited by the current paper, but from a practical standpoint it's just not clear to me what the takeaways should be here above and beyond this past work, other than the fact that these quantities _also_ bound the relevant rkhs norms.	0
moreover, [3] related the input jacobian to generalization, finding a similar result, but is not discussed or cited.	0
i will list the issues and some suggestions i have, in order to help make this work better, hopefully good enough for acceptance: 1) the authors cited [1] a few times in the paper, but actually their approach of using a vae to compress frames into a latent, an lstm to predict the next latent, and a cmaes trained network for the policy is precisely what is proposed in [1] (which had experiments that trained on the actual environment, like in this work, and also the generated environment).	0
the experiments are extremely lacking, not only are any of their cited alternatives compared, they don't compare to what would be an equivalent network to their but where they did utilize the noise at every layer and actually made the network stochastic.	0
papers have been cited in related works but differentiation in terms of what the current method adds is largely missing.	0
pros:  theoretical guarantees, elegant approach  good empirical results compared to other models  desirable properties: rotationequivariance, lower computational complexity, fewer parameters, robustness and guaranteed stability to deformations cons:  somewhat incremental technical novelty: combination of two previously published methods (qiu et al. 2018 & weiler et al. 2017) comments: 1. i believe the related work section can be improved by explaining more clearly the connection between your work and the cited ones and emphasizing the advantages and limitations of rotdcf compared to other methods in particular, a reader should be able to precisely understand what is the novelty of this work is and what were the technical challenges in combining previously published ideas (such as dcf and sfcnn) 2. how do you determine the truncation in practice?	2
cons:  the core contribution is a special case of previously published more general framework which is not cited in the paper.	0
the knowledge bases used should be at least cited, i know that freebase and wordnet are wellknown but somewhere, in the description of the test, the name should be included.	0
that being said, this does not invalidate the method, but the algorithm justification deserves a better justification there is a serious lack of rigor in the bibliography:  many peerreviewed publications are cited just as arxiv preprints  when present, there is no consistency in publication names.	0
another publication by zou & lerman, 'graph convolutional neural networks via scattering', is also cited as an inspiration, but here the differences are larger in my understanding and do not necessitate further justification.	0
moreover, in spite of the authors writing that their goal is “completely different” from [lee at al 18a, ma et al 18a], i found the two cited papers having a similar intent and approach to the problem, but a comparison is completely missing.	0
sestorain et al. (2018) (https://arxiv.org/abs/1805.10338) also seems like a very relevant reference, but it is not even cited.	0
pros:  method is fairly straightforward  modeling relationships between labels is an important problem cons:  missing references to key prior work in this space  minimal comparison to prior work  confusing experimental setup  paper is difficult to read missing references this paper is far from the first to consider the use of a semantic hierarchy to improve classification systems; see for example: deng et al, “hedging your bets: optimizing accuracyspecificity tradeoffs in large scale visual recognition”, cvpr 2012 deng et al, “largescale object classification using label relation graphs”, eccv 2014 (best paper) jiang et al, “exploiting feature and class relationships in video categorization with regularized deep neural networks”, tpami 2017 none of these are cited in the submission.	2
while the derivation differs, the motivation and final form of the updates seem to have a large overlap but this work is not cited.	0
"'detailed comments'' _paper strengths_  the idea to use a negative video example for unsupervised detection learning seems novel  the proposed method is simple and the needed data can be collected with widely available equipments  the paper addresses the problem of being robust with respect to moving distractor objects for cases in which those are present in both the positive and negative video example  the authors collected realworld data from different scenes with different objects, object counts and conditions (indoor/outdoor, still/moving camera)  the authors compare to a number of nonlearning approaches from opensource implementations (the reviewer cannot judge whether any relevant technique is missing)  the authors provide anonymized links to videos demonstrating a representative sample of the algorithm's performance on the considered scenes _paper weaknesses_  the authors clearly reduced the horizontal margins of the standard iclr style template leading to a wider text corpus, however, as the bottom margin seems to be increased the reviewer will review the paper nevertheless, but requires the authors to revert to the standard iclr style template upon update of their manuscript  the paper makes the relatively strong assumption that we have a video of the object of interest moving in the scene we plan to employ our algorithm on along with another video of the same scene with all relevant distractor objects but without the object of interest; given these assumptions the reviewer struggles to see a meaningful application of the approach (the only one provided by the authors, as tool for automated demonstration annotation, is not convincing, see below) that is outside of a very controlled setting in which more classic, e.g. makerbased approaches could be employed for detecting the object  the claimed robustness of the algorithm only holds for variations that were extensively present during training time (e.g. lighting differences on the car), in contrast the algorithm seems to be very sensitive to partial occlusion (as can be seen in the multiobject examples) and seems to heavily overfit on the color of objects (e.g. the car generalization to the new scene is easy as the car is the only red object in the scene, once the car moves away from the camera and the red front part is selfoccluded the detection fails, see e.g. minutes 1:15, 1:26 in the transfer video)  other than the single transfer example mentioned in the previous point the authors do not prove generalization to more challenging nontraining scenes with heavier clutter, nonseen lighting changes and occlusions to support their robustness claim  the proposed method cannot operate inthewild (e.g. youtube data) as it makes very strong assumptions about the required input data  the fact that the method needs to be trained from scratch for each new scene and object reduces the number of possible applications/scalability and makes comparison to classic baselines unfair which are not specifically tuned towards a certain object or scene  the authors make no comparison to other unsupervised detection approaches (e.g. to the selfcited jonschkowski et al. (2017)) to prove shortcomings of other methods on the newly generated dataset  as mentioned by the authors the method does not use any temporal information for the detection which surely could help, the reviewer cannot follow this design decision, especially because the fact that the encoder gets the difference image to the previous video frame as input in case of a moving camera (for egomotion estimation) makes applications to nonvideo data impossible, also none of the experiments exploit the nontemporal property of the approach to show single frame detection on a more varied set of scenes  the experiment showcasing the proposed application to ""learning from demonstration"" is not convincing as the method is only used to detect the goal location of the object but, critically, treats every object in the scene separately, missing any relational information in the target configuration, therefore in case of the sorting in a vertical line task the learned goal representation does not represent the actual goal of the task  the authors do not provide ablation studies proving the necessity of all three proposed objectives (slowness, variability, presence)  the reviewer cannot follow the references to objectcentric representation learning that are made in the paper, specifically because (as also noted by the authors themselves) the proposed method makes substantially stronger assumptions with respect to the input data and merely learns to detect the spatial coordinates of a single given object in a scene as opposed to learning an objectcentric scene representation that can be useful for downstream tasks, therefore the reviewer would strongly suggest to tone down the scope of the presented work, especially in the first paragraph of the introduction and the last paragraph of the conclusion  the ""random search optimization"" discussed in section 3.3 is not a valid method as it ""solves"" this problem of instable training by picking the best of n runs with varying random seeds  figure 2 is not very helpful for understanding, the details of the architecture (left part) could go to the appendix and be replaced with a figure that details the intended usage of the method for a concrete application to strengthen the motivation of the approach _reproducibility_  given the architectural information provided in the paper the reviewer believes it would be relatively straight forward to reproduce the results of the work.                  "	2
edit: however, the current manuscript lacks a proper comparison with (cited) previous work, such as 1806.08047.	0
second, learning a mapping from attributes to classifier weights have already been proposed but not cited or discussed at all.	0
the authors could convince me that i'm mistaken by pointing out closely related iclr papers (e.g. with a similar mix of techniques in their methods, or similarly proposing a handdesigned performance metric); as far as i can tell, none of the papers cited in the references are from iclr, but rather from e.g. nips, aistats, and ieee tpami, which i believe would be better fits for this kind of work.	0
previous work (none of which is cited) has dealt with unsupervised option discovery in the context of mutual information maximization (variational intrinsic control, diversity is all you need, etc), but they do so in the absence of reward, unlike this paper.	0
i am not an expert in this area, so i do not know what the appropriate references would be, but only one reference about mi is cited.	0
clarity: 7/10 results are clearly presented, although more intuition and context would be helpful, and some sections are not well explained or contextualized originality: 2/10 the methods are not novel, to my knowledge, and there is little exploration or insight given for the extensive experimental results significance: 7/10 measuring and reporting results is valuable, and the reported results are interesting pros:  interesting results, good plots  overall well structured and explained cons:  plots could use more explanation and interpretation in the captions, and more investigation and insight from the experiments  some sections are not clearly worded and i think the objective/interpretation of the experiments would not be clear to someone even a little unfamiliar with the approaches cited specific comments/nits (in order reading through paper): 1. first paragraph of intro is kind of fluff/unnecessary.	2
some cited paper are published paper but cited as arxiv paper.	0
"perhaps i missed it, but i believe dan ciresan's paper ""multicolumn deep neural networks for image classification"" should be cited."	0
[xu et al., 2017] presents a ganlike setup that targets exactly the same goal, but that work is not cited in the paper.	0
same for [zhang et al., 2018], but the latter work is rather recent (it still should probably be cited).	0
i noticed several things:  there are numerous places in the text that lack proper citation, or are cited improperly.	0
i am guessing that it is the corresponding gae hyperparameter, but i am not sure as the gae method is never written about or cited throughout the paper.	0
(a short discussion in the paper on this topic would be good as well) and finally some suggestions for small improvements:  please try to find another name than “target” network since it is already widely used in the deep rl literature for something completely different (suggestions: “random”, “distillation”, “feature”, “reference”)  in 2.1 (last paragraph) there are various papers cited regarding forward or inverse dynamics, but several of them contain both, while the way they are cited suggests they deal only with one.	0
1) the authors cited the relevant literature, but there is no comparison with any of these related works.	0
some papers which could be cited are (1) unsupervised perceptual rewards (though it uses alexnet pretrained), (2) time contrastive networks (which also uses alexnet and doesn't really work on singleview tasks but is a good citation to add), (3) original uvfa (definitely has to be there given you even use the abbreviation for the keywords description of the paper) 7. some slightly incorrect facts/wording in the paper: the two papers cited in modelbased methods (oh and chiappa) are not really unsupervised.	0
a major concern of this work is the lack of citation and direct comparison to multiple previous sotas.	0
last but not least, please use more clear citation formats: currently quite a few citations are missing of publishing venues such as fan et.al 2018 and furlanello et.al 2018.	0
the paper is clearly written, but some claims in the text are not supported by any citations (e.g. §1¶2 “more recently, several papers have shown that forward modelling…” without a citation).	0
i understand that this follows by the citation, but still an explanation is needed.	0
3: the notation for the number of relations is not optimal: should be rather rephrased as ' is a matrix of the following dimensions'  the bibliography needs to be updated: there are some inconsistencies with respect to capitalization (such as in journal titles); also, at least the citation of kipf & welling should be adjusted as it is 'not' a preprint any more but was published in iclr 2017  p.	0
the golebiewski bib entry is lacking any information as to where it is published, which seems especially bad for the key citation to prior work of the whole paper.	0
that can be fine (some would argue it’s a good thing), but there seem to be some opinions without citations/backing, i suggest trying to back up statements wherever possible and avoid opinions.	0
“since the environment behavior function is unknown, it is treated as blackbox and hence the gradients have to be computed using reinforce (williams, 1992) which is quite sample inefficient.” —> citation/backing?	0
i am sorry for the sarcasm, but it was really frustrating to see not only the lack of citation, but also the statement (already in the abstract and throughout the paper) that an fscore of 46.9 set a sota for unsupervised parsing with wsj penntreebank.	0
minor issues:  the lack of parenthesis around citations makes the text hard to follow at times (maybe use .citep whenever the citation mixes with the text?	0
it is also unclear to me why “fake papers” are needed for the citation networks; it is clear that “fake author lists” are needed for negative sampling, but it seems they could be attached to existing papers.	0
minor comments:  p1: analogically > just drop the word  p1: citation of brin & page > this seems a bit out of place  yes, it is a method working on graphs, but it is not relevant in the context of the paper  to the best of my knowledge there are no neural networks in this.	0
the one question i have regarding your results is the following: you include the average reward for the citationfield extraction task in your results table, but don’t seem to comment on this anywhere.	0
pros  considering correlations between features from different encoder layers is a good idea  the improved encoder / decoder architecture is significantly more efficient than the cascaded approach of [li et al, nips 2017] cons  somewhat incremental  limited experimental evaluation  qualitative results not clearly better than existing methods  missing citation for multiscale losses limited experimental evaluation one of the key claims of the paper is that “our method with interscale (fig.7(f)) or intrascale feature transform (fig.7(g)) are more similar to the target style than those of singlescale style transfer without considering interchannel correlation” (figure 7 caption); this claim is substantiated primarily by qualitative results in figures 4, 7, and 8. personally i don’t find the results with interfeature correlations to be much better than those with only intrafeature correlations or the results from prior work.	2
overall the literature review is reasonably solid, but i am not sure the citations in the opening sentence are quite appropriate as modelbased drl has been around for longer than 2017 (see for example [13]).	0
minor concerns:  “such as crfs or iterative evaluation” i would include a citation on this type of work.	0
without stronger comparison to other closely related work, and lack of citation to several closely related models, the claim of novelty isn't defined well enough to be useful.	0
i am completely sure there are obvious connections i'm missing, but these should provide some entry points into the citation web.'	0
also add citation (wang et al., 2017) since it ie the same model of that paper  # postdiscussion i increased my rating: even if novelty is not high, the results support the incremental ideas proposed by the authors.	0
cons ' much of paper revises the dice estimator results, arguing for and explaining again those results rather than referring to them as a citation. '	2
mmd lacks citation (e.g. [2]).	0
i noticed several things:  there are numerous places in the text that lack proper citation, or are cited improperly.	0
i feel this paper could be made much stronger by carefully using the results of all this prior work; these are not merely citation omissions, but indeed there is good understanding and progress in these papers.	0
the theoretical work is related to linear regression and gaussian mixture model but the experiments are relayed to deep neural nets!	0
(c.f point 2. of the decision section) i think that it is important to emphasize that in your work c_k are randomly sampled and then fixed (it is much more clear in [15], but i do not think that the reader should know the related work to realize that).	0
a symptomatic example of the lack of paper positioning is the related works section which does not even give a single reference !	0
weaknesses: 1. related work: the paper needs to cite and mention a much more broader literature.	0
the authors listed the difference from (glimer et al. 2017) and (li et al. 2017) in table 1, but ignored (pham et al. 2017) and (battaglia et al. 2018), which were also cited in the related work.	0
with respect to related work, i'm missing 'attentionbased deep multiple instance learning', by ilse et al. i'm not certain if it could be applied to the reconstruction task, but it seems that it should be a baseline for the classification task.	0
the paper severely lacks in relation to relevant related work.	0
the concepts are easy to follow, the related work covers a lot of different but related domains.	0
another issue is that there is no comparison to other representation learning techniques (like those mentioned in the related work section, or the recent 'unsupervised state representation learning in atari'), nor to a natural and more straightforward variant of the proposed method where z would simply be sampled from a (learned) gaussian distribution z ~ n(mu(x), var(x)), which at first sight seems like an easiertooptimize objective (using the reparameterization trick)… i may be wrong, but then this should probably be explained in the paper (i realize that the proposed approach is more general, but then it should be shown how this extra flexibility can lead to improved results).	0
weaknesses of the paper:  the related work section could be greatly improved, thereby showing the limited novelty of the proposed method (qgan).	0
i am not very familiar with the related work but this seems to be sufficient number of baselines to assess the effectiveness of the approach.	0
additionally, in table 1 the method is compared with weak baselines (no da, flip, crop, but not the combination of flip and crop which is standard on cifar10) and it is not compared with any other approach (and there are several as shown in related work).	0
similarly, the proposed method is simple and intuitive (which is good), but it will help if there were more comparisons to set the paper in context of related work.	0
here are a few random remarks: about related work, 'balancing the objective and diversity' is also the central concern of qualitydiversity (qd) algorithms (see e.g. cully&demiris for a survey). '	0
this paper should be rejected because (1) this method only combines existing techs, such as stochastic generative hashing (eq.1 and eq. 6), and lacks novelty; (2) lack of introduction to related work and baselines, (3) the experiments results can not support the claim, i.e. the effectiveness of cgh in marketing area, and (4) paper writing is awful and very hard to follow.	0
a lack of many relevant citations indicates that the authors are not familiar with the related work done in this field over the past three years.	0
there has been already many works on variants of lstm, such as sru, fastgrnn, clockwork rnn and etc. but none of them are employed as the baseline model, or even mentioned in the related work.	0
but the most serious problem with this paper is a lack of references to related work.	0
there is no related work on background classification (or 'context' classification); but i am sure that there might be works on this.	0
in addition to the above, other minor weaknesses of the paper includes typos, poor experimental practices, missing citations and related work, and other wording issues.	0
there are also some less critical, but still important aspects of the paper (related work, clarity of explanations, repetitiveness) which lead me to decide this paper is not currently ready for publication.	0
one of my main concerns, however, is that robustifying d in gan training is not a new idea for some readers [1], so they need more clarification on the novelty of the proposed method, e.g. by discussing about it in related work or by comparing the performance.	0
the related work section helped a bit, but still unclear.	0
the paper studies an interesting task however it is not ready for publication:  empirical results of all baselines are missing (table 2)  other results are mentioned but are absent from the manuscript  the related work does not provide details as to how the proposed model to prior work  the figures are difficult to understand (although they do help make the model clearer and so i suggest polishing them for the next version of this work)  the manuscript should be carefully copyedited.	0
# singularities i looked at the papers citing the main related work (the ptc paper by schonscheck et al., 2018), and of the four listed in google scholar, one seems relevant in that it prominently cites schonscheck et al. and claims to improve upon it, but this work is not cited in the present paper: cohen, weiler, kicanaoglu, welling, gauge equivalent convolutional networks and the icosahedral cnn.	0
i am not necessarily interested in an actual empirical evaluation, but including this in the related work section would likely be interesting for the reader.	0
for example, the paper lacks awareness of, citation to and comparison with related work such as [15].	0
the significance of the paper is moderate as the key idea of learning disentangled latent variables has been studied, and the paper lacks of evidence to show the pure benefits of introducing z_x as well as the comparison with the related work [ref1].	0
the end of the related work section is not very clear, you say these methods are problematic because 'the adopted shaping reward yields no direct dependence on the current policy' but there's no explanation or motivation for why that would be a problem.	0
the revised version of the paper addresses many of my concerns about the motivation, related works, and comparisons with gail, so i'm updating my score to weak accept.	0
specifically: 1) i would like to see a comparison to probabilistic image colorization (pic) [1], which was mentioned in the related work section but not included in the comparison of colorization models.	0
hoffer & ailon is incorrectly cited as ailon (2015); in general the references are poorly formatted  snell et al is barely mentioned in the related work, but the two methods seem very similar to me; i think it merits more discussion (in particular, highlighting how what you do is different / an extension).	0
however, i do have some concerns about the treatment/comparison to related work and i think without this it's not ready for publication.	0
overall i think this is an interesting paper, however i am not familiar with all the related work.	0
weaknesses: 1. related work: one of the major weakness of the paper is the missing related work.	0
no doubt the authors realized already but page 7 has some 'related work still needs some work, but there....' which should be deleted.	0
one minor issue: 3. the sentence at the bottom of page 7 should be removed ('related work still needs some work, but there seems to be some bug on overleaf right now')	0
this may just be personal preference on my behalf, but i think a short treatment on vaes and optimal transport would be useful in the related work and background sections.	0
# related work my main concern with the related work section is that there a lot of literature on risk sensitive and optimism in the face of uncertainty (which is a subset of your method when c>0) in control, bandits, and some on 'reinforcement learning' that has been neglected.	0
on the other hand, the paper may be still in lack of comparisons and/or discussions with the related work.	0
cons:  some important previous works are missing from the related work section.	0
in the related work on semisupervised learning (section 3), the authors only review mixmatch but neglect other literature, e.g.[1,2,3,4].	0
the proposed method works with a variety of quantization approaches, such as binary, simple pq or lsq (even if the authors aren't able to report results for this last method due to technical issues as explained in appendix 7.7) weaknesses of the paper:  the related work could be more detailed, see for example: 'spreading vectors for similarity search', sablayrolles et al. ; 'pairwise quantization', babenko et al ; 'unsupervised neural quantization for compresseddomain similarity search', morozov et al. justification of rating: the paper proposes a new loss function that weights the scalar products differently according to their importance than can be applied to a wide range of existing quantization methods.	0
also in the introduction, you could consider referencing the following papers on robustness to different threat models: ' engstrom et al., 'exploring the landscape of spatial robustness' ' tramer and boneh, 'adversarial training and robustness for multiple perturbations'  in the related work, you reference a number of works for adversarial training but not the original idea in the paper by szegedy et al.  in section 3.1., the observation that the epsilonball around training examples can cross class boundaries is further analyzed in 'excessive invariance causes adversarial vulnerability' and 'exploiting excessive invariance caused by normbounded adversarial robustness' by jacobsen et al. typos ===== p.6 enumerator > numerator	0
the second contribution of learning a sampler given a density estimate is interesting but likely suffers from all the instabilities of gan training, and does not compare to related work on distilling energybased models.	0
i think that technically this idea is new, but there is important related work [1] that (imo)  does essentially the same thing  better experimentally validates the thing they do  was published in last iclr.	0
in my opinion, the motivation of the paper is clear and the writing is easy to follow, but one potential limitation is the lack of comparison with recent related work, e.g., generate to adapt: aligning domains using generative adversarial networks swami sankaranarayanan, yogesh balaji, carlos d. castillo, rama chellappa https://arxiv.org/abs/1704.01705 deep transfer learning with joint adaptation networks mingsheng long, han zhu, jianmin wang, michael i. jordan https://arxiv.org/abs/1605.06636	0
i am not familiar enough with related work to evaluate this statement, but given it’s true, this is an interesting application of these ideas.	0
however, in my opinion there are a few weaknesses in the paper in its current state: (1) the clarity of sections 3.13.2 could be significantly improved as currently the proposed probabilistic model framework is confusing and not welldefined; (2) the experimental results are provided only for embedding spaces of dimensionality 23 which significantly hinders performance of prototypical networks compared to having a much higher dimensional embedding space, so it would help to see comparisons of spe and pn using highdimensional embeddings; (3) the central idea and proposed model seem to be very close to those of [2] which is mentioned in the related work, so, please, list differences with this prior work in the updated version.	0
very strange claim (which is false, as far as i know) that curriculum learning has only been used in shallow networks emphasizes that the related work is lacking.	0
i have read the related work section but can't figure out all the details.	0
4. i have not followed this topic much but it seems to me that there should be more related work on modelling annotators' competence and item difficulty for crowdsourced annotations.	0
overall, the idea proposed seems quite incremental, experiments are limited, and related work discussion incomplete. '''''''''	0
i read the author response but i do not think the paper is ready for publication yet without the thorough comparison with related work.	0
the student after stagebeta also outperforms the teacher  something that was mentioned in the related work, but i would like more discussion around it specifically for table 4. another thing i was wondering was how important pba is for the teacher’s ability to be a good teacher.	0
typo: 'they main takeaway' > 'the main takeaway' strengths:  good related work  somewhat complete evaluation weaknesses:  no analysis with so many hyparparameters (reg lambda, number of concepts), and thus not sure about the validity of the simulation  idea is interesting but straightforward  not very interpretable results	2
the paper would be greatly improved by adding:  an intuitive paragraph in the intro that explains a concrete example of ds high level, but with enough details for the reader to grasp the idea)  adding a new section right after related work (and before the current '3.	0
however, the comparison to other approaches does not show a clear advantage, and the related work (and experiments) lacks recent techniques.	0
especially, section 2.3., should not be a part of related work but should be integrated either to section 1 (introduction) or section 3.	0
1) marginal novelty compared to related work there have been several maskingbased blackbox methods.	0
however, the related work is not always well described, the experiments lack important comparisons, and the practical effects of pcgrad should be explained in more details instead of focusing on a proof for a convex case.	0
however, (1) the paper lacks any discussion of related work in terms of causal reasoning and partial observability, and (2) the experiments and analysis seem weak.	0
missing connection in related work: previous conditional generation methods (e.g., tacotron, deep voice 3) are autoregressive over time, but assume conditional independence over frequency bins.	0
strengths  i really like the related work section.	2
the paper is not easy to read, and mixes various terms without introducing them (e.g presynaptic activity is used to introduce the method but never introduced, not even in related work).	0
strengths:  the biological motivation is quite clear  architecture is simpler than that of previous related work (hgru) weaknesses:  not clear what the objectives/contributions are  no advancement of state of the art in computer vision  no novel insights about brain function  motivation of the 'texturized challenge' is unclear  performance on bsds500 is far from state of the art  value of the qualitative analysis on stylized imagenet is unclear overall, i'm not sure what the goal of this paper is.	2
altogether, i find the paper borderline: it is clearly written but the methodological contribution is incremental, some citations to related work missing, and some parts of the results section are weak.	0
however, there are a few weak points which should explain my overall score: 1. the proposed gsm model is not new and only reuses building blocks from the related work.	0
i also have concerns about related work in heuristic algorithms.	0
pros:  the paper is well written, with sufficient background and related work section for the paper to be selfcontained.	2
the authors however ignore most of previous related work, there is a huge bulk of work on graph neural networks and on modelling timeseries.	0
in the related work section for dynamic neural networks, the authors claimed that 'most dynamic networks methods sacrifice accuracy in exchange of adaption in inference', but it seems to be quite overclaimed.	0
as is detailed in the related work, the field has been inching towards this but without as much success as this paper has.	0
strengths interesting nonparametric approach to estimating uncertainty in the agent's forward dynamics model clearly written paper with sufficient technical depth well structured discussion of related work weaknesses my main problem with the paper is a missing fair comparison to prior work.	2
pros: ' good results on c10 ' a clear related work section that divides the existing works in pseudo labelling vs consistency ' interesting results about the effects of using different architectures.	2
these methods are acknowledged in the related work, but i think they should be taken into consideration when describing this “critical limitation.” while not having an encoder does indeed hinder or prevent the use of an implicit model for inference, i think stability, mode dropping, and mode collapse are more prominent issues with gans.	0
there's plenty of neural topic models to compare against (you mentioned some in your related work section) but no comparison with any of those is presented.	0
second, in terms of comparisons, the paper lacks adequate related work.	0
so promising work, but related work and experimental work need to be improved.	0
it seems to work pretty well in practice, but i wonder how it compares to other risksensitive rl algorithms (e.g. those cited in the related work section).	0
============= to improve paper:  clarify motivation and how this would inform adversarial training highly nonlinear classifiers;  add related work for robustness to perturbation of linear models, or state that they don't exist;  clarify weaknesses in the claims.	0
the rebuttal does not address my major concern (motivation), nor does it discuss its relationship with related work.	0
regarding belkin et al: sorry for the misunderstanding, i didn't mean to imply that it's highly relevant, but i thought it might be a good addition to the related work section as it also relates to the generalization of neural networks.	0
it provides clear motivations and goals, as well as an impressively comprehensive related work that discusses their shortcomings.	0
i agree that table 1 confirms the equivariance so that is great but it is less clear that the network is suitable for the pose task since the baselines seem very simple for the pose estimation experiment (and the related work covers a lot of prior work in this area) and again, without error bars it is hard to judge significance.	0
i think there is a lot of material in the appendix that should really be in the main paper  i'm happy for the proofs to be in the appendix but i think it is a bit wrong to essentially violate the page restrictions by moving important related work into the appendix.	0
this looks crucial, but i don't believe distillation is mentioned at all until the end of the related work section, and even there it comes as a bit of a surprise since there's no mention anywhere of this technique in the introduction.	0
furthermore, the paper lacks a discussion of related work on incorporating wavelet ideas into neural networks.	0
smaller concerns and questions:  there are a couple of instances where i found the claims of the paper with respect to related work to be overstated.	0
## strengths  the language of the paper is clear and easy to follow  the paper covers the related work well  the provided explanations help understand the content of the paper  the analysis of how the information captured in the agent's representation changes over the course of a trajectory is interesting (more such visualizations in the appendix would be nice!)	2
3 the related work section misses significant number of prior work on continual learning (i have provided a short list at the end [4,5,6] but authors are strongly encouraged to read more on this literature).	0
this lack of baselines and reference to related work makes the experiments inadequate.	0
other minor comments not related to decision: ' 'concrete autoencoders for differentiable feature selection and reconstruction' by abid et al. (2019) targets unsupervised feature selection but has enough similarities in the approach that it should be considered related work. '	0
my main concern is regarding the related work and experimental validation being incomplete, as they don't mention a very recent and similar work published in icip19 https://ieeexplore.ieee.org/document/8803498: 'optimizing the bit allocation for compression of weights and activations of deep neural networks'.	0
i also noticed several places throughout the paper where citations or related work seem to be misunderstood:  1st page, 2nd paragraph: this is not what griffiths (2010) is about, and is not really an appropriate use of the term “inductive bias”  2nd page, contribution 1: the paper claims that it is not dealing with a partially observable setting, but this is exactly what the paper is doing.	0
strengths:  the paper is well written with high quality visuals and plots  the paper studies an important problem weaknesses:  the contribution seems to be rather incremental (evaluating existing methods on 2 dataset) and some related work might be missing  although the analysis is well executed, it is not clear what the community learns from the paper although i enjoyed reading the paper, i'd lean towards rejection of the paper.	2
there is also a major concern with respect to novelty and related work.	0
in 2. related work, saliencybased explanations, the paper refers to whitebox models but does not offer explanations as to why mask is chosen over other methods (gradcam, guided backprop etc).	0
my only concern is that although the related work section provides a thorough survey of the current methods in the literature, the authors did not demonstrate the performance of stateoftheart and compare their performance with them.	0
i think the motivation is adequate, but the review of the literature glosses over related work (or the absence thereof) in predicting the direction of arrows in causal graphs.	0
lack of algorithmic novelty is not an issue but the authors should at least discuss similarities to lml (amos 2019) in a clear manner in related work.	0
i recommend it be rejected due to lack of novelty and missing connections to much related work.	0
the paper describes related work but the connection to the exact problem they are solving wasn’t 100% clear to me.	0
in sum, i think though the paper makes contribution on exploring better flow models but the novelty is relatively weak, the discussion and comparison of related work is insufficient and the experiments are not convincing or have mistakes.	0
while the idea is interesting, the paper lacks precision in key areas and the method is not placed in context among related work.	0
this paper introduces the vector quantization but doesn't mention the use of it in streaming data in related work, which kind of blurs the contribution a bit.	0
a quick search shows several related work in this domain, e.g., ‘an online incremental learning vector quantization’.	0
the related work section provides thorough review of different methods to decrease computational costs, including not only knowledge distillation, but also pruning, compressing and decomposition approaches.	0
## strengths  bootstrapping a learned local distance metric to a global distance metric to reduce testtime planning cost is an interesting problem  the paper has nice visualizations / analysis on the toy dataset  the learning procedure for the local distance metric is clearly described  the paper uses a large variety of different visualizations to make concepts and results clearer ## weaknesses (1) missing links to related work: the author's treatment of related work does not address the connections to some relevant papers (e.g. [13]) or is only done in the appendix (especially for [4]).	2
## minor edit suggestions  fig 2 seems to define the blue square as the target, the text next to it describes the blue square as the agent, please make coherent  for fig 7: the numbers contained in the figure are not explained in the caption, especially the numbers below the images are cryptic, please explain or omit [novelty]: minor [technical novelty]: minor [experimental design]: okay [potential impact]: minor ################ [overall recommendation]: weakreject  the exposition of the problem and treatment of related work are not sufficient, the actual novelty of the proposed paper is low and the lack of comparison to strong baselines push this paper below the bar for acceptance.	0
my two major critiques are (1) the related work is seriously lacking making it difficult to situate this work in a broader context.	0
as discussed in the related work, this work can be seen as complementary to many related works such as igl 18, but the novelty of the idea is rather limited.	0
the related work section focuses on gradient compression techniques (which tackle low bandwidth, not latency) and asynchronous sgd (which is more prone to congestion, with a single parameter server), but seems to overlook that sparse communication techniques already exist (this fact should at least be mentioned).	0
i believe this is a sensible restriction which enables analysis beyond the setting of primary concern in alemi et al. (and other related work).	0
the related work section is extremely lacking, with no work older than 2016. the introduction presents more background, marginally older than that (up to 2012), when grammars make for an entire field of study with decades of history.	0
5. the introduction lays out connections to some related work, but leaves several relevant pieces missing.	0
major comments:  authors need to include more related work and describe the main related paper they mention (peterson et al 2018) as well as describe how their work fits in with previous work  while the idea here is novel and impactful, the experiments used to explain the importance of superordinate labels do have not much compelling information and are not well described  4.2 plots for visualization are mentioned to be in the appendix, but are not there minor comments:  fig2 large subordinate group text would help  lots of typos throughout and grammar mistakes o typo ‘use vgg16’ and then ‘vgg16’ in same paragraph bottom of page 4 o typo top of page 2 “convolutional neural network(cnn)” o appendix list – ‘banna’ typo under fruit o page 1 intro ‘for both behavioral and computer vision’ doesn’t really make sense o page 3 top section ‘new one’ should be ‘new ones’ o bottom of page 3 ‘room from improvement’ o last line of conclusion – ‘classificacation’ consensus: this is a very interesting and potentially impactful idea, but the experiments used to defend and explain the importance of superordinate labels are relatively weak.	0
the authors write in the 'related work' section that gmm with regularization was proposed by [verbeek et al. 2005], but it is an older idea  for example [ormoneit&tresp 1998] in section 3.1, the motivation for the maximization in eq. (2) is unclear.	0
the general direction of this work is worthy of study, but the paper needs additional justification for its task, better discussion of recent related work, and more development of its regression models.	0
table 1. seems to cite the related work results, but it doesn't seem to include the results of the proposed method. '	0
surely just ‘1 bit’  the related work contains a lot of equations, but no real explanation of what they are.	0
the authors are recommended to compare with previous work on hierarchical generative modelings with objects and parts, such as (xu et al, iclr 2019), and other related work, such as spiral (ganin et al.) due to the limited contribution, lack of comparison with related work and limited empirical evaluation, i recommend rejection of the submission.	0
e.g., one related work on blackbox softlabel/hardlabel attack https://arxiv.org/pdf/1907.11684.pdf thus, my initial rating is weak reject.	0
in the related work, it is mentioned that “[compared to gidaris & komodakis]… we differ in how we compose classifiers and the unified learning objective.” as mentioned, the generation scheme is a bit different, but i don’t see a difference in the learning objective between the two papers?	0
the related work section is large but unhelpful about offering connections of prior work to this work.	0
the results that the paper reports lack of comparison with those from related work.	0
a quick internet search shows a number of other papers that use gumbelsoftmaxbased hard attention, but there is no mention of these papers in the related work (e.g., [1]).	0
the latter is the only one cited in this paper, but only in the results table and there is no mention in related work.	0
reasons to accept:  strong empirical results  thorough treatment of baselines and related work reasons to reject:  incremental contribution (especially compared to tsai et al., 2019)  writing lacks sufficient technical detail	0
older approaches (nonlocal neural network) are noted in related work under 'crfbased' but the authors do not expand on why these methods are not suitable to solve the problem at hand, or the fundamental distinctions between such approaches. ')	0
i am not very familiar with aes in general but i think that related work section needs improvement and the authors have missed out on few works that i found are closely related to their work.                  	0
so i am concerned that the paper seems to miss this important related work.	0
this paper should be rejected in my opinion due to the following four main reasons: (i) the technical quality of the paper is poor and the main idea not well explained; (ii) the experimental evaluation considers rather simple datasets (mnist, fashionmnist) and only includes two baselines (vanilla ae, ocsvm), but not any major competitors ; (iii) the work is not well placed in the literature and major related work is missing; (iv) the overall presentation is poor; (i) i find that subset scanning [7], seemingly the main component the approach, is not well defined and explained in the paper.	0
i notice that this paper has been cited briefly in the small related work section at the end, but this really should feature earlier as it's not a great look to pass off an older method as something new (although this may be unintentional).	0
although there is a reference, batch augmentation is not just related work but an important element of one of the two suggested training regimes (d).	0
the main concern that i have with the paper is the experiment depth: in specific, the paper does span a number of related works, but it does not empirically expose the systems comparison in sufficient detail.	0
better performance compared to related work is obtained, but an additional se layer is used in the current work, which may account for a large part of the gains.	0
pros: 1. the proposed method is clearly introduced 2. the differences between the proposed method and related work are clearly explained and demonstrated through ablation study.	2
see my detailed for other weaknesses in related work.	0
the paper discussed many related works, but it's not clear why the specific methods were chosen for comparisons.	0
the results presented on celeba and imagenet are interesting, in particular using different models is a good idea, however the evaluation relies mostly on a few cases or examples and i would have liked to see more quantitative results, e.g. like in figure 8 appendix f. note on related work: it has been shown (isolating sources of disentanglement in vaes by duvenaud et al., disentangling by factorising by kim et al., challenging common assumptions in the unsupervised learning of disentangled representations by bachem et al.) that betavae is far from optimal for “extrinsic” disentanglement, the text in section 4.1 should take these results into account.	0
strengths: 'the discussed mi subject is important research area, the paper presents the vast related work, proven by the fact mi techniques appears in many recent models. '	2
5. lack of related work: 4d spatiotemporal convnets: minkowski convolutional neural networks, cvpr 2019.	0
most paragraphs in the introduction section review the related work and background but do not introduce what assumption and strategy the proposed method adopted.	0
the paper is missing references to some related work but is otherwise well written.	0
the paper is strong in its idea, formulation, and theory, but is too similar to recent related works which this paper is reluctant to compare to (either in theory, efficiency, or performance).	0
ideas are simple and incremental, even if i rely upon literature overview provided by the authors in the related work section.	0
strengths:  good coverage of related work, including recent publications.	2
some of my previous concerns (point 2 and 3) seems true for many related works in this area in general.	0
the paper has a designated related work section but the entire paper reads from its abstract to conclusions constantly like a literature review.	0
my current recommendation is very borderline (weak accept) because of a lack of some experimental rigour (which i would love clarifications on), and missing related work, which i mention below.	0
[weaknesses] 'related work' the descriptions of the related work are not comprehensive.	0
the text was also confusing in a number of places (possibly due to my lack of knowledge in choice modeling), and there’s no discussion of related work incorporating neural networks into rankingbased models.	0
discussion and comparison to very significant related work is missing and experimental measurement of any advantages of the proposed method vs. adversarial training is lacking.	0
however, i do have some rather serious concerns about the generalsum game results and several questions regarding the relation to related work and the experiment details that need to be addressed.	0
related work is covered to a satisfactory degree, but a discussion of some of the following closely related papers could improve the paper: ' chang et al., a compositional objectbased approach to learning physical dynamics, iclr 2017 ' greff et al., neural expectation maximization, neurips 2017 ' kipf et al., neural relational inference for interacting systems, icml 2018 ' greff et al., multiobject representation learning with iterative variational inference, icml 2019 ' sun et al., actorcentric relation network, eccv 2018 ' sun et al., relational action forecasting, cvpr 2019 ' wang et al., nervenet: learning structured policy with graph neural networks, iclr 2018 ' xu et al., unsupervised discovery of parts, structure and dynamics, iclr 2019 ' erhardt et al., unsupervised intuitive physics from visual observations, accv 2018 in terms of clarity, the paper could be improved by making the used model architecture more explicit, e.g., by adding a model figure, and by providing an introduction to the supair model (stelzner et al., 2019) — the authors assume that the reader is more or less familiar with this particular model.	0
one concern for this paper is the level of novelty, as each major component of the proposed solution has been explored quite extensively in the existing literature (as mentioned in the related work section).	0
bo was also used for generating blackbox adversarial examples at https://arxiv.org/pdf/1907.11684.pdf this is a missing related work, and please elaborate on the differences.	0
i have three main reasons for my decision (with more details in the next section): 1. the paper is very poorly written : a lot of details are missing in the paper, notation is not standardized, related work is just a list of previous papers without any context on how the proposed method is related, previous methods are referred to without any citations, and quite a few blanket statements which are not substantiated.	0
the model presented here uses a pretrained vision module, which by itself is not a problem and is used in related work [1], but this vision module does not operate on visual input but the symbolic representation of the map.	0
strengths:  simple approach that seems to be giving good results  large number of adversarial attack scenarios tested  good related work review weaknesses:  results are reported without variance information  there are some details missing on how the decay factor is selected  results are reported only on one dataset (imagenet) the paper is well written, the authors have identified a 'problem' of resnetlike models and proposed an approach that can exploit the problem in adversarial attacks scenarios (sgm).	2
in general, a related work section is vital here, but missing in the paper.	0
there is some missing discussion of related works: 1. ensembledagger (menda 2018) also uses the variance of ensembles in imitation learning, but instead of using it to regularize onpolicy learning, it uses it as an improved decision criterion by which to query an expert demonstrator.	0
i find the further experiments performed by the authors of very good quality overall, but i'm still not particularly satisfied by their `argument that the codebase itself is distinct enough from separate related work.	0
this paper shows the resnet baseline achieve nearzero test accuracy but doesn't compare to other relevant baselines that are mentioned in the related work section: for example [bello et al, deudon et al., kool et al.] for the tsp.	0
major comments ============= 1. the presented approach is very similar to chen et al, which is discussed in the related work section but not used as a baseline.	0
a few additional suggestions for related work: noisy channel approaches (eg, the neural noisy channel, yu et al, iclr 2017); decipherment (eg, beyond parallel data: joint word alignment and decipherment improves machine translation, emnlp 2014  yes, from smt days, but still); other joint modeling work (kermit: generative insertionbased modeling for sequences, chan et al, 2019).	0
'the authors make the following contributions:'' 1. they show that qlearning trained on multiple tasks with a context variable as an input (an rnn state summarizing previous transitions) is competitive to related work when evaluated on a test task even though no adaptation is performed 2. based on these observations, they introduce a new method for offpolicy rl that does not directly optimize for adaptation but instead uses a fixed adaptation scheme 3. the new method leverages data during metatesting that was collected during metatraining using importance weights for increased sample efficiency ''overall, we believe the contributions are significant and sufficiently empirically justified.''                  	0
here are a few random remarks: about related work, 'balancing the objective and diversity' is also the central concern of qualitydiversity (qd) algorithms (see e.g. cully&demiris for a survey). '	0
so with that the paper positions itself not as a survey but as a method paper but lacks evidence that the method expected gradients performs better.	0
the authors didn't survey the literature after 2016 at all... nowadays most papers focus on sample selection/reweighting and label correction rather than loss correction in this area, but there are still many recent papers on designing more robust losses, see https://arxiv.org/abs/1805.07836 (neurips 2018 spotlight), https://openreview.net/forum?id=rklb76ekpr and references therein.	0
my only concern is that although the related work section provides a thorough survey of the current methods in the literature, the authors did not demonstrate the performance of stateoftheart and compare their performance with them.	0
this paper should be rejected due to the following arguments:  the paper lacks a section on literature survey, to let the reader know how/where the proposed method fills the gap in the current stateoftheart.	0
my main concern about the paper is a weak survey for disentanglement researches.	0
what follows are the pros and cons / discussion points / styling suggestions the authors could choose to address: [pros]  wellwritten  a good survey of related literature and concepts  interesting visualizations [cons / points / styling]  the placement of figure 1 seems arbitrary as you refer to it for the first time on page 3. this would not be such a big problem; however, it divides the paragraph in two without need to.	2
first, this paper lacks a survey of works on handling label noises.	0
i think that this paper merits acceptance because (a) the motivation of taking a necessity in practice (somehow selecting models / injecting inductive biases) and making it more explicit in the approach is a good one, and because the thorough empirical survey (and simple, but novel, contribution of a new semisupervised representation learning objective) are likely valuable contributions to this community.	0
another concern i still have is the claim of 'reasoning', and i'd suggest to narrow down the claim to be only on pattern demixing, since the reasoning part seems to be writing down continuous constraints from the discrete constraints (same as the concern in review #3).	0
questions  see the concerns strongpoints  the probabilistic explanation of the mlp and the cnn seems novel and was interesting to the reviewer  the proposed explanation assumes a weaker condition compared to the existing methods.	0
concerns  the main concern is that the reviewer cannot fully convince that i.i.d.	0
supports the argument of the author, but the reviewer failed to clearly agree with the argument.	0
in that case, the reviewer is little suspicious of the role of the proposed regularization in that the regularization comes from bayesian formulation, but the model was trained in a deterministic way.	0
therefore, the reviewer temporary rates the paper as weakreject, but this can be adjusted after seeing the answers of the author.	0
review:###major caveat: i have published in the area of adversarial attacks on nlp models, but the specifics of the methods presented in this paper are quite outside of my expertise, and i do not have time to become familiar with them for this review.	0
review:###[due to the rebuttal, my score was raised from a weak reject to a weak accept] summary the paper addresses the problem of interpreting predictions/decisions of a blackbox classifier/regressor by masking the parts of the input that were most relevant.	0
i am therefore slightly leaning towards suggesting a major revision of the paper, but i am happy to be convinced otherwise by the other reviewers and the authors during discussion/rebuttal.	0
(i would rate the paper as 'borderline', but it seems that this year's review system only allows for 'weak reject' or 'weak accept', so i'll go for 'weak reject' for now).	0
unfortunately, the lack of clarity in the paper and poor writing prevents me from writing a thorough review.	0
regarding the merits of the technical contribution, i'll perhaps have to defer to other reviewers, but overall the contribution seems above the bar.	0
i reread it to assess the modifications made by the authors but i am aware of the comments that they received in the previous round of reviews.	0
i'm also reraising some concerns that i made in a previous review that the authors didn't address.	0
as i stated in the review ('no, e.g., neural networks are employed'), neural networks are an 'example' of, but do not subsume, all representation learning methods.	0
however, as i stated in the review, my evaluation of the method proposed in the submission is that it does not concern representation learning ('the employed features in table 3 are handcrafted').	0
27) as the other reviewer notes, the paper lacks clarity in many places, and does not sufficiently discuss prior work, including in postural control (there is one citation in the references that is not mentioned in the main text), hierarchical bayesian optimization within or without a gaussian processes framework (https://scholar.google.com/scholar?hl=fr&as_sdt=0%2c5&q=hierarchicalbayesianoptimization&btng=), or experience replay (https://scholar.google.com/scholar?hl=fr&as_sdt=0%2c5&q=replaymachinelearning&btng=).	0
i am in a difficult situation here: the study is one of those things (like determining human performance on imagenet, or recoding some baseline where the original code is not available) where i find it valuable that someone did them in the community, but still i don't think they need a reviewed paper.	0
however i'm willing to change my opinion after reading other more qualified reviewers in the subarea of variancereduction techniques.	0
review:###summary: this paper discussed an approach to do named entity resolution (ner, the paper focuses only on chinese ner but i think it could generalize to other languages as well).	0
however, it still does not address my concern, which i resummarize here: i do not dispute the beneficial of exploiting neighborhood information but my point is we could still leverage the same amount of neighborhood information without going through the trouble of incurring extra steps of approximation due to approximating q(f) instead of q(f_i)  i think i have elaborated this in points (1)  (4) in my original review  which also creates the amortized gap.	0
the reviewer has the following concerns: 1. while the proposed method is capable of handling adaption of the output space between the source domain and the target domain, it makes use of a multitask subnetwork component, which is a sensible modeling choice but it seems that the idea of leveraging a global discriminator and a classwise discriminator has been exploited in previous works, as pointed out by the authors in section 4.2. therefore, the reviewer is concerned about the modeling contribution made in this paper is somewhat incremental given existing literature.	0
( your methods rely on q(s, a) which is actionvalue function, or the constraint in equation 3 is integral of q over all actions which would be valuefunction in traditional definition ) note: this is explained very well towards the end in the appendix b, but this is a review of the paper and not appendix b or c.	0
however, the reviewer has the following concerns: as to the assumption in this paper, it is too strong to assume independence between different elements of hessian, wigner ensemble seems to be a better model, since the only independence only comes from samples instead of the elements of the hessian.	0
review:######summary### this paper tackles the transfer learning problem with the doubleblind unsupervised domain adaptation, where either the source or the target domain cannot observe the data in the other domain, but data from both domains are used for training.	0
in addition, the authors did not add new empirical evidence regarding my questions but mainly reiterated the applicability of the proposed method, so i will remain my review rating. '''	0
i’m don’t know why the reviewing system assigned this paper to me, but i will try my best to judge the value of the paper.	0
[1] 'filling the soap bubbles: efficient blackbox adversarial certification with nongaussian smoothing', https://openreview.net/forum?id=skg8gjbfvr [2] salman, hadi, et al. 'provably robust deep learning via adversarially trained smoothed classifiers.'	0
i am not considering this as part of my review but i would encourage the authors to look at [1].	0
after considering the other reviews and discussions with other reviewers, i also share the concern that the simple megad baseline performs very well, with little additional gain from the full mega approach (only on the many permutations case that was introduced in the rebuttal).	0
review my primary concern about this paper is the largely insufficient literature review.	0
to summarize, i think the paper could easily be accepted to a future conference, but i think it is important to:  make connection between the insights and exploration clear, specifically designing the introduction, lit review, and experiments around this connection.	0
i agree with the sentiment trying to be expressed, but the absolutism makes it difficult to separate that sentiment from a deep understanding of the current rl literature with only the most important papers cited, or a fundamentally insufficient lit review.	0
• « we add 21 to all four curves in order to make exponential moving average »: i do not understand that sentence • « we set the number of samples as 26 for the sake of computation efficiency »: i fail to see how going from 32 to 26 is going to make a major difference in computational efficiency update: thank you for your response, but in the absence of a revised version addressing my concerns (as well as those from the other reviewers), i cannot increase my rating	0
==== update: the authors do address my concern #2. after reading other reviews and reading the revised paper i do think this approach of this paper is novel and can potentially lead to a gain.	0
my only possible concerns would be somehow comparisons to existing methods are not comprehensive enough (if this will be pointed out by the other reviewers)	0
review:###this paper is concerned with how to determine whether a set of data points are from a given distribution.	0
review:###the paper is mostly concerned with multiaspect sentiment classification.	0
update post author response: i thank the authors for carefully responding to the concerns raised in the initial review.	0
i would have made the same remark for (learning latent dynamics for planning from pixels, hafner et al.) but the paper does not seem to be not peerreviewed.	0
my main concern is that this paper actually was accepted by a neuro ai workshop of neurips and thus this submission does not comply the rules of doubleblind review process.	0
i have more following concerns 1) as the review given by neuro ai, the submission just compare their results to zenke et al. 2017 for split cifar10/cifar100.	0
actually, most concerns raised by the reviewers in neuro ai have not been considered.	0
some of the queries/concerns in the review comments above were clarified.	0
review:###this paper is concerned with contrastive disentanglement.	0
the author clarified one of my main concern, but the other reviewers point out that the comparison is not fair (using only 5 seeds and discarding the failure seeds).	0
review:###this paper provides a simple but novel coaching method for teacherstudent based semisupervised learning framework.	0
feedback/suggestions/nits (not necessarily part of decision assessment): 1. cite the definition of continual learning (e.g. with a reference to a textbook or review) 2. a lot of the writing is unclear, wordy, and/or grammatically incorrect  inconsistent verb tense  e.g. 'if one would need .... it is required' should be 'if one would need .... it would require' i'd suggest rewording this sentence entirely, because it's misleading  it says 'retrain on this new dataset (which sounds like train just on the new data), but i guess you mean retrain on all data including the new data.	0
1. since authors propose an invertible neural networksbased method for continual learning, instead of only focusing on incremental class, authors should also evaluate the proposed method in other continual learning tasks in object classification, for example, incremental domain and task, as defined in this review paper (https://arxiv.org/pdf/1810.12488.pdf).	0
review:###postrebuttal feedback i share the same concerns as that of reviewer 2 in the response to the rebuttal.	0
update after reading the other reviews and the rebuttal, the concerns i have raised remain.	0
(though i am less positive due to the concern of novelty raised by other reviewers.)	0
the literature review is good but must add two relevant works.	0
i also agree with concerns raised by other reviewers.	0
this may have been obvious to the authors, but spelling them out may help the reviewer/readers to understand the contribution.	0
the reviewer feels that the paper stands at a high level in general, but lacks concrete examples/applications for general readers to appreciate the significance.	0
however, all reviewers still share concerns about the importance of the problem tackled.	0
in a way, this paper reads like an interesting technical review of atari, but i don't think it provides enough new knowledge to be a conference paper.	0
review:###my understanding is that the paper does not claim to deliver some great results here and now but instead suggest a promising direction ('that ellipsoidal constraints prove to be a very effective modification of the trust region method in the sense that they constantly outperform the spherical tr method, both in terms of number of backpropagations and asymptotic loss value on a variety of tasks').	0
review:###update after rebuttal: the rebuttal addresses my concerns.	0
the point raised by reviewer 2 regarding other results on clothing1m is concerning, but the authors' response is reasonable.	0
thoughts after author feedback: i really appreciate the response of the authors to my review, which included some interesting new experiments and explanations addressing concerns i raised.	0
overall i agree with reviewer 1 that the topic is interesting, but in the paper’s current form, it is not ready.	0
however, the reviewer is concerned with the following questions: assumption a2 does not make sense in the context.	0
the following comments are not as critical but fall into the category of ‘nice to have': 5) although the reviewer is aware that there were some experiments in the appendix on the value epsilon, it might be a good idea to have more studies on the influence of this regularisation parameter for other datasets rather than just mnist 6) while figure 1 appears in the beginning of the paper, on page two, it is discussed on page seven, in the experimental section.	0
post rebuttal edition: after reading the reviews and the authors' reply, several questions such as the major concerns over this oversimplified linear assumptions surface out, as discussed in length by other reviewers.	0
in particular, in addition to points raised by reviewer 2 there are concerns with regard to lack of ablation studies, and major clarity issues.]	0
review:###i'm somewhat out of area for this review: i study relational models, but have little experience with computer vision in general and object tracking in particular.	0
as clarity and experimental evaluation are also major concerns of the other reviewers and it is unclear if and how they will be addressed in a revision i do not recommend accepting the paper.	0
in its current form, the paper has two main weaknesses:  it is poorly written & organized  it was a fairly weak empirical evaluation in order to address the first issue:  the authors should significantly improve the quality of the prose, which can be confusing & difficult to undersrand  the introduction needs to be significantly crisper: in its current form, it is far too general and does not describe the rest of the paper; the authors should explain ... 1) what is the problem they are working on (currently present, but far too long) 2) what is the proposed approach & why is it novel (missing) 3) what are the main results & their significance (also missing) in order to address the second issue:  3.1 needs more details; it is this reviewer's understanding that the current corpus consists of 1065 documents (which is extremely small in size); how many sentences are there in these documents?	0
review:###this paper develops a random walkbased method on top of prototypical networks to address the semisupervised fewshot learning, i.e. when each classification task can access only a fewshot labeled data but many unlabeled data.	0
the paper uses a lot of spaces to review the existing works and problem settings, but only spends one page (section 2.2) on the description of their contribution, and the description lacks any indepth discussion about “why it is designed in this way but not others” or “how this objective helps the fewshot learning”: it simply lists the procedures without convincing explanation.	0
cons:  some very relevant elements in the literature review are missing.	0
it is also hard to evaluate the quality of the training time during the review  typo: extra parenthesis in eq 4 in conclusion, the authors give some good intuition about promising methods, but i had some difficulties in understanding all the details of their approaches.	0
further, the other reviewers also pointed out concerns regarding the difficulty of the task and complexity of language used.	0
perhaps 'fine tuning' is indeed 'super standard in the object recognition literature', but as all three reviews here indicate, the presentation of fine tuning is unclear in this paper.	0
strengths  the literature review of existing work on gnn was a pleasure to read and provided a good motivation for the proposed gnnfilm architecture.	2
ps: the reviewer is very familiar with the modulation and multimodal literature, but he has only basic knowledge in graph networks.	0
i will thus leave the “weak reject” score unchanged but will not block the acceptance if other reviewers and/or the ac believe the paper should be accepted.	0
the reviewer also disagrees with using only 1k samples for selecting best dataset to transfer from  explained in minor weaknesses.	0
in the related work on semisupervised learning (section 3), the authors only review mixmatch but neglect other literature, e.g.[1,2,3,4].	0
i guess this is why the data generation process is a common concern raised by both reviewers 1 and 2. i think the response of the authors is not enough to clarify this.	0
concerning the presentation and the review of other works, i am a bit surprise that the 'teacherstudent' setting appears out of the blue, without any references to any paper.	0
review:###this paper proposes a solution to overcome the challenges due to the blackbox nature of physical constraints that are involved in the design of nanoporous templates with optimal thermoelectric efficiency.	0
review:###the paper contains one main contribution, the unbiased version of mine obtained using the etatrick, however a lot of theory is presented and not always very clearly.	0
they should be compared to those in 'learning representations by maximizing mutual information across views' by philip bachman, r devon hjelm, william buchwalter response to the author response: this was written earlier but there was a mishap when i attempted to submit it and it was not actually submitted until comments were no longer available to the authors so i am putting this in the review.	0
based on the concerns raised by the other reviewers and looking through the comments, i am inclined to lower my scores to a weak reject.	0
i agree to other reviewers, that the limitation to linear debiasing is a concern for the paper, but the authors have clarified it now in the abstract an other locations; the additional experiments with and rbf kernel have shown that indeed the formulation only does mainly do linear decorrelation.	0
the author response does not address any of my concerns raised, yet the authors insisted that their 'theory' is useful (which is apparently not true according to all reviewers) and provided more confusing and misleading results.	0
i have written a long review with detailed reasons and hope the authors can understand why the proposed method fails, but it seems they completely ignored it and did not learn anything from it.	0
finally, the role of inhibory neurons in the visual cortex seems to be well understood, both biologically and mathematically (see for instance https://www.sciencedirect.com/science/article/pii/s0896627303003325 or https://www.sciencedirect.com/science/article/pii/s0896627303003325 or https://www.sciencedirect.com/science/article/pii/s092842570300072x) overall, the quality of the article at least in its current state, does not seem to be ready for acceptance to iclr, but i'm willing to adjust my opinion after reading the opinion of more qualified reviewers' in this area and the authors response.	0
i’m not giving a high score for now but i will reconsider my review once i hear back from the authors.	0
while the paper is nicely written and does a good job of reviewing knockoffs, i see two main issues: (1) i am not sure about applications for the proposed algorithm; in particular, the authors allude to use on devices with limited memory and computational power, but do not discuss why the johnsonlindenstrauss transform or some of the many lowprecision implementations of neural networks (binarised neural networks, xnornets, …) cannot be used; furthermore, in the case of images, i am not sure why there is no comparison to simple downsampling to a smaller resolution; (2) the reported results do not show a reliable improvements over existing methods.	0
if the authors can convincingly demonstrate the novelty of the proposal to learn the terminal signal via extrinsic reward supervision, and if the other reviewers feel similarly convinced, then i would feel more comfortable reevaluating my concerns about the significance of this work.	0
however, concerns c) raised by reviewer 2 seems critical.	0
moreover, there is a large body of work in the drug discovery literature that uses sparse experimental data on the interactions of multiple target proteins and multiple ligands to build models that predict the outcome of biological assays for held out protein targets, where this problem is known as drugtarget interaction prediction, but these papers are not referenced in this work (e.g. reviewed in chen et al. molecules 23(9):115, 2018, ezzat et al. 2017, 2018, 2019).	0
:) feedback/suggestions/nits (not necessarily part of decision assessment): 1. briefly review some continual learning work; incremental labels are very similar to open set learning; this is worth mentioning.	0
overall, in reviewer's opinion, results looks quite incremental, and are heavily concentrated around specific paper of bialkowski et al., and as such might see limited interest in the iclr community.	0
'global shape and structure the group' > 'global shape and structure of the group'  ''anchor' agent (mehrasa et al.)' > year for citation  post review i appreciate the author addressing my concerns and making clarifications here in discussion and in the text.	0
i liked the idea quite a lot and would not mind seeing it in the conference, but given the number of issues raised by myself and others it seems that the best route forward is rewriting the paper given the inputs by the reviewers and submitting to a future venue.	0
there are two concerns with the paper from the reviewer.	0
review:###update after author response: i would like to thank the authors for the thoughtful response, and for addressing several of the concerns raised by the reviewers.	0
review:###update after author response: i would like to thank the authors for their thoughtful response, and for addressing some of the concerns raised by the reviewers.	0
for the record, the score i wanted to give is a 4, but since i can only choose 3, or 6, i will assign a score of 3 for this review (although should really be a 4).	0
postrebuttal review the rebuttal resolves my major concerns and the manuscript has been carefully revised accordingly.	0
reviewer has several concerns regarding the experiments.	0
4. the authors claim their implementation is 'approximately x times faster' but there is no quantitative proof of it, which seems to be one of the sellingpoint of the paper (or at least one of the best results) 2. writing those typos do not impact the review score, i hope it can help the authors to gain more clarity in their writing.	0
i did not consider it in this review since it was published a few weeks ago on arxiv, but it could be interesting to discuss it nevertheless.	0
i don't feel this in any way undermines the contribution of the work presented here, but merely wanted to make the meta reviewer aware in case it was relevant to their decision.	0
review:###motivated by the observation that powerful deep autoregressive models such as pixelcnns lack the ability to produce semantically meaningful latent embeddings and generate visually appealing interpolated images by latent representation manipulations, this paper proposes using fisher scores projected to a reasonably lowdimensional space as latent embeddings for image manipulations.	0
i have spent a lot of time reviewing this paper and related papers, the technical explanation about the hidden activation calculation of pixelcnn used in this paper is unclear and lacking (please use equations not just words).	0
review:###observing shortcomings of bleu and rouge, the paper proposes, jaune, a set of criteria for a good evaluation metric.	0
the initial rating is towards reject, but i would like to see the authors' response and the other reviewers' comments.	0
review:### comments after reading the reply from the authors: thanks for the clarification which resolves most of my concerns, and i have updated the score accordingly.	0
here are some concerns, and the reviewer is willing to adjust the rating if these concerns are resolved.	0
related work: https://openreview.net/forum?id=rkvoxhaqy7 (ceb) that may result in a similar objective as wyner’s common info ' when comparing to jvae/jmvae, it seems like the main difference is suing a latentvariable in the decoder, but the framework is still the same.	0
on the other hand, if the dataset remains closedsource then blind review isn’t violated but results aren’t reproducible and hard to follow by the community with the current level of description.	0
update#2: as i mentioned in my review, adam with large epsilon is not equivalent to momentum sgd but only approximates the latter.	0
review:###postrebuttal update: i have just noticed the authors modified their summary post below and claimed '[my concerns] are all minor or resolved'.	0
however in terms of novelty, adashift was published at iclr last year (https://openreview.net/forum?id=hkgtkhrckq) and seems to include a closely related analysis and update rule of your proposed optimizers.	0
the reviewer has some main concerns regarding the claimed novelty: 1. pdog computes the difference between outputs of two depthconvolution layers, but there is no evidence that the distribution of feature maps is gaussian or gaussianlike.	0
however the reviewer does acknowledge that the estimates are mostly likely better than relu networks that are well known for having terrible estimates of uncertainty.	0
i do agree with some of the concerns raised by other reviewers.	0
i dislike writing short reviews, but i fear this paper falls too far short of iclr standard.	0
# after rebuttal taking into account the concerns of other reviewers and the newly added evaluations, i lower my score to weak accept.	0
review:###########updated review ########### i would like to thank the author(s) for their reply, which i have carefully read and it partly addresses my original concerns.	0
review:###update to the review after the rebuttal from the authors: after carefully reviewing the responses by the authors especially on my concerns about the significance of solving an instance of a given problem and the improvement in the exposition of the ideas i would like to amend my earlier decision and recommend to accept.	0
moreover, for my question number 1 about the optimization problem, the authors referred me to corollary 1 from the paper, but that didn't really help me because, as the other reviewers also point out, the writing is quite hard to follow.	0
there are several concerns raised by the reviewer.	0
however, the reviewer is concerned with the following questions: the paper is mainly on analyzing the case when the true data has n points instead of on a continuous support.	0
the goal of this work is quite interesting, but the reviewer feel a bit challenging to follow the writing.	0
i am not very familiar with the literature but it seems some relevant work may be missing from the review.	0
however, i have a few concerns that lead to me to give a low score (at least in the first round of reviews).	0
concerns  the main concern of the reviewer is that the model shares the core contribution to the existing method; squeezeandexcitation network (senet, hu et.al.).	0
the reviewer agrees that some recent works focus more on flops, but the number of parameters is also discussed in general, when telling about the 'model size'.	0
the reviewer has the following concerns,  this paper motivates from rankk quantization but implemented as a scaled quantization.	0
however, the paper in the current state cannot be accepted for the following reasons: (1) the novelty is low, this very type of decomposition is already widely studied (2) the paper is not clear as to what the contributions are, and why they are justified, theoretically or empirically, (3) the review and comparison with the stateoftheart is lacking and (4) the experimental setup is simplistic and not convicing.	0
the reviewer is aware that this paper mentions the proposed method doesn't apply regularization, but why not compare to the original results.	0
my concerns with experiments and clarify remain unaddressed, and are amplified by reading the other reviews.	0
postresponse comments: in my opinion, the authors adequately addressed both my own concerns, and also several valid concerns from the other reviewers.	0
however, the reviewer has the following concerns, it is already shown in (engstrom et al., 2017) that models hardened against l infinitybounded perturbations are still vulnerable to even small, perceptually minor departures from this family, such as small rotations and translations.	0
additionally, as pointed out by reviewer #4, the results seem somewhat incremental.	0
their method seems technically sound, however i am not familiar with this area, so i would trust more the opinion of other reviewers  subject experts in the matter.	0
review:###overall: i don't work on atp and am not particularly well suited to review this paper, but i am slightly inclined to accept for the following reasons.	0
review:###======== update ======== i have read the authors' response and it has addressed most of my concerns.	0
however, the reviewer has some caution and concerns as follows: 1) the lack of a large scale experiment demonstrating improvement with an actorcritic method.	0
review:###a simple method to detect adversarial examples, but needs more work.	0
this paper presents several useful heuristics around, but i share the concern with other reviewers about whether the main point is compelling enough, given the existing body of work along with this line.	0
review:###update after author response: i would like to thank the authors for the thoughtful response, and for addressing some of the concerns raised by the reviewers.	0
[reviewer's reply:] gem (lopezpaz et al., 2017) and its faster version (agem) (chaudhry, et al. 2018) and other memory based methods such as mer (riemer et al. 2018), erres (chaudhry et al. 2019), they use memory sizes of at most 6mb to store samples but they only do a ''single epoch'' through the data.	0
[reviewer's reply:] i agree that this work is not published and hence can't be asked for comparison but i encourage authors to read it.	0
the reviewer has several concerns: 1) the sbmd and asca algorithms are existing generic algorithms.	0
reviewer has concern about the scope and application value of the problem as a research paper.	0
3) reviewer is interested in the nature of the error (7.5% loss) but it's not discussed.	0
8) in section 4.2. second paragraph, reviewer can understand the nessesity of additive and subtractive operations, but why multiplication?	0
11) in section 5.1, reviewer respect the experiment results but doesn't understand why solid color background provides the best variety but screenshots don't.	0
(4) why do the baseline methods perform so poorly against labelflipping against on mnist (figure 3) while performing fairly well on cifar10 and amazon reviews (table 1/2)?	0
review:###======================================== update after rebuttal ============================================= i have now read the author rebuttal, but my concerns about the paper remain.	0
i understand that the authors are not required to provide their code, but this should have been a relatively straightforward request in this case given the simplicity of the experiments and as i mentioned in my initial review, it would have been very useful in evaluating the paper.	0
however, if the paper clarified the concerns below, i'd be willing to increase by review.	0
note that 5split mnist is not reported in [4], but a recent work has reported hat’s performance on this dataset (https://openreview.net/forum?id=hkluccvkdb) that achieves 99.59%.	0
[reviewer's response:] i disagree with authors on this because gem, its faster version (agem (chaudhry et al. 2018)), and all other methods explored in the recent study which i mentioned in my review (ref#2) use the single epoch protocol and are perfect match to be compared with this method but there is no memorybased baseline except for vcl with coreset and frcl (only for mnist variations) which makes it difficult to measure this method's capabilities (performance, memory size, and computational time) against methods which only require one epoch to be trained.	0
main arguments apart from the interesting approach, this paper should be rejected due to several reasons: (1) the specific application field, considered in this paper, have to be generalized to more general cases, in order to be valuable for machine learning community, (2) from rl algorithms perspective, the novelty of proposed method is questionable due to lack of literature review and advanced approach to deep reinforcement learning, (3) requirement of explainable ai is essential for deployment and in spite of the quite sufficient explanations of the algorithm’s works, this paper does not well justify its superiority over the traditional methods either by theory or practice, due to experiments suffering from the lack of variability and missing the main point of improvement, which leads to generally insufficient contribution (4) the paper is unpolished and lacks specific formulations from the existing literature on related subjects.	0
secondly, except general notice of combinatorial problems solved by rl algorithms, the literature review lacks mentioning graph representation methods or any seq2seq algorithms (which efficiently uses attention), which should serve as an initial guess for the wellperforming model in this particular problem.	0
related work if the main concern of the paper is still the limitation of other methods which use expert knowledge then it is better to state the usage of additional data (development index) in social equity metric as a reward design part in appendix to justify this reward engineering “we believe that rl has the ability to solve the metro expansion problem” is the statement, which should be substituted by extensive literature review on rl methods used for planning with constraints or specifically graphbased expansion methods.	0
first, this paper lacks a structured literature review.	0
minor additional comments there are more minor points i would like to make, but these do not contribute to the review decision.	0
more concerning examples are given at the end of this review.	0
my review can seem to be a bit harsh, i actually enjoyed the paper, but i don't think iclr is the right conference for it, and i would advise the authors to improve it and submit it to a speech conference.	0
review strengths: the paper is clearly written.	2
review:###claims: the paper presents a concept of 'recognitionaware (ra) image processing': when one enhances image in a some way, not only human judjement should be taken into account, but also performance of various computer vision application using that image.	0
i think the motivation is adequate, but the review of the literature glosses over related work (or the absence thereof) in predicting the direction of arrows in causal graphs.	0
review:###the authors propose a new certified defense strategy that considers unrestricted black box attacks.	0
review:###pros solid technical innovation/contribution:  the paper proposed a novel method ficm that bridged the intrinsic reward in drl with optical flow loss in cv to encourage exploration in an environment with sparse rewards.	0
edit after author response: i appreciate the authors' efforts in providing extensive responses to all of the reviewers' concerns as well as a significant general response detailing what seems to be a large amount of additional experimental work.	0
[1] https://arxiv.org/abs/1812.07671 ### update the authors gave a detailed response to the reviews and answered some of my main concerns.	0
despite this i feel that this submission should be accepted but at the same time i’m curious to see what the authors have to say regarding the concerns i raised in my review.	0
the related work section provides thorough review of different methods to decrease computational costs, including not only knowledge distillation, but also pruning, compressing and decomposition approaches.	0
############## after reading the author's feedback and the comments from other reviewers, i keep the current rating but tend to a borderline score and it is ok if it must be rejected because of the concerns of limited applicability and the experimental.	0
sadly, my concerns are only answered at a highlevel, and the consensus among reviewers is clear.	0
review:###after reading the other reviews and comments, i appreciate the effort by the authors, but it looks like the paper still needs some work before being ready.	0
strengths:  the paper studies an interesting problem of adaptive mri reconstruction  the review of mri reconstruction techniques is well scoped weaknesses:  the evaluation is rather limited and performed on one, proprietary, relatively small sized dataset  some simple baselines might be missing i like the idea of adaptive sampling in mri.	2
review:###https://openreview.net/pdf?id=skxauehfpb the paper has some interesting ideas but i don’t think any of them are fully fleshed out.	0
it seems like there is a common concern about the novelty among reviewers: improvements over hrn are quite incremental.	0
3. given points 1 and 2, the literature review is lacking  there's a lot of prior work done on macroactions in both rl and robotics (planning, hri, ...) that goes well beyond the few recent papers mentioned by the authors, and i think it might be necessary to mention work on options where the termination function is structured / biased in some way.	0
after discussing with the reviewers about the methodological issue of the validation set, i have lowered my score to a weak accept, but i think this paper should still be published.	0
review:###this paper argues that artificial neural network (ann) lack in biological plausibility because of the backpropagation process.	0
as a summary: pros: a nice interpretation of cyclegan with ot the paper is fairly well written cons: overall the quantity of novelties is, in the eyes of the reviewer, somehow limited.	2
there is a short literature review, but i am wondering if something similar was done for static word embeddings.	0
cons: 1. the paper lacks a good literature review to place this work in the right context.	0
i did not verify the proofs in detail but they seemed ok at a highlevel; however, i am not an expert in convex optimization so i hope other reviewers will be able to comment on this aspect.	0
1. safegarding is the key point of this paper, but the authors did not review related works on safegarding.	0
i don't know if you will get an alert that the review was updated, but i hope you get a chance to take a look.	0
it is still not completely clear and i find obfuscated since just one sentence not even fully answering the concern about this was added to the manuscript despite myself and another reviewer asking about it.	0
my original concerns are like the other reviewers: why bn, not other techniques such as structure of dnns mlp vs cnn vs resnet, activation functions, weight decay, learning rates, softmax etc. my initial suspect was that it is caused by gradient masking likely caused by the l2 weight regularization, so asked the authors to look at the gradient norms and run some testes to rule this out.	0
they said they solve the problem by the keywords spotting system (kws), but they did not give a comprehensive review of the current progress of kws.	0
this reviewer did not read the appendix (not sure where this would be located  first time reviewing with openreview here), but the intuition doesn't seem to be much different than ma.	0
2. the paper lacks a cohesive introduction that includes a literature review on this very rich area of research.	0
the paper reviews previous literature and outlines a model, but it seems to be at the draft stage as it stands as the experiment section is missing (section 4).	0
the quality has improved but as mentioned in the original review, it would be good to see results on a more significant nonsynthetic task before i would argue for acceptance.	0
it is authors' job to provide a comprehensive ovreview of prior literature and i cannot do it for them here, but below are a few papers that come to mind.	0
the paper provides a fairly thorough review of a lot of different design decisions, but perhaps it is not necessary to go into such excruciating details for all of the different components.	0
i am going to lower my score to communicate a stronger signal that i believe the paper has more work to be done before publication, but note that my general opinions about the direction of this research have shifted slightly more positively after considering the other reviews.	0
''lack of comparison with [2]'': this is the reviewer's primary complaint with the paper.	0
i do suspect that the theorems you are proving are not interesting or already known, but i am not counting that suspicion in the review.	0
## feedback for improvement ' the authors should address the reviewer's concern about clarity and experiments.	0
the extensive graphs of correlations were also nice, but some of these graphs could be relegated to the appendix to assist with length issues (the authors barely extend to 9, which means they are supposed to have a harsher review).	0
review:###this paper discusses the many shortcomings of existing adversarial attacks for nlp models.	0
overall, i think rlst is clearly a strong model, but i am not sure about the main novelty of the paper (rl), for 3 reasons: 1) if rl is a significant cause in the improvements 2) the way that rl is used is unintuitive in several ways to me 3) how novel the use of rl is compared to prior work i think several of the above concerns may be addressed in the rebuttal and/or other reviewer's remarks, so i am looking forward to reading what others have to say.	0
the results appear impressive, but i will leave it to reviewers with more experience in the field to judge how it stacks up against recent work.	0
the authors use the 'attention' nomenclature throughout the paper but it is unclear to this reviewer why this choice is made.	0
strengths:  the paper studies an important problem  human study is interesting weaknesses:  the description of the gramnet is rather short  making it hard to asses the novelty of the method  the structure of the paper could be improved comments: although the study seem to be sound, the observations about texture importance are not surprising (e. g. see https://openreview.net/pdf?id=bygh9j09kx)  making the contribution rather incremental.	2
another concern i have (that did not influence the decision in my review): the proposed method assumes given the chopped shots of a video.	0
this does not mean to shorten the literature review or remove comparisons, but add the most relevant ones given that there is such a large body of network compression methods published in the last three years.	0
1) about the lack of novelty: 1.1) the doubly normalized attention appears to me identical to em routing proposed in the capsule network (iclr '18, https://openreview.net/pdf?id=hjwlfgwrb).	0
addendum: after writing this review the authors have responded to my concerns regarding the cl experiments and have begun to recompute some of the experiments using a more rigorous comparison with promising results on permuted mnist.	0
concerns  the main concern the reviewer has is that the experiment section should include more items.	0
join image and perpixel annotation can be a good idea however the paper needs significant improvement on literature review, model presentation and experiment result to be able to publish in iclr.	0
4. the writing is not great, and i've find several typos, which a more thorough proofreading could have caught (i mention some i found at the end of this review, but i stopped taking such notes after section 3.2.1).	0
i'm sorry this is different from the paper but i find it a lot easier to elaborate my review with this notation.	0
however the reviewer is not totally convinced about the conclusion in the paper.	0
however, the reviewer has some concerns about the overall significance and some other concerns on the experimental evaluations, and hence recommends rejection.	0
cons: there are few problems i encountered reviewing.	0
pros: 1. the writing is clear 2. the literature review seems thorough 3. segmentation results provide ample evidence cons: 1. the global classification results are not convincing enough to claim 'significant improvements in terms of imagelevel classification', as stated in the paper, according to the experiments.	2
the proposed mixreview strategy is very straightforward and lacks novelty.	0
weaknesses: (1) the approach of the paper (mixreview) is very similar to methods that have been proposed already, and the papers doesn’t acknowledge the huge body of prior work already existing on (catastrophic) forgetting.	0
first, results of figure 1 mainly show that mixreview is less prone to “forgetting” than wd, but i find that unsurprising.	0
at the risk of sounding obvious: the notion of forgetting only makes sense in the context of information (here, pretraining instances) that has been seen in the 'past', but those instances continue to be shown to mixreview in the 'present'.	0
now, the actual issue is that early stopping is not applied consistently between wd and mixreview, as the wd approach has seen the pretraining data only 20 times (“we stop the pretraining after the ccnews data is swept 20 time”), but mixreview continues to be shown ccnews data even after 20 epochs, so there is effectively no early stopping for mixreview.	0
3. i'll be interested to see what the other reviewers say, but i found figure 2 hard to follow.	0
review:###the authors' response addressed my concerns.	0
review:### update after author's response  thank authors for providing the detailed response to all my concerns.	0
therefore, the review is rather brief and i will comment also on concerns raised by the other reviewers.	0
concerning the remarks from reviewer #3, i believe that it is totally fair to use here a simple es algorithm that still shows reasonable performance.	0
(remark: since there is no page limit for refs, i would recommend to cite [1,2] in the paper) i share some concerns from reviewer #4 regarding the hyperparameters.	0
however, the reviewer has the following concerns and questions, the theoretical analysis depends largely on the gaussian assumption and argues that when the loss is distributed as gaussian, it seems to be not even a fair comparison since assuming l_{mmc} is gaussian is totally different from assuming l_{gsce} is gaussian.	0
review:###[post rebuttal: the rebuttal addresses most of my concerns.	0
my initial review was negative, but i changed my mind after reading a few papers in this area.	0
review:######summary### this paper introduces incremental domain adaptation for natural language processing, assuming that each domain comes one after another and only the current domain can be accessed in the application scenario.	0
#################### updated review ########### the authors have addressed most of my concerns i proposed in the initial review, thus i raise my score to 6 weak accept.	0
review weaknesses.	0
a similar observation was found in wikihop dataset, which is a multichoice qa dataset that all negative candidates are guaranteed to be the same type, but still questioncandidatesonly baseline (without context paragraphs) outperforms stateoftheart models (https://openreview.net/forum?id=b1lf43a5y7).	0
review:###summary: gradient clipping has been studied as an optimization technique and also as a tool for privacy preserving, but in this paper, it studies the robustness properties of gradient clipping.	0
but to be honest since i lack the background of pacrl, i would remain a conservative of weak accept and would like to hear more discussions from other reviewers and authors to finalize my decision.	0
note a small typo in the displayed equation just above fig 4: the sum is over but it's written (and also using     ext makes it look nicer, )  original review  the paper proposes a neuron pruning technique that can compress an existing pretrained neural net (though the experiments actually do additional unspecified 'finetuning' training).	0
my concerns have been well addressed and my review stands.	0
review:###background disclaimer: i work in rl research for quite an amount of time, but i do not know much about the domain of distributed systems.	0
cons  it was not clear to the reviewer how the convergence analysis of the proposed method differs from the existing analysis in the literature and if any novel ideas were involved in obtaining the theoretical results presented in the paper.	2
review:###'''''''''' postrebuttal update '''''''''' i appreciate that authors provided comments on all the raised concerns and updated the paper accordingly.	0
review:###i'm afraid i found this paper somewhat confusing and hard to see the big picture but i also acknowledge that i am not an expert in deep, modelfree rl and my rl experience is mostly in modelbased rl and i am happy for this to be taken into consideration when evaluating my review  apologies if i miss something that is well known in that community.	0
most paragraphs in the introduction section review the related work and background but do not introduce what assumption and strategy the proposed method adopted.	0
small stuff that doesn't affect my review: 1) it might be worth explicitly pointing out that p_    heta(x_k,z_k^c) is just a gaussian soon after eqn 3. it's written after equation 5, but without making the p_  heta explicit.	0
the reviewer is neither an expert in face verification and in knn retrieval algorithms but has a solid experience in sparse ml algorithms and group lasso algorithms.	0
cons:  i am familiar with metalearning, however, it is my first time to review a paper whose main contribution is proposing a new benchmark.	0
for example, [a] is one i recall well from 15 years back, but at that time there was a strong community in this area, so i encourage the authors to do a bit more thorough review.	0
it seems to work well, but i feel as if the wrong people are being asked to review the paper.	0
i am a tiny bit worried about venue and whether the right people will check the work, but i don't think this should be decided by reviewers.	0
i am willing to accept the title asis (and could be overwritten by other reviewers), but i would like some discussion on a more appropriate tile, if possible.	0
however the authors should release the code however they see fit, this is more of a personal preference on the part of this reviewer.	0
review:###============================== update after rebuttal ======================================================= i did not have any major concerns about the paper in my initial review, only some suggestions for improving the presentation.	0
review:###disclosure on reviewer's experience: i am not an expert on adversarial attack methods or defenses, but i am well read in the general literature on robustness and uncertainty in deep neural networks.	0
review:#### summary the paper compares 3 ways to account for the variability of the dynamics model in the td error computation: (i) be robust (take the lowest target value obtained when evaluating the valuefunction on the training distribution of models); (ii) be bayesian (average over models); (iii) domain randomization (compute td error as usual but randomize the dynamics to obtain a more diverse data set).	0
7.: you say 'to lengths of 2.0, 2.1 and 2.2', but according to table 3, these should be '2.0, 2.2 and 2.3' # after rebuttal the authors incorporated the feedback of the reviewers and 'significantly' rewrote the paper.	0
review:###this paper presents an ensemble method for neural networks, named batchensemble, that aims to provide the benefits of improved accuracy and predictive uncertainty of traditional ensembles but with a significantly lower computational cost and memory cost.	0
https://github.com/googleresearch/googleresearch/tree/master/dual_dice ======= after rebuttal ======= the author's feedback clarified some of my concerns in the initial review.	0
the paper has a designated related work section but the entire paper reads from its abstract to conclusions constantly like a literature review.	0
see [rezende, 2016][1] and [rajeswar, 2018][2]  i understand how some literature is required to position your method, but i think it's better to not have the entire literature section in the center of the introduction [1]: https://arxiv.org/abs/1607.00662 [2]: https://openreview.net/forum?id=bjeem3c9f7 ### method  2.1 clear  nicely written  figure 2 good, caption a bit too short  figurecaption should be able to stand on their own  illustration of figure 3 nice, except for unclear deepvoxel part: what's the wavy orange flag stand for?	0
overall, the reviewer feels that this paper starts with an interesting idea, but the developments on the theoretical side is a bit thin.	0
review:###[score raised from weak reject to weak accept after rebuttal  on a more finegrained scale, i would rate this paper now an accept (7), but not a strong accept (8), however since this year's scale is quite coarse, i'll stick with a score of 6] summary the paper proposes a new perturbationbased measure for computing inputsaliency maps for deep rl agents.	0
currently i am in favor of suggesting a major revision of the work, but i am happy to reconsider my decision based on the rebuttal and other reviewers’ assessment.	0
however, the reviewer has a few concerns which needs to be addressed.	0
this reviewer moves to accept the paper for its contributions to intrinsically motivated exploration with thorough discussion of how the technique addresses shortcomings of past methods.	0
review:###i found this paper very easy and clear to follow  the authors present, what i believe to be an elegant, approach to training a gan in the presence of missing data or where many marginal samples might be available but very few complete (e.g. paired) samples.	0
review': while i think the method has potential interest to the community, i found the empirical results lacking (particularly in missing competitors).                  	0
[1]: a slight caveat here: in the proposed algorithm 1, the abm model is learned online along with the policy, but i believe it could be learned without the policy  for example, by using mc returns as in https://openreview.net/forum?id=h1gdf34fvs.	0
as far as the reviewer knows, the proposed method improves the sparsity of the network, but most works choosing the strategy actually cannot meaningfuly enhance the operation time and just enhances the sparsity.	0
the reviewer has some concerns regarding the novelty, real speed up, and guarantee of the sparsity.	0
however, the reviewer thinks that this work has meaningful observations for this field with a sufficient amount of verification, assuming that the author's answers for the concerns do not have much problem.	0
post rebuttal edit: following updates to the paper manuscript, which address my concerns around the correctness of the empirical results, i have updated my review score from 1 to 3.	0
i am however willing to increase my score based on discussions with the authors and other reviewers.	0
the reviewer doesn't think this paper reached the bar of a good iclr paper but hesitates to reject.	0
i have only very minor comments:  i would prefer to get the paper additionally linked to a few more transfer learning techniques out of the deep learning domain which is important as well  do you really need to call it (multi) flow network ....  a flow network is a well established concept in algorithmics and refers to a graph problem ... to avoid name clashes ...  in the references you have provided back links to the pages where the references are used  this is handy but also confusing and a bit unusual  i think it was not part of the standard template  please avoid using arxiv references but replace them by reviewed material.	0
review:###the authors response on 13th nov regarding the main concerns i have are valid.	0
review:###[update after rebuttal period] while i still find the paper somewhat hard to parse, the revision and responses have addressed most of my concerns.	0
having also read through the concerns of the other reviews and the rebuttal to them, i have decided to upgrade my review to a 6.	0
review:###this paper provides a method for instructing an agent using programs as input instructions, so that the agent should learn to contextually execute this program in a specified environment, learning to generalise as needed from perception, and to satisfy concerns that in the language of planning would be called monitoring and execution.	0
review:###update: i thank the reviewers for their extensive rebuttal and revision of the paper addressing all of my concerns.	0
review:###the paper is concerned with neural odebased networks, specifically their robustness.	0
strengths:  simple approach that seems to be giving good results  large number of adversarial attack scenarios tested  good related work review weaknesses:  results are reported without variance information  there are some details missing on how the decay factor is selected  results are reported only on one dataset (imagenet) the paper is well written, the authors have identified a 'problem' of resnetlike models and proposed an approach that can exploit the problem in adversarial attacks scenarios (sgm).	2
while reviewing this paper i went back and read the ende evaluation data for the last few years trying to see how often i could reason that images would help and i came up severely lacking.	0
i do not think the current version is ready for iclr, but i am looking forward to seeing the authors' rebuttal and i am willing to revise my review accordingly.	0
i appreciate the thorough proofs of the claims in section c of the appendix, but i did not review all proofs in detail.	0
while reviewing, i’ve been assuming this was just a mistake in writing but please double check and clarify.	0
my suggestion for a further experiment would be to apply the movie review classifiers to, say, book reviews  something where the task is fundamentally the same but the context is different.	0
1 », « together with an analysis parses this data », « anonimize », « bsuite environments by implementing », « even if require » review update: the authors have addressed my concerns, and i look forward to using bsuite in my research => review score increased to 'accept'	0
this reviewer moves for a weak accept on account that the paper is well written (with quite thorough experiments explaining improvements in sample efficiency and possible limits in final task performance) but specifically targets ale where execution is so cheap.	0
review:###this paper proposes a straightforward method for training black box solvers of a restricted kind (namely those with inputs in r^n and linear cost functions).	0
it is great to see that the paper improved since my last review and stands stronger on its results, but there are still a few issues with it that make me hesitant to fully accept the paper:  the conclusion of the paper is biased towards the introduced models, but it should clearly define the limitations of these models wrt nalu/nac  the performance of nalu on multiplication is in stark contrast to the results in the original paper (table 1).	0
after rebuttal: i have raised my score to 6 after going through the authors' response for my questions, and other reviewers' concerns.	0
these are not simply implementation details as 'codelevel optimizations' suggests, but are rather details that necessarily must be included in peerreviewed works.	0
i have only 2 main concerns with the paper:  the paper is very long (10 pages), and given that, we reviewers should use stricter reviewing rules.	0
edit: the authors greatly improved the paper, addressing all major reviewer concerns.	0
also, for important tasks like name deduplication, the paper does not discuss or compare against techniques from previous work, and instead proposes a small set of heuristics, which is a sensible approach for building a resource but will not be of interest to the iclr audience.	0
while the paper reflects thorough and substantial work  both in the theoretical framework and in the experimental part, i have serious concerns about its clarity and about the experimental results and also some concerns about comparison with previous work.	0
this paper only follow previous work and lacks new insights about the problem.	0
the paper provides a thorough background on previous work; however the motivation for having an inputdependent dropout method is relatively weak.	0
i do not specifically have issues with 'more stringent robustness metric' but it should not be used to claim incredible results (like an accuracy drop of 10 to 16% instead of 3% for previous work (real et al. 2017)).	0
the actual model implementation is a straightforward extension of the sent2vec model to crosslingual scenarios, inspired by previous work (e.g., the work on transgram and bivec), so the paper is also very incremental from the methodological perspective.	0
i take most of space to describe previous work, but hard to find out what's difference of this paper.	0
final evaluation: i find the paper's only original and validated contribution to be using wang & manning [icml 2013]’s explicit regularizer to derive the complexity upper bound in lemma 1. due to the paper's lack of discussion and, at times, mischaracterization of previous work, the text needs to be significantly revised before it can be accepted.	0
lastly, the methodology seems quite incremental over the previous work.	0
perhaps the most surprising result of this work is that all gnns perform remarkably similar (contrary to what previous work has reported) weaknesses  there seems to be a much tighter relationship between gnnfilm and gated gnns than currently discussed.	0
i understand that previous work has suggested that mixup features are superior for discrimination than normal features, but in this work specifically the evidence for this assertion is fairly weak.	0
3. the overall technical contribution is somewhat incremental based on previous work on gnn and manifold mixup based regularizations.	0
2. this paper reduces time and space complexity of the algorithm in a previous work, but there is no running time or memory footprint statistics to support this argument.	0
learning the abstract representation space itself is based on a previous work, but the contribution of this paper is the utility of it to design the reward bonus for exploration by utilizing distances in this evolving representation space.	0
< but (1) highres images here are synthetic and limited in scene variability; (2) the second part is expected given previous work.	0
strengths: overall, the paper is well written and the relationship to previous works is well described.	2
strengths:  nicely motivates the approach of separating foreground and background  fewer landmarks are needed than in previous work  approach seems beneficial for video prediction  clear and well written  detailed description of architecture and training weaknesses:  the changes and improvements feel somewhat incremental  some uncertainty about the solidity of the evaluation/comparability with baselines results on celeba somewhat weak overall the paper is well written, easy to follow, presents a straightforward extension of previous work and appears to show an improvement.	2
although the proposed approach is interesting, this paper has several weaknesses (i) the method is not sufficiently justified or analyzed; (ii) there are missing links with previous work (notably on domain adversarial training); (iii) experimental setting is rather weak.	0
graph unet seems to be the most relevant previous work, but there's no discussion of how this work relates and why it's better.	0
it is an interesting work but it is not sure that there is a difference in contribution when compared to previous work.	0
al. the authors have carefully analyzed weaknesses in previous work and i think their experiments do suggest that they have improved on them.	0
my concern with the paper is twofold: 1) the major technique of transformdomain coding is borrowed from previous work (e.g., goyal 2001), hence the novelty of the proposed method is in doubt.	0
strengths: overall, i think the paper is well written and the relationship to previous works is well described.	2
we are also concerned about the novelty of the results, and believe most of these results have appeared in previous work.	0
it is not a problem to assume that the complete state is available, but claiming to generalize to partial observability is not entirely correct, even if your method handles the same semipartially observable case as previous work like vic or diayn. '	0
the authors propose an empirical analysis of different ways to mask the visual input, however this might not be a substantial extension of previous work.	0
i reckon this is a very interesting piece of work, but also that it draws too heavily on previous work from which the study is just an incremntal extension.	0
the paper also claims “recent efforts in terms of evaluating predictive uncertainty have focused on entropy as measure for uncertaintyawareness for predictions under domain shift.” in previous work addressing uncertainty in domain shift [1], not only entropy but other various metrics are considered for outofdomain detection (brier score, thresholded confidences, etc), these metrics don’t depend on particular perturbations and are very informative.	0
concerning the sparsehalfcheetah task, from appendix f: '...baseline reward level is 1 while a successful state provides 0 reward, but report reward values on a 0 to 500 scale for direct comparison with previous work'.	0
some of the main issues i notice are: 1. the novelty of the proposed (combined) method is unclear, given that it is a relatively straightforward combination of relatively simple and battletested techniques; i don't consider this in general to be a problem, but previous work has explored the problem way more significantly both algorithmically and in modeling terms.	0
while the idea of using the log trace covariance as a regularizer for the manifold is certainly interesting, it seems fairly incremental upon previous work (i.e., dmwgan).	0
i can see some new elements, but my knowledge of the previous work in this area is not deep enough to evaluate technical novelty very well.	0
in addition, i think the paper is lacking some grounding and context in terms of what problem is being solved and what previous work exists.	0
this lack of reference to findings in previous work make the analysis incomplete.	0
the paper lacks also proper citations to previous work and i find the background section and motivation rather weak.	0
summary  good research question concerning the robustness of flow models  simple and understandable claims supported by simple experiments  easy to read  can be improved more to clarify the difference from the previous work that study the flow model’s likelihoods.	0
the paper is full of flaws, incorrect statements, poorly constructed arguments, speculative explanations, and superficial descriptions of previous work.	0
my major concern is that the paper, including the motivation and illustrative example, are too similar to previous work [12].	0
some of the results do look nice, but it’s hard to say that the method has improved over the past 20 years of strokebased rendering, e.g., many of the results look worse than those in hertzmann 1998. the paper doesn’t offer any meaningful comparisons to the previous work, such as fair sidebyside comparisons on the same images, comparing computation times and aesthetics.	0
finally, it is also great to have some benchmarks of the algorithms being implemented, but at least for atari, i am not aware of previous work using the exact same evaluation setting, so it is hard to tell how they compare to other implementations.	0
compared to previous work, the learning curve model not only takes hyperparameter configurations into account, but by training it on offline generated data, it is able to model learning curves across different datasets.	0
major comments:  authors need to include more related work and describe the main related paper they mention (peterson et al 2018) as well as describe how their work fits in with previous work  while the idea here is novel and impactful, the experiments used to explain the importance of superordinate labels do have not much compelling information and are not well described  4.2 plots for visualization are mentioned to be in the appendix, but are not there minor comments:  fig2 large subordinate group text would help  lots of typos throughout and grammar mistakes o typo ‘use vgg16’ and then ‘vgg16’ in same paragraph bottom of page 4 o typo top of page 2 “convolutional neural network(cnn)” o appendix list – ‘banna’ typo under fruit o page 1 intro ‘for both behavioral and computer vision’ doesn’t really make sense o page 3 top section ‘new one’ should be ‘new ones’ o bottom of page 3 ‘room from improvement’ o last line of conclusion – ‘classificacation’ consensus: this is a very interesting and potentially impactful idea, but the experiments used to defend and explain the importance of superordinate labels are relatively weak.	0
pros: the motivation for having only one model is interesting the results are promising cons: one of main motivation of the paper is to achieve zeroshot as opposed to previous work.	2
the authors are recommended to compare with previous work on hierarchical generative modelings with objects and parts, such as (xu et al, iclr 2019), and other related work, such as spiral (ganin et al.) due to the limited contribution, lack of comparison with related work and limited empirical evaluation, i recommend rejection of the submission.	0
this paper presents an interesting application of rl, but overall the technical innovation of the method is fairly modest, and mainly consists of different components that are already commonly used in previous work.	0
it follows but improves on a previous work that leverages commonsense in generating the responses.	0
since previous work, like layerwise bp, ended up with pretty simple formulae, i suspect this to be the same here, but this would be a random guess, as what is written here is (at least to me) inpenetrable.	0
it is true that for one of the tasks they quot the stateoftheart from a previous paper, but for crosslanguage sentiment analysis there is no comparison to previous work.	0
i understand that asking to evaluate dozens of methods would be not be reasonable, but i think that the limited scope of the analysis is a weakness if you want to make general claims on the limitations of previous work.	0
the main weaknesses are (1) the novelty of the proposed methods is low (2) results are hard to compare with previous work and some experimental details are omitted.	0
cons: my most significant critique of the paper is that it exaggerates its contributions and ignores a large body of previous work.	0
i'm not aware of previous work explicitly highlighting it, but even if you had convincingly demonstrated it, i wouldn't have been super surprised.	0
my only concern is that the paper claims they are improving speed comparing to previous work, but they never compare their work to those mentioned and they don't talk about why there is no comparison provided with previous work of art.	0
conclusion: overall, i think the paper has merits in showing that rehearsal methods should probably be explored in the context of pretraining/finetuning architectures, but problematic experimentation and lack of comparison with previous work (there is only one baseline, wd, which is not enough to me given all the prior work on the subject of forgetting mitigation) make me recommend rejection for now.	0
some major concerns: 1) the bidirectional gated gnn doesn’t seem novel enough in comparison to previous work 2) i believe rl to graph2seq is a minor extension from seq2seq, since rl mostly deals with the decoder part which is common in across both graph2seq and seq2seq arguments: 1) adding the structure information to the encoder via the gnns is an interesting angle for question generation.	0
i understand that this is not the main contribution of the paper, but given the substantial amount of work on semantic parsing and question answering i was expecting more appropriate baselines taking previous work into account.	0
however, i have concerns about both the clarity of this paper and the lack of clear comparison to previous work.	0
weaknesses and questions: in general, some more description about the motivation of each metric would be helpful, rather than just stating that its from previous work.	0
the evolutionary search algorithm was not wildly original or a huge breakthough in the general context of previous work, but seems appropriate, well thought out and works well.	0
the main strengths of this paper are extensive experimental evaluation using both quantitative and qualitative analysis, and significant improvement in performance on reallife data over previous works.	2
however, i have some concerns regarding experiments and comparison to previous work.	0
concerns: while the paper explains the proposed method well, the description of previous work and relation to previous work is inadequate.	0
the main idea of the paper is to propose an estimator for offpolicy evaluation, that computes the ratio of the stationary state distributions (similar to recent previous work liu et al.,) but when the behaviour policy may be unknown.	0
this question ties in with a general point i am ambivalent to in this paper that it is very long, but there is very little analysis done on what makes the method work, why it is better than other control methods or control baselines, where the proposed control mechanism is not effective, how the model scales if there are large quantities of topics rather than just a few of them, if the bow and discriminator attribute models work well together or if certain attributes are easier to learn than others, so the model focuses more on those when there are conflicts, etc 5. missing citations: previous work has investigated controlling various attributes of text generation.	0
the contribution in this paper is too incremental given previous work.	0
review:###the paper introduces a generalization of the randomized smoothing approach for certifying robustness of blackbox classifiers, allowing the smoothing measure to be an arbitrary distribution (whereas previous work almost exclusively focused on gaussian noise), and facilitating the certification with respect to different metrics under the same framework.	0
rather than motivating the work in this way, it might be helpful to focus the contribution as a combination of future time step prediction and discretization (both of which have been considered in previous work, but not in combination).	0
the method does not yield clear gains over previous work, but rather a similar performance for classification and segmentation of shapenet and s3dis data is shown.	0
overall it lacks clarity in the presentation of the results, the assumptions made are not always clearly stated and the split between previous work and original derivations should be improved.	0
as the authors note, previous work addresses “cognitive flexibility” (yang et al. 2019) in isolation without motor commands, or studies motor dynamics of real mammals but without any task flexibility—occluding the actual advantages that mammals have over machines.	0
however, my primary concern with this paper is that it’s not sufficiently distinct from the previous work of lee et al, 2019. after all, most of the experiments in that paper would have required the type of implementation that is described in greater detail in this paper.	0
my surface level assessment of them is that the logic seems generally sound, but i cannot make any strong statements placing them in the context of previous work, nor can i properly evaluate the nuances.	0
first, the idea of evolving a neural turing machine was first proposed in greve et al. 2016, which the authors cite, but only in passing in the conclusion.	0
2 (2nd paragraph), you cite vaswani et al. (2017) but in that work the quantity under the squareroot in the denominator of attention(q, k, v) is actually d_k, the dimension of the key, and not d_model.	0
some sentences cite the reference but conclusions drawn on these are not cited, are you claiming that these conclusions are original from this paper ?	0
weaknesses: 1. related work: the paper needs to cite and mention a much more broader literature.	0
while the authors cite lack of work in such data setting (which is actually incorrect as described below), they do not motivate or justify why such an approach of using either unifilar hsmm or bayesian inference techniques are good starting point to model such information.	0
issues ====== ' the split lbi method is presented as a novel contribution (in the abstract: 'we propose a new approach based on differential inclusions of inverse scale spaces ...'), but it was already described in detail in a paper that they cite ([1]) published at neurips 2016. the only theoretical contribution of this paper is section 3: global convergence of split lbi. '	0
i do understand that the authors cite oh et al. 2018 who apply the same technique of sparsification, but oh et al. also conduct additional experiments in ale.	0
pros • interesting approach to extend the framework in [1] to cnns, with use of masks and maskspecific loss • clear motivation for the network bandwidth limited use case cons • hardly any technical novelty because the core ideas are already presented as well as applied to the same task in [1] • it is very surprising that the authors do not even cite [1] in their paper, despite their work being extremely closely related to it • most of the discussion in the related work section is unrelated to the specific task they tackled in the paper (i.e., input/feature selection).	2
for instance, i'd recommend to cite hubel & wiesel's seminal work on mapping the mammalian receptive fields, and older work by m. lewicki about analyzing learned receptive fields by sparse coding algorithms, similarly to the cited b. olshausen et al. 2) the authors show that gabor wavelets are eigenfunction of convolutions and they stop here to conclude that filters in cnns are the way they are because of the architecture, but how about the effect of the nonlinearities, depth and the type of cost used for training?	0
following are my concerns: 1) it is important to cite properly.	0
the main reasons for this are: (i) a potential failure to cite and acknowledge the prior contribution of [1] which seems to have nontrivial overlap with this paper (on arxiv since end of july which is more than 30 days before the iclr submission deadline and thus should be treated as prior work); (ii) the claims of guaranteed frequentist coverage are not backed up as, according to thm.2, they only hold when n >> 0 and the number of influence functions used goes to infinity (ideally, the authors would provide nonasymptotic bounds as in [1], but at the very least, these limitations should have been clearly pointed out and their practical implications discussed).	0
currently, i have three major concerns that keep me from judging this paper acceptable in iclr 2020. first, the authors failed to cite two closely related papers below:  tokozume et al., learning from betweenclass examples for deep sound recognition.	0
for linear classifiers, i do not know if there are existing work on their robustness when perturbation of samples are being trained on, but to be wellplaced in the literature, the authors must either claim there is none, or cite those papers.	0
the paper has two fundamental weaknesses: i) the paper misses a key reference, which addresses the same representation disentanglement problem using the same informationtheoretic approach, only with some minor technical divergences: alemi et al., fixing a broken elbo, icml, 2018. this paper is a mustcite, plus a key baseline.	0
afaik this paper only works with infinite networks but does not actually prove that ''deep'' networks of finite width (in each layer) converge to the ntk limit; imho you should cite the allenzhu et al. (2018) and du et al. (2018) papers from your references for that result.	0
based on p.2 (end of par.2 in sect.2), you seem to be aware of this distinction but cite arora et al. (2019) instead of these two; i would suggest either citing allenzhu et al. and du et al. only, or citing all three as the arora et al. paper came out later than the first versions of the other two paper which afaik already contained all the necessary derivations (even if the words “neural tangent kernel” were not spelled out there).	0
the authors do cite [1], but unless i missed something, their main argument for uniqueness is basically 'in experiments, we prefer s to the jacobian, because in order to compute s it is enough to look at the network as a black box that given an input, generates an output, without requiring further knowledge of the model.'	0
you do detail it in the appendix, but forgot to cite the appendix !	0
weaknesses: a primary area of deficiency concerns the relation of the proposed model to other proposals for sparse attention: the authors cite 5 of them (and 2 more are cited in the comment by cui).	0
shin et al. iccv 2019. i agree that there are differences between these works and the manuscript, but it's really peculiar to work on inferring a 3d volume of scenes from a 2d image or set of images, and only cite yolo, faster rcnn, and fcns from the world of cvpr/iccv/eccv etc where this work is done very frequently.	0
at the very least a comparison with asgd (cited) is necessary, as in a realistic setting latency is indeed a problem but arguably not bandwidth (plus, orthogonal gradient compression techniques do exist, e.g. as in 'federated learning: strategies for improving communication efficiency').	0
authors did cite peters 2018 and howard 2018 at the beginning of the paper, but may want to explicitly associate them with ‘elmo’ and ‘ulmfit’ when these two terms first occur respectively; 3) for table 2, does the ‘all data’ or ‘data with 100% agreement’ include training data (80%) or just the test data (20%)?	0
the author(s) seemingly achieve sota, but without knnbased accuracies for their model it is hard to compare to cited works.	0
the paper does not cite any previous research (no references) and is poorly written.	0
though the idea is good, i found the contribution to be too incremental for the paper to be accepted: ' the comparison should include the state of the art adversarial training defenses, pgd adversarial training (madry et al; you might want to cite the iclr 18 paper) and trades (zhang et al., interpreting adversarially trained convolutional nn, icml 2019); ' i would consider the szegedy baseline as obsolete; ' fig. 4 is unclear: the percentage of adversarial examples detected by the detector, but quid of the false alarms; there are quite some typos (nosie; iterarion; tabel; unsafety) and missing words.	0
table 1. seems to cite the related work results, but it doesn't seem to include the results of the proposed method. '	0
cons: 1. limited novelty & prior works are not properly cited.	0
however, the authors do not cite [1] in the method section but only shortly mentions it on the last page.	0
missing reference the paper proposes a transfer learning/domain adaptation technique, but few work on the topic was cited.	0
i am aware that the authors cite russin et al. but it is rather unclear how and why they incorporate these intuitions/motivation into their work.	0
likewise, you cite many related papers on quantization but do not compare to the performance of quantizing pretrained bert models and only storing the quantized weights for downstream tasks.	0
the authors do cite a good variety of recent relevant work, although some papers which would be good baselines are cited but not actually compared against.	0
discussion: the access to the external memory in section 3.2 is too concise  the dnc is cited but the description sounds like a cutdown dnc, without the link matrix or any kind of location based addressing, meaning the memory used is possibly even less capable than the original ntm.	0
it used to be common in metric learning for face recognition, as the authors cite facenet 2015, but has been long abandoned in favor of spherefacelike approaches.	0
however, in p.5, the authors claim that they observed the problems with no multiresolution networks and claim that they came up with this idea inspired by the mechanism in biological vision......... also, the paper claims that they compared their method with sota methods on table 2 caption, but they do not actually cite any sota methods.	0
the main shortcomings of the paper are its limited novelty (multiscale pyramids are an old 'trick' in computer vision), and the use of baselines that are behind sota for the discussed problems  e.g. dai el al, 'secondorder attention network for single image superresolution' could be a more current baseline for sisr (instead of memnet) and liu et al, 'nonlocal recurrent network for image restoration' for denoising (which the authors cite and briefly discuss in the introduction).	0
(remark: since there is no page limit for refs, i would recommend to cite [1,2] in the paper) i share some concerns from reviewer #4 regarding the hyperparameters.	0
and one more thing: in the revised version they write 'more recent works implement fastweight using outerproducts,' citing papers from 201617, but this was actually first done in the 1993 paper they already cite.	0
section 5.1: 'p(x|y,z_s,z_u)' > 'p(x|y,z_s,z_u)'  in a number of places, i think the paper meant to cite [1] but instead cited the older kingma & welling (2013) paper; for instance before equation (6) (this additional loss did not appear in the original vae paper).	0
also, the paper cites only the recent reference [4b] (2016) on synthetic gradients but not the original work [4a] (1990).	0
from what i can make out, not only should this paper cite neural logic machines but they should in fact be comparing against it via experiments.	0
minor suggestions: in the introduction, you mention l0 and l1 norm methods, but cite han et al. (2015) which compares l1 and l2 norm and found l2 norm to be better overall.	0
i agree that the authors extend a lot on this papers, especially in terms of dataset and completeness of experiments, but they are definitely closely related, and the fact that it is not cited is a serious flaw to the current version.	0
the authors claim many novel contributions, but most of them are special cases of existing literature (not cited), or are simple modifications to existing approaches.	0
comments: difficulty in training conditional generative models: i believe in the two papers you cite the models do not use the label as input, but rather there is a separate model for each class?	0
the authors point out that the lack of dependence of theorem 3.1 on epsilon is surprising, and cite lin’s work from 2017 who previously found such an independence.	0
the authors point out that the lack of dependence of theorem 3.1 on epsilon is surprising, and cite lin’s work from 2017 who previously found such an independence.	0
related work: the authors cite airl, but could do a better job distinguishing between airl and the current work.	0
strengths:  the idea is simple and motivated by the fisher vector work (jaakkola & hausler, 1999), which the authors cite.	2
this is very intuitive, but the authors do not cite or compare to related approaches.	0
however, the approach is related to chen et al, which is cited in the text but not used as a baseline.	0
moreover, hartman et.al. method is cited, but not compared to, because it needs '3d reconstruction' for supervision.	0
some sentences cite the reference but conclusions drawn on these are not cited, are you claiming that these conclusions are original from this paper ?	0
the authors listed the difference from (glimer et al. 2017) and (li et al. 2017) in table 1, but ignored (pham et al. 2017) and (battaglia et al. 2018), which were also cited in the related work.	0
the cited work by schafer&zimmermann only considers deterministic systems  but what is the distinguishing idea of your paper that makes your more general analysis possible?	0
to name a few: multigrid neural architectures, ke et al., 2017 feature pyramid networks for object detection, lin et al., 2017 multiscale dense networks for resource efficient image classification, huang et al., 2018 deep scalespaces, worrall and welling, 2019 i believe these works should at least be cited, but ideally compared against.	0
i agree with the sentiment trying to be expressed, but the absolutism makes it difficult to separate that sentiment from a deep understanding of the current rl literature with only the most important papers cited, or a fundamentally insufficient lit review.	0
with these two comments, i would like to know better how the work positions itself to supervised dictionary learning: the paper is cited (albeit with an incorrect citation), but the positioning is not explicit.	0
my first concern is that several papers are not cited, although they also address exposure bias:  venkatraman et al., improving multistep prediction of learned time series models.	0
minor:  the work of artetxe et al. (acl 2017) should be cited when talking about bootstrapping alignmentbased methods from limited bilingual supervision (instead of the work of artetxe and schwenk which concerns learning multilingual sentence embeddings).	0
# singularities i looked at the papers citing the main related work (the ptc paper by schonscheck et al., 2018), and of the four listed in google scholar, one seems relevant in that it prominently cites schonscheck et al. and claims to improve upon it, but this work is not cited in the present paper: cohen, weiler, kicanaoglu, welling, gauge equivalent convolutional networks and the icosahedral cnn.	0
regarding (ii), mathieu et al. [icml 2019] also study priors formed by products of studentt marginals, but their work is not cited.	0
authors have cited the paper on 'sanity checks for saliency maps', but have not used it to verify their own results, not with respect to saliency map, and not with respect to computational cost.?	0
hoffer & ailon is incorrectly cited as ailon (2015); in general the references are poorly formatted  snell et al is barely mentioned in the related work, but the two methods seem very similar to me; i think it merits more discussion (in particular, highlighting how what you do is different / an extension).	0
for instance, i'd recommend to cite hubel & wiesel's seminal work on mapping the mammalian receptive fields, and older work by m. lewicki about analyzing learned receptive fields by sparse coding algorithms, similarly to the cited b. olshausen et al. 2) the authors show that gabor wavelets are eigenfunction of convolutions and they stop here to conclude that filters in cnns are the way they are because of the architecture, but how about the effect of the nonlinearities, depth and the type of cost used for training?	0
in regards to the novelty claim, there have been several developments of depthbased (as opposed to timebased) adaptive computation time in the literature, for example: [1] mcgill et al 2017 'deciding how to decide: dynamic routing in artificial neural networks' [2] bolukbasi et al 2017 'adaptive neural networks for efficient inference' [3] figurnov et al 2017 'spatially adaptive computation time for residual networks' (this paper is cited by the authors) these papers do not present sequence models, but the ideas in them readily apply to sequence models.	0
the modulation adaptation problem is framed into nonstationary multiarmed bandit problem but the authors present a heuristic to solve it instead of using provably efficient bandit algorithm such as exponential weight methods (besbes et al 2014) or thompson sampling (raj & kalyani 2017) cited in the paper.	0
the authors claim this could “potentially improve generalization” but this is not justified and no reference is cited.	0
in spite of my concerns, i find the presented theory interesting and with better motivations and examples, it may eventually become a solid and wellcited contribution.	0
my major concern with this paper is that the “denoising density estimator” proposed here is identical to denoising score matching (which is not cited or discussed).	0
_using selfsupervised learning can improve model robustness and uncertainty_ (neurips) uses selfsupervised learning for ood detection and achieves good performance, but this work is not cited.	0
paper, in its current form, lacks quantitative evaluation, comparison to other methods (heavily cited in the paper), and any well established applications that can be quantified.	0
this work expands on risi2019, and proposes the use of multiobjective optimization (nsgaii) to allow a world model to learn several subsystems by the fact that the ga optimizer is not only targeting the reward function of the environment, but it is also optimizing for diversity, similar to mapelites line of literature (i.e. cully2015, mouret2015, and other more recent cited in this paper).	0
3  in section 5.1 please state that you used vgg 16 (i assume so since it is what was used in the cited reference (gal et al. 2017) but authors need to verify that.	0
## suggestions to improve the paper (for 1) add an experiment where the distractor has more natural dynamics so that there is mi between the distractor positions in consecutive frames (e.g. ball bouncing in the image frame in the background instead of randomly jumping to new positions) (for 2) add an experiment with a rewardprediction only baseline, i.e. only actionconditioned reward prediction so that taskirrelevant parts are ignored by default (i.e. also no reconstruction objective, but also no mi objective) > show how planet performance compares to the so far reported numbers when using this representation for planning (for 4) add details about the architecture, hyperparameters and training schedule, for both the method and all comparisons to the appendix (for 5) add references to related works that use cpcstyle mi objectives for representation learning in the context of rl/skill learning:  [1] nachum et al., iclr 2019  applies cpcstyle objective to hierarchical rl setting  [2] anand et al., neurips 2019  investigates mi objectives for representation learning on a wide range of atari games (don't apply to rl)  [3] gregor et al., neurips 2019  while the main proposed model is generative they compare to a contrastive version that uses cpc to learn predictive representations (don't use it for rl)  [4] guo et al., arxiv 2018  similar investigation to [3] of cpcstyle objective for representation learning in rl environments (don't use it for rl)  it should also be mentioned that the original cpc paper already showed that adding cpcstyle auxiliary loss to rl improves performance (even though they did not compare to other modelbased methods)  add qualitative rollouts for predictions from the planet predictive network both with and without distractor to the appendix ## minor edit suggestions  'learning latent dynamics from pixels', hafner et al. is cited twice in the reference section  it might help to add the reward prediction module to fig 3 or mention in the caption that it is omitted, it is only described later in the text and was confusing for me on first sight [novelty]: okay [technical novelty]: minor [experimental design]: okay [potential impact]: high ####################### [overall recommendation]: weakreject  i am inclined to accept this paper but am not fully convinced that the random distractors provide a good intuition about how the proposed method would behave with more natural distractors.	0
there is also individual fairness (the paper by dwork et al. is cited, but not properly discussed) and prior work emphasizing certain deficiencies of group fairness [1] along with several recent papers studying individual fairness [2,3], some also utilizing wasserstein distance [4].	0
it seems to work pretty well in practice, but i wonder how it compares to other risksensitive rl algorithms (e.g. those cited in the related work section).	0
additionally, i suggest that authors be more careful with their citations, for example, authors cited silver et al 2017 [the predictron: endtoend learning and planning], as one recent paper using the method; however silver et al 2017 is in mrp setting (markov reward process) where there is no action, so the described problem setting doesn't apply.	0
despite addressing the most recent papers in section 2, authors have only made comparison against two relatively old approaches (ewc by kirkpatrickthat et al from 2016 as well as lwf by li & hoiem presented at eccv 2016, i believe the authors have cited the journal version of the work published in 2018 but the work is actually from eccv 2016).	0
weaknesses: a primary area of deficiency concerns the relation of the proposed model to other proposals for sparse attention: the authors cite 5 of them (and 2 more are cited in the comment by cui).	0
related to this point, in section 2 of the paper, it is written that 'l2 regularization is applied to the critic q network because it tends to have overestimation bias (fujimoto et al., 2018)' but i was not able to find such an explanation in the cited paper though i may have missed it.	0
at the very least a comparison with asgd (cited) is necessary, as in a realistic setting latency is indeed a problem but arguably not bandwidth (plus, orthogonal gradient compression techniques do exist, e.g. as in 'federated learning: strategies for improving communication efficiency').	0
the author(s) seemingly achieve sota, but without knnbased accuracies for their model it is hard to compare to cited works.	0
in fact, the newest cited papers are from 2017. the github link in the paper was last updated on 23rd december 2017. my objection is not that this work was started a long time ago, but that it has not been updated in years.	0
for example, approaches such as gail (cited after the first sentence) are efficient with respect to number of demonstrations, but require similar amount of exploration experience as rl approaches.	0
cons: 1. limited novelty & prior works are not properly cited.	0
while i am not an expert in visualization techniques, i note that some very popular ones are just cited, but not compared against (check for example http://www.heatmapping.org/).	0
missing reference the paper proposes a transfer learning/domain adaptation technique, but few work on the topic was cited.	0
something close has already been proposed in https://arxiv.org/pdf/1602.06023.pdf, but it's not cited in the paper.	0
the latter is the only one cited in this paper, but only in the results table and there is no mention in related work.	0
the authors do cite a good variety of recent relevant work, although some papers which would be good baselines are cited but not actually compared against.	0
discussion: the access to the external memory in section 3.2 is too concise  the dnc is cited but the description sounds like a cutdown dnc, without the link matrix or any kind of location based addressing, meaning the memory used is possibly even less capable than the original ntm.	0
though some work is cited, experimental comparison to competing methods in both of these areas is entirely lacking.	0
this is a well written paper but, in its current form, it isn't above the acceptance bar: (i) the idea of using consistency terms as regularizer is not novel and related works on consistency losses have not been adequately cited; (ii) the experiments are in general well executed but are not quite comparable with the stateoftheart.	0
consistency across corrupted / augmented views has been used in a plethora of domains, not only in vision but also nlp (https://nlp.stanford.edu/pubs/clark2018semi.pdf, not cited).	0
in reference section, pereyra et al. 2017 is cited as an iclr paper, but is this a workshop paper?	0
i notice that this paper has been cited briefly in the small related work section at the end, but this really should feature earlier as it's not a great look to pass off an older method as something new (although this may be unintentional).	0
i think [9] (cited in the submission, but cited in another context) is particularly worth discussion in this context, given that it makes almost the same visualization in [9] in fig.1.	0
a lot of works are cited but they are not described sufficiently.	0
my first concern is that the related papers are not cited:  chatterjee and schwing, diverse and coherent paragraph generation from images.	0
a couple of concerns: 1. the work appears somewhat incremental in going from the cited gaussian model (he et al.) to a multivariate gaussian to a mixture of multivariate gaussians.	0
============= following are the things that could be improved in the future version of the paper but did not affect the score: ' figure 1 does not seem to be cited anywhere. '	0
for instance, in the last paragraph of sec 2, the author list is duplicated for all 7 cited papers as in “hodges and pollack designed machine learningbased systems hodges and pollack (2007)“ in all 7 sentences, the first reference should be replaced with citet{<hp07>}, and the last reference should be removed.	0
since i am not from the field of forecasting, i can not be sure of this, but from my understanding these benchmark datasets are indeed challenging and the cited references back up the claims of the paper related to these datasets being important in the field.	0
it is cited in this paper but i think the proper conclusion is the opposite of what is written here.	0
detailed comments: i see wei and ma ‘19 cited in the beginning only, but there is no further comparison.	0
also the results in the paper beat those of the gresnet on cora, but not on pubmed and , which is a recent paper not cited by this work.	0
section 5.1: 'p(x|y,z_s,z_u)' > 'p(x|y,z_s,z_u)'  in a number of places, i think the paper meant to cite [1] but instead cited the older kingma & welling (2013) paper; for instance before equation (6) (this additional loss did not appear in the original vae paper).	0
(4) lcns seem to present a less bulky alternative to e.g. deep neural decision trees (https://arxiv.org/abs/1806.06988), but that work should be cited and discussed (5) the proof sketch in section 3.6 of the equivalence between the 'standard architecture' and decision trees is difficult to understand and not convincing.	0
i agree that the authors extend a lot on this papers, especially in terms of dataset and completeness of experiments, but they are definitely closely related, and the fact that it is not cited is a serious flaw to the current version.	0
the authors claim many novel contributions, but most of them are special cases of existing literature (not cited), or are simple modifications to existing approaches.	0
here are some papers about recently proposed memorybased methods, which are not cited: castro et al. endtoend incremental learning.	0
a bunch of papers are cited in the introduction as doing this, but the relationship to the proposed work is unclear.	0
4) in section 2.2, second paragraph, the dsprite dataset is mentioned but not cited.	0
(2019) — not cited update: my two main technical concerns have been addressed in the rebuttal and i think that the revised version of the paper can be accepted to iclr (my comment w.r.t.	0
in particular, what was the precise architecture for a2c and the hyperparameter settings (particularly since the reference that is cited is not a paper, but a github repo).	0
similarly, in terms of formulating the discrete search problem as a reinforcementlearning problem, again there are similar works in the past, which are cited in the paper, but the combination of these two is novel to my knowledge; having said this the paper should discuss relevant works such as the one above.	0
future work can not only reproduce this work, but also the cited works.	0
some works are even cited in this paper, for example, optioncritic, feudal network, etc. these methods fix their skills in the new task, not because they are inherently not able to do so, but because they want to demonstrate that the learned skills can be reused in new tasks, even if there is no further adaptation.	0
branavan’s work (all but one cited languageinstructed agent papers are post 2017) as well as [4]  objectoriented and hierarchical rl  [5], where they train the neural programmer interpreter from the final reward only, which brings npi close to this work questions:  figure 5  there’s a mark for treernn, but treernns are not in any figure.	0
(2) unrealistic threat model:  for blackbox transfer, all the strongest attacks use multiple source models (see e.g. neurips 2017 adversarial examples contest, the baselines cited in the paper).	0
(already cited, but no comparison) [2] what’s in a name?	0
however, the approach is related to chen et al, which is cited in the text but not used as a baseline.	0
strengths: 1. the paper is well organized except the reference citation (read difficultly) 2. the proposed method is very simple and effective.	2
minor: section 2, most of these citations should not be shortcites but should be regular full cites.	0
27) as the other reviewer notes, the paper lacks clarity in many places, and does not sufficiently discuss prior work, including in postural control (there is one citation in the references that is not mentioned in the main text), hierarchical bayesian optimization within or without a gaussian processes framework (https://scholar.google.com/scholar?hl=fr&as_sdt=0%2c5&q=hierarchicalbayesianoptimization&btng=), or experience replay (https://scholar.google.com/scholar?hl=fr&as_sdt=0%2c5&q=replaymachinelearning&btng=).	0
the presentation of this section is also not very clear, e.g. the equation on page 6. the citation style look odd to me, often you use either something like '[2,3]', or something like 'dhillon et al. (2018)', but not '(2,3)'.	0
with these two comments, i would like to know better how the work positions itself to supervised dictionary learning: the paper is cited (albeit with an incorrect citation), but the positioning is not explicit.	0
the citation i suggested has been added but with inadequate acknowledgement.	0
major concerns: the theoretical result provided is just a citation of an existing proof, rather than a new contribution.	0
for example, the paper lacks awareness of, citation to and comparison with related work such as [15].	0
on gnnfilm's training stability and regularization: i am interested in the negative result described in the following sentence: 'preliminary experiments on the citation network data showed results that were at best comparable to the baseline methods, but changes of a random seed led to substantial fluctuations (mirroring the problems with evaluation on these tasks reported by shchur et al. (2018))' do the authors have any intuition about why the results are highly dependent on the random seed?	0
this literature is touched on shortly afterwards alongside the related proposed method in section 4.1 but only by a single citation.	0
'global shape and structure the group' > 'global shape and structure of the group'  ''anchor' agent (mehrasa et al.)' > year for citation  post review i appreciate the author addressing my concerns and making clarifications here in discussion and in the text.	0
the attention in citation networks are more uniform, but they behave differently in protein or molecule graphs.	0
the citation is given in the opening part of the introduction, in an enumeration, but isn’t revisited later in the text  not even here where the results of the model are introduced.	0
in section 5, the zerospeech challenges are mentioned briefly (with a single citation), but over the last decade there has been substantial work in this community specifically looking at exactly the main problem addressed in this paper (unsupervised speech representation learning).	0
lack of evaluations with variety of datasets (cifar10/mnist)/configurations (other bitwidth)  lack of the citation and comparison to many most recent works on binarized networks (except xnornet) comments: i consider this a wellwritten paper with great clarity and good empirical performance.	0
as an indication of the grammar and phrasing issues in the paper i have below included issues from just the first page of the paper:  “in real world”> “in the real world”  “have to made decision” > “have to make decisions”  “researchers steers towards” > “researchers have focused on”  “chess, best action” > “chess, the best action”  “it is independent of opponent and action history” > “it is independent of the opponent or action history”  “history actions” > “action histories”  “in early ages there are heuristic based system to assign different prior” > “early approaches employ heuristic based systems to assign different priors”  “try to convert the problem to a perfect” > “try to convert the problem into a perfect”  “explicitly with neural networks, and try to optimize it” > “explicitly with neural networks, trying”  (not a phrasing issue but i would have appreciated a citation for the claim at the end of the third paragraph of the intro)  “simulation based approach usually requires large” > “simulation based approaches usually require a large”  “sequences of existing player and opponent” > “sequences of the existing player and opponent”  “a few underlying complete information state” > “a few underlying complete information states” this issue of readability came up in the figures as well.	0
minor, but some of these citations can be updated.	0
minor concerns: inconsistent citation for pcfg in sec1 and sec4.	0
i’m not sure what the key citations in this area should be, but searching the web for “object center bias” yields several starting points.	0
besides the issue of coverage, there are quite a few parts that require citation, but no citation is provided.	0
on compressing ensembles:  model compression, https://dl.acm.org/citation.cfm?id=1150464  compact approximations to bayesian predictive distributions, https://dl.acm.org/citation.cfm?id=1102457  distilling model knowledge, https://arxiv.org/abs/1510.02437 on informationtheoretic measures for decomposing total uncertainty as in eq. (4):  decomposition of uncertainty in bayesian deep learning for efficient and risksensitive learning, https://arxiv.org/abs/1710.07283 '[knowledge uncertainty] arises when the test input comes from a different distribution than the one that generated the training data' this is only one way knowledge uncertainty can arise, it could also arise when the test input comes from the same distribution that generated training data, but there aren't enough training data available.	0
i think that result only applies with iterate averaging but it might still be useful (certainly as a citation suggestion).	0
minor comments: introduction: “after learning, the the (sic) activation of the deep network are considered as generic features.” not only is there a small typo, but you should either include a citation here or be more specific as to what “the activation” of the deep network is here.	0
i'm not familiar with the relevant literature, but this seems like a strong statement which i believe should be supported by a citation.	0
the paper is reasonably written (the proof of the main claim is fairly easy to follow), but needs to be carefully read through because i see typos and illformed sentences that should be rectified  e.g. see point 3. in appendix a.1  some facts about equation 4, missing citation in definition 1.2 amongst others.	0
strengths interesting nonparametric approach to estimating uncertainty in the agent's forward dynamics model clearly written paper with sufficient technical depth well structured discussion of related work weaknesses my main problem with the paper is a missing fair comparison to prior work.	2
strengths:  the paper is well written with high quality visuals and plots  the paper studies an important problem weaknesses:  the contribution seems to be rather incremental (evaluating existing methods on 2 dataset) and some related work might be missing  although the analysis is well executed, it is not clear what the community learns from the paper although i enjoyed reading the paper, i'd lean towards rejection of the paper.	0
i feel that this paper is not ready for publication at iclr due to the following major issues: ' missing important related work: this paper seems unaware of an important related work 'multitask learning for multiple language translation' by dong et al, acl 2015. in fact, dong et al. investigated the problem of learning a machine translation model that can simultaneously translate sentences from one source language to multiple target languages.	0
## strengths  bootstrapping a learned local distance metric to a global distance metric to reduce testtime planning cost is an interesting problem  the paper has nice visualizations / analysis on the toy dataset  the learning procedure for the local distance metric is clearly described  the paper uses a large variety of different visualizations to make concepts and results clearer ## weaknesses (1) missing links to related work: the author's treatment of related work does not address the connections to some relevant papers (e.g. [13]) or is only done in the appendix (especially for [4]).	0
strengths:  simple approach that seems to be giving good results  large number of adversarial attack scenarios tested  good related work review weaknesses:  results are reported without variance information  there are some details missing on how the decay factor is selected  results are reported only on one dataset (imagenet) the paper is well written, the authors have identified a 'problem' of resnetlike models and proposed an approach that can exploit the problem in adversarial attacks scenarios (sgm).	0
7. there are several gradient perturbation based dp algorithms [1,2] for solving highdimensional problems are missing in the related work.	0
(b) the paper is imprecise and missing important details in both the description of the method and the experimental verification (c) the paper misses important related work, which tackles the same problem.	0
strengths:  simple approach that seems to be giving good results  large number of adversarial attack scenarios tested  good related work review weaknesses:  results are reported without variance information  there are some details missing on how the decay factor is selected  results are reported only on one dataset (imagenet) the paper is well written, the authors have identified a 'problem' of resnetlike models and proposed an approach that can exploit the problem in adversarial attacks scenarios (sgm).	0
this is an extremely wellstudied problem, and many important references are missing in the discussion of related work [1].	0
the related work section is missing several methods that attempt to address the same problem.	0
the paper is missing references to several key pieces of related work tackling similar problems.	0
i think both the related work and experiments sections are missing many substantial contributions, as there is vast literature of work from operations research area about solving such problems through constraint optimization.	0
i have missed some references to related work on inverse problems.	0
the problem is formulated clearly, and the review on the polyak stepsize and related works are well done.	2
the paper does a good job motivating the problem and covering related work.	2
the paper is well written and the background / related work makes it easy for the reader to understand the problem's relevance within the related literature.	2
(b) in the related work section, very little is said about bin packing problems.	2
=== relevance & prior work ===  the related work gives a good summary and categorization of prior work in physicsbased learning  the problem (physicsbased learning) is interesting and relevant to the community === novelty & approach===  application of nas to physics based learning  incorporation of physics solutions as inputs into differentiable nas  creation of physicsinformed operation sets to merge physical models into network  technical steps to merge nas and pbl are relatively straightforward === evaluation === two representative physical simulations were chosen for evaluation, where elements of the physics model are intentionally omitted, 1) estimating trajectory of a ball in presence of wind and air resistance, and 2) a collision speed simulation where two objects collide, where sliding friction is not accounted for in the physics model.	1
the current paper has not discussed any related work of costsensitive learning although they want to study a problem in its field.	1
in the related work section for example, the paper notes that gating mechanisms have been used to handle the vanishing gradients problem.	1
## minor edit suggestions  fig 2 seems to define the blue square as the target, the text next to it describes the blue square as the agent, please make coherent  for fig 7: the numbers contained in the figure are not explained in the caption, especially the numbers below the images are cryptic, please explain or omit [novelty]: minor [technical novelty]: minor [experimental design]: okay [potential impact]: minor ################ [overall recommendation]: weakreject  the exposition of the problem and treatment of related work are not sufficient, the actual novelty of the proposed paper is low and the lack of comparison to strong baselines push this paper below the bar for acceptance.	1
although this reference is used in the experimental section, it would be appropriate to clarify the difference/contribution compared to this work in the intro, sec3, and/or related work as a naive reading of the paper incorrectly suggests it is the first to consider a data driven approach to this problem.	1
using a graph neural network for modeling latent physics is reasonable and has been shown to work on related problems before (see referenced work above and related work mentioned in the paper).	1
related work: recently, many papers have directly or indirectly handled the problem of exposure bias that this paper attempts to address.	1
i feel like experiments from related work don’t usually have such a problem.	1
finally  i found the positioning of the work of the work misleading: from the abstract and related worked we're told that this is a 'seemingly impossible problem' and prior work has relied on side information to deal with the inductive case.	1
at the moment, the theory section describes background information, related work and problem definition as well as the contribution of the paper.	1
as an example of a different approach towards the problem, which the authors overlook in their related work section, is that of learning with spiking neurons and point processes.	1
in order to make the paper more accessible to a general audience, the authors should: 1) have at least one sentence in the abstract that explains in layman terms why is cca important and how it works ('multiview learning' does not suffice); given that you have the term 'multiview learning' in the title, you should explain what it is and how it can benefit from cca 2) reorganize the current intro, which reads more like related work, into a more traditional format  one intuitive paragraph on what is multiview learning (mvl), what is cca, how does cca help mvl  one intuitive paragraph on an illustrative example on how mvl & cca help solving a problem  one intuitive paragraph on how the proposed approach works  one paragraph summarizing the main findings/results 3) ideally, add a section with an illustrative running example, which would have a huge impact on the paper's readability (far more than, say, than the current appendix)	0
the end of the related work section is not very clear, you say these methods are problematic because 'the adopted shaping reward yields no direct dependence on the current policy' but there's no explanation or motivation for why that would be a problem.	0
typos/unclear expressions: [p1] 'may not willing' >> 'may not be willing' [p1]'with the property similar to the original data is demanding' >> properties, demanded/in demand [p2] 'although gans are versatile as aforementioned'  strange wording [p2] 'the pioneered work' >> 'pioneering work' [p2] 'information of models' >> 'information from the models' [p2] effects >> affects [p3] related works >> related work [p3] distribution of label >> distribution of labels [p3] 'generated dataset adopt ' >> 'generated dataset will adopt ' [p3] 'to known about the boundary' >> ' to know the boundary'/'to include the information about the boundary' [p3] 'the a distance' [p3] 'the problem to distinguish whether two sets of samples' [p4] 'if they are close the sets might be sampled from the same distribution' (?)	0
the model presented here uses a pretrained vision module, which by itself is not a problem and is used in related work [1], but this vision module does not operate on visual input but the symbolic representation of the map.	0
older approaches (nonlocal neural network) are noted in related work under 'crfbased' but the authors do not expand on why these methods are not suitable to solve the problem at hand, or the fundamental distinctions between such approaches. ')	0
comments: ' 4th line of related work: parr > 'parr & russel' ' page 2, problem formulation: in beta(s,o), s is not defined.	0
other comments  1. the related work is comprehensive and sets the background well for the paper problem setup and contributions.	0
in order to make the paper more accessible to a general audience, the authors should: 1) follow the 1st sentence in the abstract by a new sentence that provides an intuitive example the idea of domain shift from labeled source to unlabeled target domain 2) reorganize the current intro, which reads more like related work, into a more traditional format  one intuitive paragraph about domain adaptation, source/target domain, and domain shift; provide at least one compelling illustrative example from a realworld application  one intuitive paragraph with an illustrative example on how the proposed approach will help solve a problem; at the same intuitive level, compareandcontrast it with existing approaches  one intuitive, indetail paragraph on how the proposed approach works  one paragraph summarizing the main findings/results 3) ideally, add a section with an illustrative running example, which would have a huge impact on the paper's readability	0
related work if the main concern of the paper is still the limitation of other methods which use expert knowledge then it is better to state the usage of additional data (development index) in social equity metric as a reward design part in appendix to justify this reward engineering “we believe that rl has the ability to solve the metro expansion problem” is the statement, which should be substituted by extensive literature review on rl methods used for planning with constraints or specifically graphbased expansion methods.	0
suggestions ' while the authors do bring up lots of related work on learning from noisy labels, the insights from that work, and its relationship to this proposed technique could be more productively explored ' the connections between the assumptions of the evaluation metric and the motivation for the smoothing methodology could be more productively elucidated ' the task explored in this paper, and the taskspecific problem, should be described more generally since iclr has a generalist readership.	0
the paper describes related work but the connection to the exact problem they are solving wasn’t 100% clear to me.	0
it provides a good discussion of why generalization is puzzling, related work on the attempts to improve generalization bounds for nns, and qualitative discussion of possibly answers to this problem.	0
the major problem of this manuscript, to me, is its ignorance of related work and, therefore, overclaiming at a few places.	0
but the most serious problem with this paper is a lack of references to related work.	0
the authors didn't provide a thorough literature review on mixing multiple styles in the related work or anywhere else in the submission.	2
the paper is missing references to some related work but is otherwise well written.	1
(1998)  the introduction is a bit long and a “related work” section is missing.	0
main contributions:  presents a causal discovery technique for the univariate cases that only examines the marginal distributions of x and y and seems fairly competitive (tables 1 and 2)  extends the postnonlinear identifiability analysis of zhang & hyv¨arinen (2009) from scalars to vectors and proved that their method will actually identify the correct causal direction  demonstrates competitive experimental results for both their univariate method  claims sota results for their multivariate method decision: i lean toward rejecting this paper because 1) i have several questions about the univariate case (see below) that would need to be resolved before i lean toward accept, 2) although i am not too familiar with the literature, i believe that this paper may be missing key related work that also uses independence testing for causal discovery (see, e.g., heinzedeml et al. (2017)’s invariant causal prediction for nonlinear models), and 3) i am not yet convinced that the comparison done in table 3 is fair and exhaustive.??	0
this submission cannot be treated as a contribution without showing an improvement on top of this extremely closely related work.	1
note that an important related work is missing, namely 'robust inference via generative classifiers for handling noisy labels' from icml 2019 (see https://arxiv.org/abs/1901.11300).	0
missing related work: 1st paragraph: compressing or distilling one network into another is much older than 2015, dating back to 1991  see references in section 2 of the overview http://people.idsia.ch/~juergen/deeplearningmiraculousyear19901991.html the gan principle itself is also much older (1990)  see references in section 5 of the link above.	0
from the related work section, the relationship between this paper and the previous work is somewhat complicated  it is hard for a reader not deeply familiar with these previous works to understand the unique contribution made in the submission, and assess why it is significant.	0
from the related work section, the relationship between this paper and the previous work is somewhat complicated  it is hard for a reader not deeply familiar with these previous works to understand the unique contribution made in the submission, and assess why it is significant.	0
4. for the experimental section and related work, another existing work is missing, i.e., 'neural logic machines'.	0
1 i guess there is an error on the first line (the integral is not over mathcal{x}     imes mathcal{x} / a union b given the previous definition missing related work dlow: domain flow for adaptation and generalization rui gong, wen li, yuhua chen, luc van gool; the ieee conference on computer vision and pattern recognition (cvpr), 2019, pp.	0
this is basically the more general model introduced by the authors of this submission in the beginning of section 2, without all the assumptions made in the rest of section 2. a comparison with this related work would help assess the differences in terms of modelling power and in performances.	0
whereas as mentioned yukun ding in a public comment there is a related work on identifying issues with popular uncertainty metrics, the mentioned paper is missing the through comparison of the methods for estimating uncertainty.	0
these omissions must be addressed as the introduction and related work is misleading in its current state.	0
there is some missing discussion of related works: 1. ensembledagger (menda 2018) also uses the variance of ensembles in imitation learning, but instead of using it to regularize onpolicy learning, it uses it as an improved decision criterion by which to query an expert demonstrator.	0
the paper is missing a 'related work' section that embeds the proposed algorithm in the literature.	0
the introduction needs a bit of work to separate the context of the present submission, the submission’s contributions, and the related work.	0
the first key missing comparison (imo) is to the inverting gradients approach from hausknecht & stone (2016), which the authors know about since it is cited in the related work section.	0
the first key missing comparison (imo) is to the inverting gradients approach from hausknecht & stone (2016), which the authors know about since it is cited in the related work section.	0
some of the missing related work (on populationbased diversity): diayn, learning selfimitating diverse policies, divide and conquer rl.	0
similarly, the model is trained on simple noise patterns  missing related work there is related work [1] in learning in hopfield networks using the implicit function theorem and finding stationary points of the dynamics.	0
regarding related work, the paper is missing a discussion of several relevant papers that use embeddings to obtain relative comparisons or estimates of commonsense properties of objects, including: forbes, maxwell, and yejin choi.	0
please clarify the differences between the literature and this submission in either introduction or related work section.	0
other missing recent related works include hiro [2] and hierarchical actor critic [3].	0
nits: missing c in 'contrary to these methods' in related work section conclusion: analized > analyzed [1] universal planning networks  srinivas et al. 2018 [2] differentiable mpc for endtoend planning and control  amos et al. 2018 [3] path integral networks: endtoend differentiable optimal control  okada et al. 2017 [4] mpcinspired neural network policies for sequential decision making  pereira et al. 2018	0
in general, i felt that this paper was missing related work which enforces orthogonality constraints in deep learning.	0
in addition to the above, other minor weaknesses of the paper includes typos, poor experimental practices, missing citations and related work, and other wording issues.	0
i'd like to see the authors' responses regarding the missing related work.	0
icml 2019. also missing related work for graphs: bloemreddy, benjamin, and yee whye teh.	0
i rated this paper as weak reject because this paper is weak on several aspects  in related work many similar approaches are missing (see below).	0
i missed having [1] and other similar approaches in the related work and how the proposed method compares to those directly promoting lowrank solutions.	0
i believe the authors missed some related work by tsuzuki, sato and sugiyama (2019), where a pacbayes bound was derived in terms of the hessian, via a secondorder approximation.	0
i also miss a discussion of these methods in the related work section.	0
i also feel some relevant literature may be missing from the related work.	0
however, this paper misses several related work in the literature.	0
for example, here's a list of a few of the works that were missed: kikuchi et al 2016 ficler and goldberg, 2017 wang et al, 2017 fan et al, 2018 baheti et al, 2018 see et al, 2019 martin et al, 2019 the related work section only focuses on very recent work, e.g. only one paper is discussed amongst a large body of existing work.	0
bo was also used for generating blackbox adversarial examples at https://arxiv.org/pdf/1907.11684.pdf this is a missing related work, and please elaborate on the differences.	0
and the paper misses this body of work in the related work.	0
8. add missing deep anomaly detection related work [6, 2, 5, 1].	0
3 the related work section misses significant number of prior work on continual learning (i have provided a short list at the end [4,5,6] but authors are strongly encouraged to read more on this literature).	0
2. the paper misses numerous citations to related work in generative 3d shape modeling:  voxel grid based, (since the authors mention them): [2, 3, 4, 5, 6, 7]  point cloud based: [8, 9, 10]  graph based: [11, 12] all these approaches propose various types of decoders for 3d shapes represented accordingly and some of them perform evaluations for pure generative, autoencoding task, which, again, can be used for comparison.	0
2. the paper misses numerous citations to related work in generative 3d shape modeling:  voxel grid based, (since the authors mention them): [2, 3, 4, 5, 6, 7]  point cloud based: [8, 9, 10]  graph based: [11, 12] all these approaches propose various types of decoders for 3d shapes represented accordingly and some of them perform evaluations for pure generative, autoencoding task, which, again, can be used for comparison.	0
2. missing related work there is a huge body of missing work in multiagent interactions modeling and generative modeling.	0
(the gradient of the quantile is zero almost everywhere due to the argmin) apart from the two key points above, the presentation of the paper is unpolished (nested lists in the main text, etc.) and major deep anomaly detection related work [10, 6, 5, 7, 3] is missing.	0
(i) some related work from two lines of research are missing that i believe might lead to interesting connections and insights in the future.	0
(b) missing related work that was publshed in icml 2019 that has a very similar approach in matching state distributions ('provably efficient imitation learning from observations alone' or fail) and works very well.	0
the related work section is missing many references to video prediction models, please add them to the paper.	0
the authors are recommended to compare with previous work on hierarchical generative modelings with objects and parts, such as (xu et al, iclr 2019), and other related work, such as spiral (ganin et al.) due to the limited contribution, lack of comparison with related work and limited empirical evaluation, i recommend rejection of the submission.	0
the authors are recommended to compare with previous work on hierarchical generative modelings with objects and parts, such as (xu et al, iclr 2019), and other related work, such as spiral (ganin et al.) due to the limited contribution, lack of comparison with related work and limited empirical evaluation, i recommend rejection of the submission.	0
some related work (detailed below) in other fields and just about curriculum learning seems to be missing.	0
sec 2.1: there's a whole line of related work missing here.	0
missing connection in related work: previous conditional generation methods (e.g., tacotron, deep voice 3) are autoregressive over time, but assume conditional independence over frequency bins.	0
a missing related work: 'shallowdeep networks: understanding and mitigating network overthinking', icml 2019. it also discussed how to append early exits to pretrained backbones.	0
some comparisons to related work are missing; while the comparisons would enrich the paper, their absence is not fundamentally limiting to the conclusions.	0
with respect to related work, i'm missing 'attentionbased deep multiple instance learning', by ilse et al. i'm not certain if it could be applied to the reconstruction task, but it seems that it should be a baseline for the classification task.	0
this paper should be rejected in my opinion due to the following four main reasons: (i) the technical quality of the paper is poor and the main idea not well explained; (ii) the experimental evaluation considers rather simple datasets (mnist, fashionmnist) and only includes two baselines (vanilla ae, ocsvm), but not any major competitors ; (iii) the work is not well placed in the literature and major related work is missing; (iv) the overall presentation is poor; (i) i find that subset scanning [7], seemingly the main component the approach, is not well defined and explained in the paper.	0
the paper studies an interesting task however it is not ready for publication:  empirical results of all baselines are missing (table 2)  other results are mentioned but are absent from the manuscript  the related work does not provide details as to how the proposed model to prior work  the figures are difficult to understand (although they do help make the model clearer and so i suggest polishing them for the next version of this work)  the manuscript should be carefully copyedited.	0
the reviewer is not working on related topics and is likely to miss related work.	0
the reviewer is not working on related topics and is likely to miss related work.	0
[3]: https://arxiv.org/pdf/1811.04551.pdf ### related work all good ### method  figure 1: the whole thing is not entirely clear  crucial details are missing, like how the action tiling and rollouts actually work.	0
the submission is interesting; however, its novelty is not even clear since authors did not discuss majority of the existing related work.	0
the paper is missing some notable related work:  s.r.k.	0
related work discussion was insufficient  related work section is missing and work is not adequately placed in the context of existing literature in the introduction where some related work is indeed discussed.	0
i have three main reasons for my decision (with more details in the next section): 1. the paper is very poorly written : a lot of details are missing in the paper, notation is not standardized, related work is just a list of previous papers without any context on how the proposed method is related, previous methods are referred to without any citations, and quite a few blanket statements which are not substantiated.	0
i am not very familiar with aes in general but i think that related work section needs improvement and the authors have missed out on few works that i found are closely related to their work.	0
however, i do not believe this comparison is adequate for neither of the two proposed extensions, as they differ in scope and more closely related work and relevant baselines have been missed.''	0
the authors didn't provide a thorough literature review on mixing multiple styles in the related work or anywhere else in the submission.	0
while the literature on manual design of architectures is thoroughly reviewed, there is missing related work in the context of neural architecture search, as already discussed above.	0
my current recommendation is very borderline (weak accept) because of a lack of some experimental rigour (which i would love clarifications on), and missing related work, which i mention below.	0
moreover, the authors seem to be missing on a longstanding line of active learning research known as querybycommittee (qbc) began in 1997 [3] in the related work section which should be cited as well.	0
moreover, the authors seem to be missing on a longstanding line of active learning research known as querybycommittee (qbc) began in 1997 [3] in the related work section which should be cited as well.	0
missing citations: a citation to 'beyond bleu:training neural machine translation with semantic similarity' from acl 2019 should be incorporated into the related work.	0
missing citations: a citation to 'beyond bleu:training neural machine translation with semantic similarity' from acl 2019 should be incorporated into the related work.	0
i suspect the related work is missing references, e.g. 'unsupervised discovery of parts, structure, and dynamics' xu et al iclr 2019. finally, the paper should be proofread for grammatical errors.	0
weaknesses: 1. related work: one of the major weakness of the paper is the missing related work.	0
unfortunately, the authors miss to cite and discuss highly related work [1] (icml 2019).	0
unfortunately, the authors miss to cite and discuss highly related work [1] (icml 2019).	0
this paper is also missing a related work section!	0
therefore, many related works are missing.	0
there is a lot of missing related work for sets: murphy, ryan l., balasubramaniam srinivasan, vinayak rao, and bruno ribeiro.	0
the related work is surprisingly short  either missing or briefly mentioning prior work without a discussion of similarities/differences.	0
the paper is missing a related work section describing state of the art methods to address stream data.	0
the only two (minor in my opinion) pitfalls of this work are (i) some related work is missing, and (ii) the novelty/originality of this work is rather limited as much in this paper is closely related to previous work [4].	0
the only two (minor in my opinion) pitfalls of this work are (i) some related work is missing, and (ii) the novelty/originality of this work is rather limited as much in this paper is closely related to previous work [4].	0
so i am concerned that the paper seems to miss this important related work.	0
related work section is missing majority of recent and existing work on distributed learning and federated learning.	0
regarding the first point, let's start with the related work that is missing some very relevant paper.	0
lots of related work fields are missing.	0
in terms of related work, references such as naturalparameter networks (npn) and its variants (one of which specifically handles the softmax case) are missing [1, 2].	0
in general, a related work section is vital here, but missing in the paper.	0
if my understanding is correct, then this paper is missing related works on neural networks generating weights (currently none are cited).	0
i vote for rejection because the paper makes some unfounded claims, misses important related work, has some methodological issues and presents unconvincing results.	0
i think the related work section is missing important areas of research in imitation learning and metareinforcement learning.	0
i recommend it be rejected due to lack of novelty and missing connections to much related work.	0
however, in my opinion there remain a few important issues with this submission: 1. there is no « related work » section to position bsuite within the landscape of rl benchmarks (ex: dmlab, ale / minatar, mujoco tasks, etc.).	0
finally, there is a bunch of related work that i think is missing.	0
discussion and comparison to very significant related work is missing and experimental measurement of any advantages of the proposed method vs. adversarial training is lacking.	0
cons:  some important previous works are missing from the related work section.	0
altogether, i find the paper borderline: it is clearly written but the methodological contribution is incremental, some citations to related work missing, and some parts of the results section are weak.	0
after author rebuttals: author have added discussion of related work which was missing in the original submission (thanks!).	0
additionally in the same context, a significant amount of related work is missing.	0
a discussion of related work on automl for multiple objectives is missing.	0
5. the introduction lays out connections to some related work, but leaves several relevant pieces missing.	0
2. missing important baselines in related work and experiments.	0
2) i think the related work is missing a large line of work on 'auxiliary tasks'.	0
# related work some related work on topology and deep neural networks is missing.	0
the related work is missing 'scaling memoryaugmented neural networks with sparse reads and writes' by rae et.al., which also uses sparse attention.	0
another related work is pullnet by sun et.	2
the contribution of this paper is clear to me: it is one of the first studies which investigates undersensitivity of the model when the input text after the perturbation is complete (e.g. in contrast to feng et al 2018 and other related work where the perturbation causes the input text to be incomplete).	2
this is applied as a systematic architecture change, rather than only after training is complete as in related work.	2
the related work section is extensive and thorough.	2
the coverage of related work is extensive and the contribution placement apt.	2
the related work appears to be extensive and the description of the design choices of the architecture and the training procedure is clear and thorough.	2
there is a large literature on this topic and the related work section should be written with more care and details.	2
the paper addresses a very important (efficiency) question in transformers, and gave a proper review to prior related works (such as child et al.).	2
after reading the author's feedback and other reviews, i think this paper has enough show contribution to the related work.	2
after reading the author's feedback and other reviews, i think this paper has enough show contribution to the related work.	2
the introduction and related work give a good overview of prior work on information plane theory, touching on the important contributions from tishby & zaslavsky [2015], schwartz ziv & tishby [2017], saxe et.	2
strengths:  good coverage of related work, including recent publications.	2
related work: the overview of sparse graph recovery for gaussian random variables is good and concise.	2
pros: ' good results on c10 ' a clear related work section that divides the existing works in pseudo labelling vs consistency ' interesting results about the effects of using different architectures.	2
previous work is well cited, and authors have a good overall map of related work (both older results and new papers).	2
previous work is well cited, and authors have a good overall map of related work (both older results and new papers).	2
it's a good scholarship to give proper credit to prior related work(s).	2
it is clear, wellmotivated, wellwritten, does a good job of connecting to related work, and presents an interesting method for structure learning.	2
=== recommendation === this paper is wellmotivated (improving speed of complete sat solvers) and presents a good overview of related work.	2
this is very different from the broader kbs and kgs discussed in the related work.	2
they show that early stopping prevents the learning process from entering the compression phase === related work === prior work is clearly presented and welltreated.	2
the related work seems to be well addressed.	2
the related work section is very well done.	2
the related work section is very short and mostly consists of an enumeration of references.	2
the related work section doesn't seem particularly well put together, so its difficult to place the work in appropriate context and gauge its impact.	2
the related work is well discussed.	2
the related work is comprehensive and covers most of the work in the domain of grammar induction and unsupervised parsing.	2
the related work covers many works.	2
the paper is wellwritten, references are given wherever needed and all the closest related work is covered sufficiently.	2
the paper is wellwritten and gives a nice overview on related work and in particular reweighted sampling schemes.	2
the paper is well written and easy to follow with nearly comprehensive related work.	2
the paper is very wellwritten, wellmotivated and wellpositioned with respect to related work.	2
the paper is for the most part well written, and related work well characterized.	2
the paper gives a broad overview of related work and situates the method with respect to previous option generation methods.	2
the motivation is very clear (many of the most challenging modern video games used as rl environments clearly have noisy observations, and many timesteps for which no new useful information is observed) and the related work is comprehensive.	2
the motivation is clear, related work sufficient and experimental settings and results convincing.	2
the main ideas and related work are presented clearly in sections 14, and the experiments compare topoae with a variety of lowdimensional visualization methods.	2
the 'introduction', 'related work', and 'experiment settings' sections are well written and covers many details and decent references.	2
the introduction, background and related work are adequate.	2
the introduction & related work section was very clear, and seemed to quickly get the reader up to speed.	2
the goals are clearly stated and the background (which is more of history), as well as related work, is comprehensive.	2
the contextualization of this work to related work  particularly selftraining and semisupervised training  is quite thin.	2
the background and related work section is informative and well structured.	2
the authors do a nice job of summarizing a lot of related work.	2
the analysis of related work is sufficient.	2
strengths  i really like the related work section.	2
specialized related work is discussed.	2
similarly section 1 and 2 repeat a lot of info on related work.	2
related work section: the related work section is nicely written.	2
pros: 1. the proposed method is clearly introduced 2. the differences between the proposed method and related work are clearly explained and demonstrated through ablation study.	2
pros:  the paper is well written, with sufficient background and related work section for the paper to be selfcontained.	2
previous and related work seems to be well referenced.	2
p2: the related work section is great.	2
overall, the paper is relatively wellwritten and wellpositioned with respect to related work.	2
other than that, the related work is written very clearly! '	2
it provides clear motivations and goals, as well as an impressively comprehensive related work that discusses their shortcomings.	2
it is wellwritten, wellmotivated, and wellpositioned with respect to related work.	2
in particular, the first four pages provide a nice overview of related work and a clear explanation of the gauge equivariance framework of cohen et al’19.	2
i think that this paper has treated well the related work and underlines well its contributions.	2
general: the paper is very clearly written, the method makes sense and the related work are both well explained.	2
close related work is also used for comparison.	2
c) insufficient description of related work.	2
b) section 2 is a combination of related work and proposed work.	2
5. include major related works as outlined above and clearly state the contribution of your work in context of the existing literature.	2
3. their coverage of related work and empirical comparison with existing work is sketchy.	2
3. the paper is wellpositioned in the related work and points to the correct deficiencies of the existing methods.	2
2. in the related work section, the authors discuss convergence rates of algorithms with constant and decreasing step sizes together.	2
the related work section is in the middle of the paper.	2
the related work is somewhat narrowly focused on the controlled program.	2
the paper is reasonably well written with a nice overview of the related work.	2
the paper evaluates on 6 datasets and compares different variants as well to related work on 2 datasets.	2
in the related work, you write 'the transformer provides us with a more structured memory for handling longterm dependencies', which sounds a bit odd.	2
the related work is adequately cited.	2
the related work is adequately cited.	2
i cannot comment on the related work as i am not familiar with the baselines mve & steve.	1
the related work section provides thorough review of different methods to decrease computational costs, including not only knowledge distillation, but also pruning, compressing and decomposition approaches.	1
the related work section provides thorough review of different methods to decrease computational costs, including not only knowledge distillation, but also pruning, compressing and decomposition approaches.	1
the paper provides a clear exposition of the method, succeeds to discuss related work it bases on, conducts a thorough experimental study providing convincing explanations for results and does not hide the limitations of the work (high computational requirements, optimization difficulties connected with training energybased model and the method used, limited approximation of the true energy).	1
my only concern is that although the related work section provides a thorough survey of the current methods in the literature, the authors did not demonstrate the performance of stateoftheart and compare their performance with them.	1
my only concern is that although the related work section provides a thorough survey of the current methods in the literature, the authors did not demonstrate the performance of stateoftheart and compare their performance with them.	1
the student after stagebeta also outperforms the teacher  something that was mentioned in the related work, but i would like more discussion around it specifically for table 4. another thing i was wondering was how important pba is for the teacher’s ability to be a good teacher.	1
potential improvements: (1) paper layout, to be honest, i'm not sure if figure 1 is really needed (2) related work section seems very long, would be good if it can be shorten and use the extra space for results display	1
it is still not obvious to me why maximizing the mi in the objective function would reduce the influence of potential distractors.` furthermore, the paper overlooks a good part of the related work on extending vaes to sequence data, published in the last 3 years and does not draw links to similar architectures.	1
while there is a lot of text spent discussing other work such as literature from cognitive science, this is not really that relevant to the present paper and that space would be better spent discussing related work from modelbased rl.	1
specifically: 1) i would like to see a comparison to probabilistic image colorization (pic) [1], which was mentioned in the related work section but not included in the comparison of colorization models.	1
related work:  note that additional methods than those cited in the paper have proposed to decompose the weights posttraining, e.g., denton et al., nips 2014; lebedev et al., iclr 2015. it would be worth discussing these methods.	1
on the related work side:  i am not sure whether the first paragraph is relevant for the current paper  in the second paragraph, i would mention instruction following and the recent survey on rl  language [4] remarks:  i am not a big fan of the initial citation.	1
on the related work side:  i am not sure whether the first paragraph is relevant for the current paper  in the second paragraph, i would mention instruction following and the recent survey on rl  language [4] remarks:  i am not a big fan of the initial citation.	1
on the related work side:  i am not sure whether the first paragraph is relevant for the current paper  in the second paragraph, i would mention instruction following and the recent survey on rl  language [4] remarks:  i am not a big fan of the initial citation.	1
i am not very familiar with this literature, and i imagine this paper would be of interest to folks outside the program synthesis space, so it would be very helpful to better explain this (also we note about related work).	1
i am not necessarily interested in an actual empirical evaluation, but including this in the related work section would likely be interesting for the reader.	1
however, in my opinion there are a few weaknesses in the paper in its current state: (1) the clarity of sections 3.13.2 could be significantly improved as currently the proposed probabilistic model framework is confusing and not welldefined; (2) the experimental results are provided only for embedding spaces of dimensionality 23 which significantly hinders performance of prototypical networks compared to having a much higher dimensional embedding space, so it would help to see comparisons of spe and pn using highdimensional embeddings; (3) the central idea and proposed model seem to be very close to those of [2] which is mentioned in the related work, so, please, list differences with this prior work in the updated version.	1
as i am not familiar with geometric methods, point clouds and related work, i wouldn't be able to judge the degree of novelty, beyond an educated guess.	1
=== small details in the related work section:  i would cite 'sutskever et al, 2014' for the lstm encoder, along with 'hochreiter & schmidhuber', and not only 'wu et al, 2016'  removing the nsp task was proposed in 'lample & conneau, 2019', not in 'liu et al, 2019'	1
=== small details in the related work section:  i would cite 'sutskever et al, 2014' for the lstm encoder, along with 'hochreiter & schmidhuber', and not only 'wu et al, 2016'  removing the nsp task was proposed in 'lample & conneau, 2019', not in 'liu et al, 2019'	1
the discussion of hypercube covers is repeated multiple times in the introduction and the related work section; i would suggest mentioning this only once as it does not have to a large bearing on the methods described in the paper anyway.	1
these' 'ranked by informative scores preserved on the input and output labels' => review grammar 'backpropagately' (not sure it is used correctly in this context) 'regards model compression' => 'regarding model compression' related work 'on the one hand, in paper shwartzziv & tisbhy (2017) they suggested' => 'on one hand, shwartzziv & tisbhy (2017) suggested' 'to open the box of neural networks with information' => vague statement, not clear the meaning of this.	1
the primary reason for this decision is that the authors do not provide sufficient comparisons to related work and models, either in the form of a literature review, or in the form of model benchmarking.	1
the primary reason for this decision is that the authors do not provide sufficient comparisons to related work and models, either in the form of a literature review, or in the form of model benchmarking.	1
thank you for addressing the comments about related work in an earlier thread (https://openreview.net/forum?id=rkgbyyhtwb&noteid=s1lv4r5qvs).	1
thank you for addressing the comments about related work in an earlier thread (https://openreview.net/forum?id=rkgbyyhtwb&noteid=s1lv4r5qvs).	1
tensor product representations have been used for embeddings before (but not with the goal of efficiency) (e.g. arora et al 2018) https://openreview.net/pdf?id=b1e5efc the paper covers related work briefly and does not compare experimentally to any other work aiming to reduce memory usage for embedding models (e.g. using upprojection from lowerdimensional embeddings, or e.g. this paper: learning compact neural word embeddings by parameter space sharing by suzuki and nagata.	1
tensor product representations have been used for embeddings before (but not with the goal of efficiency) (e.g. arora et al 2018) https://openreview.net/pdf?id=b1e5efc the paper covers related work briefly and does not compare experimentally to any other work aiming to reduce memory usage for embedding models (e.g. using upprojection from lowerdimensional embeddings, or e.g. this paper: learning compact neural word embeddings by parameter space sharing by suzuki and nagata.	1
without knowing related work on other protocols in detail, i suspect they probably work less well than neurcomm, simply because they allow for smaller messages only (f.ex., whereas they talk about 'policy fingerprints', they seem to submit the complete policy parameters to neighbors  that is not just a fingerprint).	1
while this idea has been explored in prior work (as noted in the related work section), the proposed idea seems like a useful contribution to the literature.	1
while this ablation study is useful, the performance of the proposed method cannot be accurately characterized without evaluation on the complete field of related work cited in the paper.	1
while this ablation study is useful, the performance of the proposed method cannot be accurately characterized without evaluation on the complete field of related work cited in the paper.	1
while this ablation study is useful, the performance of the proposed method cannot be accurately characterized without evaluation on the complete field of related work cited in the paper.	1
while the results section (and beyond) does in detail analyze the performance of the proposed model, the comparison to related work does not extend beyond the results tables.	1
unlike related work, this paper specifically is able to generalize to metatest even when the metatrain dataset is not made confusing enough (i.e. even when model can learn well from test data in metatrain alone), making it applicable to use cases where it is hard to make the dataset confusing.	1
this is not consistent and there might be a nonnegligible gain by the multiplelength decoding, so we only compare with singlelength decoding results of other related work for the sake of fairness.”  ghazvininejad et al report numbers with single length candidates as well (in table 5 of their paper), you could compare with respect to those for a fair comparison.	1
there are also some less critical, but still important aspects of the paper (related work, clarity of explanations, repetitiveness) which lead me to decide this paper is not currently ready for publication.	1
the weakest aspect of this paper is the presentation and writing; overall it seems rushed, took several readings (and some assumptions) to understand despite being familiar with relevant work, doesn’t contrast crisply with related work, overloads some notation, and doesn’t focus on possibly the most interesting aspect of the paper (in terms of seeing which subcomponents can be attributed for performance) — the ablation study.	1
the relative novelty over veegan is also limited, the description of the method is exceptionally similar to the description used in the veegan paper (going so far as to copypaste a figure straight from veegan without attribution), and the comparison to veegan in the related work section is not sufficiently fleshed out.	1
the relationship of 'classification' and 'eliminating catastrophic forgetting' to these tasks is not discussed, even though there is a whole section called 'classification' which seems like a misleading title for this section  it seems more like this is further description of your proposed method, along with some related work.	1
the related work section mentions some obvious points of comparison (note: see also https://science.sciencemag.org/content/364/6443/859.abstract).	1
the major contributions were well summarized in the bottom of page 1, the related work was discussed in sec 4.3, and the caveats of this new methodology were also given in sec 4.4. note that the proposed composite lossbased gradient clipping is applicable even on top of existing noiserobust losses, for example, the generalized crossentropy loss, and this serves as a convincing demonstration of the great significance of the paper.	1
the introduction simply analyzes some wellknown phenomenon in the literature, does not place this work well in the literature (even true in the related work section as well), and can mislead readers in believing that this work was the first to realize the importance of spatial transformation attacks.	1
the authors make the following contributions:'' 1. they show that qlearning trained on multiple tasks with a context variable as an input (an rnn state summarizing previous transitions) is competitive to related work when evaluated on a test task even though no adaptation is performed 2. based on these observations, they introduce a new method for offpolicy rl that does not directly optimize for adaptation but instead uses a fixed adaptation scheme 3. the new method leverages data during metatesting that was collected during metatraining using importance weights for increased sample efficiency ''overall, we believe the contributions are significant and sufficiently empirically justified.''                  	1
related work on hybrid vaegans is discussed in the appendix, not in the main paper.	1
recommendation: reject, because 1) the paper does not compute shapley interactions with the proposed formulation of subset feature importance, and 2) the paper does not acknowledge related work on interpreting feature interactions in prediction models beyond shap interactions [3,4,5] supporting arguments: the interaction definition shown in eq. 3 does not match the corresponding equation referenced in lundberg et al. [1].	1
questions/notes for the authors'  section 3.2, please explain the significance of lambda_x^c  please explain in the related work and/or introduce in more detail than you already have the differences and similarities between this work and your nearest neighbour “hierarchical representations with poincaré variational autoencoders” by mathieu et al. (2019).	1
pros • interesting approach to extend the framework in [1] to cnns, with use of masks and maskspecific loss • clear motivation for the network bandwidth limited use case cons • hardly any technical novelty because the core ideas are already presented as well as applied to the same task in [1] • it is very surprising that the authors do not even cite [1] in their paper, despite their work being extremely closely related to it • most of the discussion in the related work section is unrelated to the specific task they tackled in the paper (i.e., input/feature selection).	1
one of my main concerns, however, is that robustifying d in gan training is not a new idea for some readers [1], so they need more clarification on the novelty of the proposed method, e.g. by discussing about it in related work or by comparing the performance.	1
note that sec 3 related work cils description seems hard to understand.	1
minor comments:  conflicting notation: in the related work you use to denote a random gaussian, the same notation is used to denote the generator.	1
maybe the section 4.3 can instead go to prior work/related work rather than be described in this paper if it’s not being used very much.	1
lipton et al. (2018b) introduce a test distribution estimator to detect and correct for label shift.” >>> this is not exactly the right characterization of the related work.	1
in the related work part, the arguments on “weak label learning” cannot be used for partial multilabel learning is not accurate.	1
in terms of related work ,another work which can also be mentioned (although not directly related) is “darla: improving zeroshot transfer in reinforcement learning” which also uses disentangled representations for zeroshot transfer learning.	1
i lean to reject this paper because, in my opinion is very similar to ('bridging the gaps between residual learning, recurrent neural networks and visual cortex' qianli liao and tomaso poggio), which is not mentioned in related work.	1
however, the comparison to other approaches does not show a clear advantage, and the related work (and experiments) lacks recent techniques.	1
however, i propose to remove the paragraph titled “other less closely related work” as the connection to the current work is not clear, and the space could be used more effectively (see below).	1
despite these positives, i am not sure about accepting the paper because i feel the investigation methods and the results are both very specific to a particular sort of gan, and the writing (introduction, abstract, related work etc.) pitch the paper as being more general than it is, and claim the insights to be more applicable.	1
as the paper's related work section shows, this is not the first attempt to use 3d structure to create molecular representations.	1
as the author understands it, the current state of the literature of lyapunov methods for deep reinforcement learning can be summarized as: richards et al, 2018, classify stable region and learn neural lyapunov function for a safe exploration strategy berkenkamp et al, 2018: classify the stable region via gp, move there for exploration chow et al 2018 constrained mdps for discrete gridworld environments chow et al 2019 constrained mdps for continuous environments through a projection on the policy this work: actorcritic constrained policy optimization with a lyapunovbased value function critic in the introduction and the related work, too much emphasis is put on explaining stability and discussing methods like model predictive control (mpc) which do not benefit the rest of the paper.	1
as noted in the related work section, many contemporary policy learning approaches via variational inference are limited by their construction, selection of prior distributions, etc. the advantage of the proposed methodology is that it is capable of efficiently inferring the current environment and adapting the policy learning procedure accordingly.	1
as noted in the related work section this is not a completely new idea (cf. schmidhuber, ha et al.).	1
as noted in the related work section (section 2), multitask methods aim to use benefits from underlying common information that may be ignored in a singletask setting.	1
also related work section does not look like an exhaustive overview.	1
a very related work to this paper: l_{dmi}: a novel informationtheoretic loss function for training deep nets robust to label noise, where no restrictions have been made on the classdependent transition matrix and the proposed method does not need to estimate the transition matrix.	1
4) minor comment: in related work 'bayesian optimization has played a supporting role in several methods, including tu et al. (2019), where ....' however, tu et al. (2019) does not seem using bo and admm.	1
2. a related work section will be useful, especially for readers who are not familiar with lsm and node related literature.	1
1) in the last section of the related work, the work by wen & yin is said to be “not suitable for training common deep neural networks”.	1
• in related work, for “interpretable target models” the authors mentioned lime as an example of explainer functions that explains target models that are “very simple models may not be representative for the large and intricate neural networks used in practice”.	1
# singularities i looked at the papers citing the main related work (the ptc paper by schonscheck et al., 2018), and of the four listed in google scholar, one seems relevant in that it prominently cites schonscheck et al. and claims to improve upon it, but this work is not cited in the present paper: cohen, weiler, kicanaoglu, welling, gauge equivalent convolutional networks and the icosahedral cnn.	1
# singularities i looked at the papers citing the main related work (the ptc paper by schonscheck et al., 2018), and of the four listed in google scholar, one seems relevant in that it prominently cites schonscheck et al. and claims to improve upon it, but this work is not cited in the present paper: cohen, weiler, kicanaoglu, welling, gauge equivalent convolutional networks and the icosahedral cnn.	1
section 2.3 (i.e. related work on deformable object manipulation) states that 'our approach applies directly to highdimensional observations of the deformable object and does not require a prior model of the object being manipulated.”, and only cites prior work that assumes access to deformable object models.	1
although the paper cites (liu et al., 2018) as motivation for their framework, why does the proposed method does not compare to the other related work (i.e. works by xie)?	1
also in the introduction, you could consider referencing the following papers on robustness to different threat models: ' engstrom et al., 'exploring the landscape of spatial robustness' ' tramer and boneh, 'adversarial training and robustness for multiple perturbations'  in the related work, you reference a number of works for adversarial training but not the original idea in the paper by szegedy et al.  in section 3.1., the observation that the epsilonball around training examples can cross class boundaries is further analyzed in 'excessive invariance causes adversarial vulnerability' and 'exploiting excessive invariance caused by normbounded adversarial robustness' by jacobsen et al. typos ===== p.6 enumerator > numerator	1
review:###update 11/21 with the additional experiments (testing a new image, testing finetuning of handcrafted features), additions to related work, and clarifications, i am happy to raise my score to accept.	1
i would suggest the authors to resubmit when the paper is complete, maybe, start with related work and references.	1
the related work section is wanting  see below.	1
the related work section (sec.	1
related work.	1
related work.	1
other potentially related work.	1
i have read the related work section but can't figure out all the details.	1
i found many in the related work.	1
the paper would have been much stronger if it had a much more thorough evaluation of the properties and limitations of masac as well as better comparison with the related work.	1
improvement: 1. a more thorough discussion of related work would be helpful.	1
i would like to see better motivation, more engagement with a wider range of related work, and more thorough quantitative evaluations.	1
3. i hope the authors can provide a more thorough survey of related works.	1
2. i hope the authors can provide a more thorough survey of related works.	1
## suggestions to improve the paper (for 1) please add a more thorough treatment of the closest related works on semiparametric memory  learned visual planning  learned distance functions (some mentioned below [15]) to the main part of the paper, clearly stating differences and carving out which parts are similar and where actual novelty lies.	1
suggested improvements: in the related work section, the narrative of the paper would be clearer if the authors introduced why the metalearning literature is being reviewed.	1
for example, in the related work section, there is a review of work on multidomain and multimodel translation, as well as a nice summary of that review in table 1, it would be great to have that for the disentanglement property as well.	1
there is also this related work which may be good to discuss: latent normalizing flows for discrete sequences, https://arxiv.org/abs/1901.10548 in the particle analogy of the motivating example of section 3.1, it would be good to say explicitly that x is the position, u is the velocity and w is the force, to make the example even more intuitive.	1
so, it would be good to add a brief discussion of ganbased methods to the related work.	1
it would be good to include them in the related work as well.	1
if the related work and clarity of abstract/intro are improved, along with addressing false claims and some other relatively minor things, i think this could be a very good paper, and i would be happy to increase my score.	1
i think [1] would be a nice addition to the evaluation section as it tests for something qualitatively different than the various metrics from section 4. it would also be a good addition to the related work.	1
this paper would be greatly improved by an addition of a related work section.	1
the atari suite or the control tasks used in related work (e.g. diayn) would be my suggestion.	1
that may inspire future work and would be useful to mention in the related work. '	1
since this work is so similar in many ways to previous work i think the overall clarity of the paper would be improved, and the contributions clearer, if the work was better situated with respect to related work.	1
since this work is so similar in many ways to previous work i think the overall clarity of the paper would be improved, and the contributions clearer, if the work was better situated with respect to related work.	1
related works: 1. visual relationships: i would cite “graph rcnn for scene graph generation” since it is the most relevant work regarding the similarity of pipeline (using gcns).	1
other comments:  it would be useful to also point to the survey paper of ruder et al. (jair 2019) where the difference between alignmentbased and joint models is described in more detail and could inform an interested reader beyond the confines of the related work section in this paper.	1
other comments:  it would be useful to also point to the survey paper of ruder et al. (jair 2019) where the difference between alignmentbased and joint models is described in more detail and could inform an interested reader beyond the confines of the related work section in this paper.	1
one way to be convincing about the fact that this bound is interesting would be to provide some regime where we can see improvements compared with related work.	1
maybe braking the section into related work, background and methodology (where the main contribution is presented) sections would improve the paper readability.	1
less major: it would have been nice to include related work on other ways to encourage interfeature interactions, such as perhaps taking the outer product of the input with itself.	1
it would greatly benefit from a major rewrite, focused on fleshing out the novel / challenging / related work aspects of the work.	1
in general i found this subsection a bit confusing and hard to follow ' it would be nice to add xlm to the related work section, as the model architecture and losses seem similar (except without syntax).	1
in addition to discussing previous approaches in a related work section, some empirical analysis comparison would help contextualize this work as well.	1
i would've liked the related work section to elaborate more on the relationships between the insights in this paper and those of fujimoto et al. (2018a), since the paper says the insights are related.	1
i would suggest the authors to find more related work in the field of information diffusion, where researchers have long been focusing on competitive information propagation in social networks with multiple parties (such as political campaign and wordofmouth social marketing).	1
i would suggest adding it to the related work.	1
i would also recommend authors to include the following papers to the related work section: 1. riemannian approach to batch normalization [https://arxiv.org/abs/1709.09603]  respond to the rebuttal.	1
i would also like to put those observations in perspective with the evolutionary literature [1], and even provide a full paragraph in the related work section.	1
i particularly enjoyed parts of related work, the illustration of slicing in fig 1, and the illustrative examples in fig 3. i would suggest however, that the paper might benefit from placing sec 3.2 which describes the framework, before sec 3.1. fig 1 also belongs closer to sec 3.2 anyway.	1
i mean, if i were writing the paper, i would have considered and done many things, such as:  shortening the introduction  shortening the related work  making the presentation of the datasets more succinct  having only one figure that covers most of what is currently in figures 1 and 2  putting details of what seem more ancillary details like the treatment of background lines objects in an appendix  remove figure 3, which didn't convey much to me in the absence of more careful explanation of the model.	1
for this reason the last sentence of related work strikes me as false (although i would wholehartedly agree that the light task, as administered to humans, is indeed multiagent).	1
for superresolution evaluation, it would be more informative to list (at least in appendices) results for more downsampling factors than 3x (related work seems to examine 2x, 3x, 4x, and 8x).	1
first, regarding the related work, i think that the reader would be served better if the authors also list the recent works related to effect of network width on convergence and generalization (e.g., [1] and references that cite this).	1
first, regarding the related work, i think that the reader would be served better if the authors also list the recent works related to effect of network width on convergence and generalization (e.g., [1] and references that cite this).	1
comments: 1) i think you may ignore the highlyrelated work: yang and zhang, 'policy optimization with stochastic mirror descent', june 2019. since both papers are highlyrelated, i would suggest the author(s) have some discussions to differentiate two papers.	1
additional comments/questions ' the related work discussion would benefit from a discussion of how liu et al. 2018 and guo et al. 2016 reduce variance ' the computational complexity of the proposed method as compared to the baselines is unclear as is the scalability with dimensionality.	1
adding such related work would help better contextualize this paper.	1
a reference in related work as well as a comparison in experimental validation would be necessary and the novelty of this work is rather weak given the above mentioned 2019 publication.	1
a more significant restructuring however, is that this work would benefit from the related work being present the beginning of the work.	1
3) i would suggest rephrasing the last two sentences of the second paragraph in related work: 'also, these techniques consider ...'.	1
2. a direct qualitative comparison to related work would also be helpful.	1
1. given my limited knowledge in the literature on this topic, i would have appreciated a proper related work section.	1
============= to improve paper:  clarify motivation and how this would inform adversarial training highly nonlinear classifiers;  add related work for robustness to perturbation of linear models, or state that they don't exist;  clarify weaknesses in the claims.	1
## strengths  the language of the paper is clear and easy to follow  the paper covers the related work well  the provided explanations help understand the content of the paper  the analysis of how the information captured in the agent's representation changes over the course of a trajectory is interesting (more such visualizations in the appendix would be nice!)	1
# proposed improvements i would encourage the authors to address the major points listed above by: 1. including additional related work as context and clarifying the differences in scope with other unsupervised representation learning approaches throughout sections 13.	1
this may just be personal preference on my behalf, but i think a short treatment on vaes and optimal transport would be useful in the related work and background sections.	1
the related work section would be more instructive if it also gave some information about the limitations of the alternative deep learning approaches and how the proposed technique overcomes these.	1
the paragraph 'in section 4.1 [...]' in the related work section is somewhat redundant; i would suggest putting it at the beginning of the respective experimental section and merging it with the existing description there.	1
the intro needs several edits  there is too much literature that then gets repeated in the related works section and there is a whole paragraph (starting with 'we propose learning models...') that would be a better fit as overview in the method section (instead, here a 3 sentence summary would be enough  how is this model extending tung/cheng?).	1
paper organization: i would suggest moving the related work to after the background.	1
it would be useful to provide the full algorithm somewhere (e.g., using an algorithm 'box')  possible related work.	1
i would move section 5 (related work) to right after the introduction, as is common in conference papers and makes for smoother reading.	1
i would like to see an experiment that compares other works mentioned as related work.	1
the flow and logic of this paper was clean, and the authors stroke a good balance between being focused about the core contribution of the paper, and reviewing related work and introducing sufficient preliminaries.	1
the flow and logic of this paper was clean, and the authors stroke a good balance between being focused about the core contribution of the paper, and reviewing related work and introducing sufficient preliminaries.	1
the paper has a designated related work section but the entire paper reads from its abstract to conclusions constantly like a literature review.	1
the paper has a designated related work section but the entire paper reads from its abstract to conclusions constantly like a literature review.	1
related work: https://openreview.net/forum?id=rkvoxhaqy7 (ceb) that may result in a similar objective as wyner’s common info ' when comparing to jvae/jmvae, it seems like the main difference is suing a latentvariable in the decoder, but the framework is still the same.	1
post response update '' after reading other reviews i think my initial rating 8 might have been a bit higher and am adjusting to 6. fixing the discussion about related works , as other reviewers also mentioned, will improve the paper.	1
in the related work on semisupervised learning (section 3), the authors only review mixmatch but neglect other literature, e.g.[1,2,3,4].	1
in the related work on semisupervised learning (section 3), the authors only review mixmatch but neglect other literature, e.g.[1,2,3,4].	1
https://arxiv.org/abs/1609.09106 as a reviewer, i am a bit annoyed that made no effort to have a decent list of related work and that they delegate that work to the reviewers to do so.	1
https://arxiv.org/abs/1609.09106 as a reviewer, i am a bit annoyed that made no effort to have a decent list of related work and that they delegate that work to the reviewers to do so.	1
comments:  given that the authors give an implementation of the constrained rl agent as one of the key contributions of the paper, there is a glaring absence of mentioning related work on constrained reinforcement learning and reviewing the existing approaches in literature, in order to compare and contrast what the authors propose in this paper.	1
comments:  given that the authors give an implementation of the constrained rl agent as one of the key contributions of the paper, there is a glaring absence of mentioning related work on constrained reinforcement learning and reviewing the existing approaches in literature, in order to compare and contrast what the authors propose in this paper.	1
also, the other reviews and comments on existing work make it clear to me that the positioning to other related work was incomplete.	1
also, the other reviews and comments on existing work make it clear to me that the positioning to other related work was incomplete.	1
a related work can be https://openreview.net/forum?id=hjihtijvz .	1
a related work can be https://openreview.net/forum?id=hjihtijvz .	1
6) there is some potentially related work on conditional adversarial generative flows [5] that could be added to the literature review if deemed relevant enough.	1
6) there is some potentially related work on conditional adversarial generative flows [5] that could be added to the literature review if deemed relevant enough.	1
2) related work: i think authors need to do a more comprehensive literature review on generalization bounds.	1
generally, i believe that the work is wellmotivated and timely, the authors seem to have done a good job in citing related work (though admittedly i don't know much about this area), and the results are supportive of the claims of the system's usefulness.	1
some related work to this paper: 1. what makes a good story?	1
similarly, the proposed method is simple and intuitive (which is good), but it will help if there were more comparisons to set the paper in context of related work.	1
regarding belkin et al: sorry for the misunderstanding, i didn't mean to imply that it's highly relevant, but i thought it might be a good addition to the related work section as it also relates to the generalization of neural networks.	1
it will be good to see how the proposed approach compare with other related ones (three listed in related work) in the literature.	1
in the related work section, 1st paragraph, in the list of citations, it might be good to also include the work on maximizing mutual information between representation of the next state and representation of the skill (thomas et al, arxiv:1802.09484).	1
i liked the clarity of section 2. the 'related work' section is clear and presents a good overall picture of the field.	1
further, also on page 4, the authors discuss that the assumption on learning good rotation matrices relies on the assumption of rough/approximate isomorphism without citing a body of related work that actually investigated this assumption such as the work of sogaard et al. (acl 2018).	1
a good point of the paper is the related work section which provides a good and concise survey of various multiactor rl approaches: distributed rl, populationbased training and guided policy search (the last part about exploiting best information looks less relevant).	1
a good point of the paper is the related work section which provides a good and concise survey of various multiactor rl approaches: distributed rl, populationbased training and guided policy search (the last part about exploiting best information looks less relevant).	1
you mentioned in the related work that previous work (kurth et al., 2018) lets each worker sample from a local subset instead of performing a true sampling of the whole dataset.	1
you mentioned in the related work that previous work (kurth et al., 2018) lets each worker sample from a local subset instead of performing a true sampling of the whole dataset.	1
you listed a few of them: (ji et al., 2019; henaff et al., ´ 2019; tian et al., 2019; bachman et al., 2019) in the related work section.	1
you discussed further works in your related work.	1
you could also cite related work in adaptation to new class prior, class prior estimation, see below: didier chauveau, david hunter.	1
you could also cite related work in adaptation to new class prior, class prior estimation, see below: didier chauveau, david hunter.	1
while most related work was covered well, i believe the authors could have a more uptodate list of recent work that reconstructs trianglemesh representations from images [ac] (especially since several of these methods has an architecture that involves encoding and subsequent compositional refinement).	1
while it is described in related work, i found that description too highlevel to understand leo’s training objective, its mechanism for conditioning on the support set, etc. [] some inconsistencies.	1
what distinguishes it from related work?	1
what are the motivation, related work, and contribution?	1
what about the other works mentioned in the related work section, like tirinzoni (2018) or paul (2019)?	1
very strange claim (which is false, as far as i know) that curriculum learning has only been used in shallow networks emphasizes that the related work is lacking.	1
typos: line 11 in algorithm 1 > the label is wrong, i assume it's 'update the discriminator f_disc to maximize l_adv' related works that needs discussing:  drucker, lecun 91, 'double backpropagation increasing generalization performance' for other regularizer on the jacobian, discusses generalization rather than robustness.	1
this paper shows the resnet baseline achieve nearzero test accuracy but doesn't compare to other relevant baselines that are mentioned in the related work section: for example [bello et al, deudon et al., kool et al.] for the tsp.	1
this paper omits the related work part and does a rough introduction to two baselines (cdl and dropoutnet) in a confusing way in section 2. a concise and precise introduction to other methods will help the reader to better understand the related works and the advantages and disadvantages of the proposed method.	1
this paper is also ignored in the related work though referred to in some of the experiments.	1
this paper addresses an important question and provides a result that is of interest, however, the overlap between this and previous related work is quite significant.	1
this is also witnessed by some moderate repetition in the writing, e.g., between the introduction and the related work.	1
this is a well written paper that includes all the required background and related works, as well as an easytounderstand example that runs through the manuscript, explaining what the reader needs to know in order to appreciate the work.	1
they also mention a few snn works that work well on mnist in the related work section which actually have better accuracies than their model.	1
these two related work could also be cited.	1
these two related work could also be cited.	1
these things need to be discussed explicitly, with more than a sentence or two in the related work section.	1
these related work papers do some correlational experiments partly restricted in size, layers and architecture.	1
these methods in the related work section.	1
there's some related work on controlled text generation.	1
there's an additional psrrelated work that can be seen as learning representations for pomdps (guo et al., neural predictive belief representations, arxiv:1811.06407).	1
therefore more related work and discussions, and drawing connections with planning embedding and modelbased policy optimization are very helpful.	1
there is a lot of work currently trying to marry the model free with model based approaches for integrated planning and learning as the authors have mentioned in the related work section of the paper and also called out similar methods and techniques.	1
there has been already many works on variants of lstm, such as sru, fastgrnn, clockwork rnn and etc. but none of them are employed as the baseline model, or even mentioned in the related work.	1
there are related works that extend these ideas to graphs [5,6], and relational learning [7].	1
there are related works suggesting no loss in accuracy if the threshold is ~1e5 (y. sparse convolutional neural networks cvpr2015).	1
the work extends related work in translationbased property optimization [6].	1
the various qa works mentioned in the related work section address this, as well as work on theorem proving: https://arxiv.org/abs/1705.11040 furthermore, there has been at least one more previous work on table based verification against freebase tables: https://www.aclweb.org/anthology/d151312/.	1
the various qa works mentioned in the related work section address this, as well as work on theorem proving: https://arxiv.org/abs/1705.11040 furthermore, there has been at least one more previous work on table based verification against freebase tables: https://www.aclweb.org/anthology/d151312/.	1
the text in the related work seem to say the opposite, so i’m rather confused by your statement, please clarify.	1
the task is contextualized within an extensive description of related work both in amharic and other languages.	1
the significance of the paper is moderate as the key idea of learning disentangled latent variables has been studied, and the paper lacks of evidence to show the pure benefits of introducing z_x as well as the comparison with the related work [ref1].	1
the second issue is the comparison to related work, which omits both several key techniques in the literature and two related papers on universal approximation.	1
the related work section mentions that somvae and desom are 'likely limited by the absence of techniques used in stateoftheart clustering methods'.	1
the related work section is well summarized and they emphasize that the current work's primary motivation is to reduce training time while maintaining performance.	1
the related work section could be improved by including a section on the closely related work in the area of opponent modelling.	1
the related work section appears to be just a laundry list of methods.	1
the public commenters have already asked important questions about methodology and related work on neural programming that the authors have addressed in comments.	1
the papers starts to mentions related work that relates automaton's and counter machines with lstms.	1
the paper severely lacks in relation to relevant related work.	1
the paper presents results for 2 datasets (comparing with various related work methods).	1
the paper fails to cite related work, in particular on lowresource nmt (e.g. gu et al. universal neural machine translation for extremely low resource languages) and unsupervised translation (e.g. artetxe et al. unsupervised neural machine translation).	1
the paper fails to cite related work, in particular on lowresource nmt (e.g. gu et al. universal neural machine translation for extremely low resource languages) and unsupervised translation (e.g. artetxe et al. unsupervised neural machine translation).	1
the paper also provides reasonable coverage of a large amount of related work.	1
the overly simplistic statement about the limitation of our understanding of how dropout works are a little disappointing, particularly so when the authors themselves list this literature in the related work section.	1
the most related work is joshi 2019 and the authors show that the method used in that work (modification in attribute space) is inferior to modification in feature space still via attributes, as the authors proposed.	1
the model is evaluated and compared with related work on an objective evaluation (loglikelihood) and a subjective evaluation (mos), and is shown to be a tradeoff between memory footprint, generation speed and quality.	1
the idea is clear without that paragraph (from 'though newtonian physics also describes ...' to '... particles and their displacements')  you've failed to cite the very related work of [hafner et al.,2018][3] (better known as 'planet').	1
the general direction of this work is worthy of study, but the paper needs additional justification for its task, better discussion of recent related work, and more development of its regression models.	1
the experimental comparison could also be extended to include other approaches for domain adaptation across languages, discussed in the related work section.	1
the current section of related work (section 1.2) is more succinct than laying the right background information.	1
the connection and difference to that related work need to be clarified.	1
the concepts are easy to follow, the related work covers a lot of different but related domains.	1
the comparisons provided in the paper focus on specific aspects of each related work rather than the entire picture.	1
the closed related work seems to be bartlett et al. 2019 that study the convergence of gd in the case of linear networks.	1
the authors write in the 'related work' section that gmm with regularization was proposed by [verbeek et al. 2005], but it is an older idea  for example [ormoneit&tresp 1998] in section 3.1, the motivation for the maximization in eq. (2) is unclear.	1
the authors made several changes to the paper in response to my comments including removing section 4.1, fixing comments about related work, including details on the damping procedure, showing experimental comparisons to [1] along with an explanation of why the dynamics in this paper may be preferred for training gans, providing details on propositions 7 and 8 and including reference to [1], adding further assumptions on the functions, and attempting to make theorem 3 more clear.	1
the authors listed the difference from (glimer et al. 2017) and (li et al. 2017) in table 1, but ignored (pham et al. 2017) and (battaglia et al. 2018), which were also cited in the related work.	1
the authors listed the difference from (glimer et al. 2017) and (li et al. 2017) in table 1, but ignored (pham et al. 2017) and (battaglia et al. 2018), which were also cited in the related work.	1
the authors conduct experimental comparisons with prior related works using similar search spaces, as well as ablation of the novel components of their approach.	1
the authors are encouraged to include those works in the related work and in the empirical studies.	1
the authors also provide an extensive comparison to related work.	1
that being said, there are some issues that i feel needs to be addressed before the work can be published at a high quality conference, so i want to help the authors improve the work by highlighting important points that will make the work better: the related work section on metro network design is only a paragraph.	1
strengths: 'the discussed mi subject is important research area, the paper presents the vast related work, proven by the fact mi techniques appears in many recent models. '	1
some related literature on privacy in machine learning could be discussed in the related work section.	1
some of the new works in 3d object recognition and segmentation such as deep sdf(https://arxiv.org/abs/1901.05103), atlasnet(https://arxiv.org/abs/1802.05384), deep level sets (https://arxiv.org/abs/1901.06802), occupancy networks (https://arxiv.org/pdf/1812.03828v1.pdf), http://openaccess.thecvf.com/content_cvpr_2018/html/yu_punet_point_cloud_cvpr_2018_paper.html, adaptive ocnn (https://dl.acm.org/citation.cfm?id=3275050), https://arxiv.org/abs/1805.12254, 3d point capsule networks, http://t.cvlibs.net/publications/niemeyer2019iccv.pdf etc. can be compared with or at least contrasted in the related works.	1
some of my previous concerns (point 2 and 3) seems true for many related works in this area in general.	1
so promising work, but related work and experimental work need to be improved.	1
so i think it’s best to avoid the appeal to human behavior here (as well as in related work).	1
smaller concerns and questions:  there are a couple of instances where i found the claims of the paper with respect to related work to be overstated.	1
selfgoal proposing'  some more related works are [florensa 2017, savinov 2018] ' 'space associated environment'  i don't know what this means. '	1
see my detailed for other weaknesses in related work.	1
section 2 related work and section 3 background might be combined into one section.	1
secondly, this paper comes in the midst of many other works aiming to integrate different combinations of generative models, privacy, and distributed training (as pointed out in the related work section).	1
second, there is a very related work, “dong et al. unified language model pretraining for natural language understanding and generation neurips 2019” which also proposes a new pretraining approach for question generation and data augmentation for question answering.	1
right now that section has even more related work in it 3. include tsne hyperparameters in appendix 4.	1
related work: the paper really needs to make its claims more specific and position itself better with respect to related work.	1
related work: the authors cite airl, but could do a better job distinguishing between airl and the current work.	1
related work: several works with very similar intentions have been overlooked: ('a bayesian data augmentation approach for learning deep models, toan tran, trung pham, gustavo carneiro, lyle palmer, ian reid) uses gan during training for generating samples for data augmentation.	1
related work: khrulkov et al (2017) looks like a related work  especially related to how the way the adversarial perturbation is computed and backpropagation is performed.	1
related work, and expand their theoretical and/or empirical results to produce a contribution of sufficient novelty/impact.	1
related work we don't think this is the first time an rvae has been used for encoding action sequences.	1
related work on joint embedding, coembedding, labelembedding, and zero shot learning seem to be neglected totally.	1
related work is sufficient, the authors cite relevant papers with respect to convergence in deterministic and stochastic setting and present detailed comparison between their framework.	1
related work is covered to a satisfactory degree, but a discussion of some of the following closely related papers could improve the paper: ' chang et al., a compositional objectbased approach to learning physical dynamics, iclr 2017 ' greff et al., neural expectation maximization, neurips 2017 ' kipf et al., neural relational inference for interacting systems, icml 2018 ' greff et al., multiobject representation learning with iterative variational inference, icml 2019 ' sun et al., actorcentric relation network, eccv 2018 ' sun et al., relational action forecasting, cvpr 2019 ' wang et al., nervenet: learning structured policy with graph neural networks, iclr 2018 ' xu et al., unsupervised discovery of parts, structure and dynamics, iclr 2019 ' erhardt et al., unsupervised intuitive physics from visual observations, accv 2018 in terms of clarity, the paper could be improved by making the used model architecture more explicit, e.g., by adding a model figure, and by providing an introduction to the supair model (stelzner et al., 2019) — the authors assume that the reader is more or less familiar with this particular model.	1
related work is adequately cited.	1
related work is adequately cited.	1
related work covered mlps, regularization techniques, sparse networks, random forest models, and other feature grouping.	1
questions: while searching for related work, i found an earlier submitted version of this paper ('phrasebased attentions', submitted to iclr 2019).	1
questions:  related work: the ideas of diversifying solution paths and throwing away bad solutions are very popular in combinatorial heuristics.	1
possibly related work as relaxations to sat/smt solvers do exist in the literature.	1
please write a related work section.	0
please update your related work with methods such as elmo and bert and subsequent work.	1
please discuss the following related work adversarial training for free.	1
page 6 under theorem 1 typo: 'via the eulaer scheme' > euler scheme related work suggestions:  consider citing 'predictive uncertainty quantification with compound density networks' by kristiadi et al, as it uses a conditional model with multiplicative parametrization successfully.	1
overall, the related work section contains all relevant references to the previous works to the best of my knowledge.	2
overall this paper's contribution is the use of a vae (rather than an autoencoder as in related work) that contains a latent space regularized to favour learning cluster structure.	1
overall the paper is written in a coherent and selfcontained way, where the paper clearly states the related work and the contribution of this newly proposed work.	1
overall the paper can be a strong contribution if the methods are stated with less quantum computing jargon, the overall parameter size and speed of the different models is specified in the experiments, and more specific connections to related work are made.	1
other sections rely on explanations in the appendix or just refer to related work instead of providing context.	1
other baselines, including those mentioned in the related work, could also make the comparison more complete.	1
one main area for improvement is in the related work.	1
one issue is perhaps, very little in terms of related work.	1
on potential related work: gnnfilm is a 'selfconditioned' model which learns to apply featurewise transformations based on the activations at the current layer.	1
o in related work section: ?	1
none of the six references in the paper address anomaly detection for temporal data (e.g. ahrens et al. “a machinelearning phase classification scheme for anomaly detection in signals with periodic characteristics” 2019) or the extensive related literature of time series models (e.g pope et al. learning phaseinvariant dictionaries 2013, edwards and lee, using convolutional neural networks to extract shiftinvariant features from unlabeled data”, 2019), or more closely related work on shift invariant graph neural networks (e.g. gama et al, convolutional neural network architectures for signals supported on graphs, 2018).	1
my main concern is regarding the related work and experimental validation being incomplete, as they don't mention a very recent and similar work published in icip19 https://ieeexplore.ieee.org/document/8803498: 'optimizing the bit allocation for compression of weights and activations of deep neural networks'.	1
most of the approaches discussed in related work (e.g. shaping) are aimed at learning/designing more informative reward functions.	1
most importantly, i suggest the authors cite, discuss, and ideally compare with many related works from josh tenenbaum's group and sergey levine's group.	1
most importantly, i suggest the authors cite, discuss, and ideally compare with many related works from josh tenenbaum's group and sergey levine's group.	1
moreover, the related work seems to be properly included.	1
moreover, the authors have failed to provide connections to other related works, or even cite them, including papers that consider word embedding as asymmetric lowrank projections.	1
more minor points: in the related work section, the author could additionally mention distillation.	1
more about the clarity issues below for strong evaluation, comparison with malinin & gales (2018) work seems to be important since it was the only work also using uncertainties for ood detection in related work.	1
methods mentioned in the related work section (section 2.1) can also be compared to.	1
maybe you want to shorten the introduction and add an additional related work section at the end.	1
it's worth to mention it in the related work.	1
it seems to work pretty well in practice, but i wonder how it compares to other risksensitive rl algorithms (e.g. those cited in the related work section).	1
it seems to work pretty well in practice, but i wonder how it compares to other risksensitive rl algorithms (e.g. those cited in the related work section).	1
is related work adequately cited?	1
is related work adequately cited?	1
is related work adequately cited?	1
is related work adequately cited?	1
is related work adequately cited?	1
is related work adequately cited?	1
introduction and related work in section 1 are easy to follow.	1
in the section 3.4 comparison to related work, the author mentions many works aiming at defending against adversarial inputs.	1
in the related work, the authors distinguish their paper from that of agarwal et al. (2019) by claiming that they are studying the nontabular setting and they use the actorcritic scheme.	1
in the related work, it is mentioned that “[compared to gidaris & komodakis]… we differ in how we compose classifiers and the unified learning objective.” as mentioned, the generation scheme is a bit different, but i don’t see a difference in the learning objective between the two papers?	1
in the related work they mention some works from graph neural networks literature.	1
in the introduction and the related work section, these goals go unstated, making it difficult to determine how this paper compares to existing work.	1
in the experiment part, the author compares a related work fbnet, which uses the structure parameter   heta and temperature parameter     au to control the sampling.	1
in terms of related work guzdial and riedl’s 2017 “game engine learning from gameplay video” appear to use a very similar approach (but with opencv instead of supair and search instead of a graph network) as does ersen and sariel’s 2015 “learning behaviors of and interactions among objects through spatio–temporal reasoning”.	1
in summary, my suggestions for improving the paper are: 1) make sure & demonstrate (by adequate discussion of related work) the originality of the contributions: 1.1) the method for detecting the direction of causal arrows.	1
in some other related work (see c1), adversarial training can perhaps achieve the performance lift on both the adversarial examples and natural examples (if a tradeoff parameter can be well specified).	1
in particular, the updated related work and expansion of the empirical experiments.	1
in particular, in section 2 on the related work from psychology/neuroscience, little specifics are discussed to contextualize the current work.	1
in my opinion, the motivation of the paper is clear and the writing is easy to follow, but one potential limitation is the lack of comparison with recent related work, e.g., generate to adapt: aligning domains using generative adversarial networks swami sankaranarayanan, yogesh balaji, carlos d. castillo, rama chellappa https://arxiv.org/abs/1704.01705 deep transfer learning with joint adaptation networks mingsheng long, han zhu, jianmin wang, michael i. jordan https://arxiv.org/abs/1605.06636	1
in introduction section, this paper believes that the existing methods mainly follow two directions, i.e. probabilistic reasoning and data selecting; while in related work section, they are classified into three categories.	1
in fact, there is already a bit of duplication between the related works and introduction sections, so the paper could likely gain some additional realestate by combining these.	1
in effect, this equates cavazza et al. [aistats 2018]’s work with much less related work (e.g. bayesian interpretations).	1
in any case, i believe it could also be helpful to include a small discussion regarding computational complexity for the proposed approach and related work in the manuscript or appendix.	1
in addition, i have the following suggestions for improving the paper:  for the related work section, the authors may find the following papers on robustness of convnets to distortions interesting: ' manitest: are classifiers really invariant?	1
in addition, how bgpg is compared with other related work that also uses skill/policy embedding, instead of a flat po approach like trpo.	1
if the authors agree, it may be appropriate to include some discussion in related work.	1
if so, can you be more specific when characterizing related work? '	1
ideas are simple and incremental, even if i rely upon literature overview provided by the authors in the related work section.	1
i’d personally want to see a more expanded related work section that goes into some more depth into some of these papers, to be able to better judge the novelty of this contribution.	1
i vote for acceptance for the following reasons:  the paper is wellwritten, the motivation and comparison to related work is also clear.	1
i think this related work and other need to be mentioned in this section and the results need to be contrasted with existing results.	1
i think this is worth mentioning in the related work.	1
i think the title, introduction, and related work need to be revised more explicitly referring to weaklysupervised segmentation.	1
i think that the background and related work section could be more friendly written (considering the iclr audience).	1
i think it is necessary to add some discussion in the related work.	1
i think it could be significantly improved with a discussion of related work and better situating of the methods / more comparisons in the results.	1
i think an interested reader could learn much more from your paper if you discussed your model embedded in th related work rather than in isolation.	1
i suggest reducing the introduction and related work sections in order to expand on the description of their main contributions in much more details.	1
i strongly encourage the authors to cite [1] and [2] and mention them in the related works.	1
i mainly think that the structure needs to be improved and that vmpo needs to better related to closely related work.	1
i just want to know that the paper is doing due diligence regarding related work in this setting.	1
i highly suggest the author rewrite this part and has a separate section about related work and explicit describe the difference compare to others.	1
i have several comments/questions regarding the disccusion & related work section:  one link that might be worth pointing out regarding functional representation of context is that anp (or attencnp) can also be seen as giving a functional representations of the context; the anp computes a targetspecific representation of the context, which can be seen as a function of the target inputs.	1
i found myself going over and over back to the related work section to find references and acronyms.	1
i believe this is a sensible restriction which enables analysis beyond the setting of primary concern in alemi et al. (and other related work).	1
i am ambivalent about accepting this paper until we have a better coverage of related work.	1
i also wonder how the authors think of the related work from zhang et al: http://sound.csail.mit.edu/ , as they've also studied the effect of auditory and visual data in shape and material recognition.	1
i also suggest adding related work on semisupervised learning in the paper (see [4] for examples).	1
i also have a few suggestions/questions below: ' the ernie paper (https://arxiv.org/abs/1907.12412v1) is mentioned in the related work.	1
i agree that table 1 confirms the equivariance so that is great but it is less clear that the network is suitable for the pose task since the baselines seem very simple for the pose estimation experiment (and the related work covers a lot of prior work in this area) and again, without error bars it is hard to judge significance.	1
i actually like the merging of related work and introduction though; i think it could be nicely spaceefficient if things weren't so repetitive later.	1
however, the related works need to be revised and present the novelty of the work compared to some metric and distancebased learning algorithms.	1
however, the private and decentralized learning parts are rather incomplete from related work and experiment sense.	1
however, i was shocked that the authors seem to be unaware of the abundant related work in this area (see below).	1
however, i do have some rather serious concerns about the generalsum game results and several questions regarding the relation to related work and the experiment details that need to be addressed.	1
however, (1) the paper lacks any discussion of related work in terms of causal reasoning and partial observability, and (2) the experiments and analysis seem weak.	1
here's one more related work deriving intrinsic rewards from an ensemble of trained dynamics models: http://www.sciencedirect.com/science/article/pii/s0004370215000764	1
here are a few random remarks: about related work, 'balancing the objective and diversity' is also the central concern of qualitydiversity (qd) algorithms (see e.g. cully&demiris for a survey). '	1
here are a few random remarks: about related work, 'balancing the objective and diversity' is also the central concern of qualitydiversity (qd) algorithms (see e.g. cully&demiris for a survey). '	1
for similar intuitions in this direction, i recommend a related work: 'a.	1
for related work, papers on evolutionary strategies and the various selfplayinapopulation papers seem relevant, since these often take the form of having each worker i do a different perturbation that is later merged by a chief.	1
for related work, also cite topicalchat: towards knowledgegrounded opendomain conversations small grammatical errors 'recently, dinan et al. (2019) propose to tackle' > 'recently, dinan et al. (2019) proposed to tackle' 'which subsequently improves the knowledgegrounded chitchat.'	1
for prior visualization work, there is some related work from the adversarial rl literature (https://arxiv.org/pdf/1905.10615.pdf for a recent example), since adversarially attacking a policy tends to expose features that policy cares about.	1
for example: better caption for figure 2 explaining what is shown; presenting the pseudocode directly in the method overview and spending the rest of the section explaining the method; showing the related work before the experiments; etc. novelty the main novelty in my opinion is the application of compressive sensing methods to oneshot nas.	1
for example, the third paragraph in 'related work' is about the method proposed in the paper whereas the second and fourth are about related work.	1
for example, the impact of different training objectives could be studied further, and appletoapple comparison with many recently closely related work, such as cmc, cpc, deepinfomax, could be provided (the only such comparison is between stpuzzle and vie, when using 3dresnet, so it is hard to understand where the performance gain comes from).	1
for example, one possibility is to follow previous related work [2,3,4] and report quantities such as the number of “activeunits”.	1
for example, in “related work”, the authors mentioned that there are two publicly available datasets.	1
first, the comparison to (some very) related work is insufficient, and so the actual novelty is misrepresented (see detailed comments below).	1
final evaluation: the paper overclaims its contributions and ignores some very related work (e.g. [geifman & elyaniv, neurips 2017]), thus necessitating substantial revisions to the text.	1
experiments look less informative for comparing the proposed method with other existing methods for similar motivations (e.g., some methods introduced in related work) since there is only a trivial baseline by the original lime's method.	1
experimental validation is carried out on a standard zinc molecule generation benchmark (graphs with up to 48 nodes) and the reported metrics are competitive with recent related work.	1
even with some discussions on the related work with cache based lm and the work that use training examples explicitly, i feel it is a simple extension/usage of previous approaches.	1
even the citation to the some of the most related work has mistakes (e.g., inconsistent author names (melis vs.	1
even the citation to the some of the most related work has mistakes (e.g., inconsistent author names (melis vs.	1
e.g., one related work on blackbox softlabel/hardlabel attack https://arxiv.org/pdf/1907.11684.pdf thus, my initial rating is weak reject.	1
d) the idea of learning quantization under objective of interest using observed data distribution has been studied earlier (e.g. see marcheret et al., “optimal quantization and bit allocation for compressing large discriminative feature space transforms,” asru 2009), perhaps worth citing as related work.	1
currently, it mentions just 3 related work, and contrasts itself with one.	1
could the difference with related work in section 2 be discussed more precisely?	1
comparing with other related work will be appreciated, such as seqgan, leakgan, textgan, maskgan etc. d) two variants of the qdtc algorithm are provided.	1
compared to related work on a similar system (slalom), the proposed system enables secure training in addition to inference.	1
comments on experiments and related work:  experiments only show images of reconstructions of a vae and lsrgan, a mean squared error plot of reconstruction errors and an accuracy plot of a classifier evaluated on the reconstructions produced by both models.	1
check for backwards quotes in the related work section. '	1
can the authors point to related work supporting this assertion?	1
c. the last two paragraphs on page 4 seems to be related work, while there is a section called 'related work'.	1
but extending the current stateoftheart such as td3 [2] / pets i also suggest adding this benchmarking paper into the related work, which empirically studies the compounding error in different stateoftheart modelfree and modelbased reinforcement algorithms.	1
both uda approaches as well as data completion approaches have a sizable research history, as laid out in the related work section (section 5).	1
as mentioned in the related work section, one could use a more complex prior such as a mixture of gaussians or an architecture like [b] to do clustering.	1
as discussed in the related work, this work can be seen as complementary to many related works such as igl 18, but the novelty of the idea is rather limited.	1
arguments: 1) there are many works in multitask learning after luong et al., 2016, please refer them in the related work section (this section is very short!)	1
and it is more important to discuss them in the related methods section (2.1) rather than mentioning the most related works as the work that requires true ood sample when training.	1
an immediate related work is layernet, where a deep neural net is created by replicating the same layer.	1
all relevant and recent related work is included in my view.	1
al (2018): a closely related work in optimizing realvalued functions with domain {1,1}^n is hazan et.	1
after highlighting the said properties in context of related work, the authors propose an approach to calculate the contextindependent importance of a phrase by computing the difference in scores with and without masking out the phrase marginalized over all possible surrounding word contexts (approximated by sampling surrounding context for a fixed radius under a language model).	1
a second class of related work is goalconditioned rl [e.g., hindsight experience replay, temporal difference models, visual rl with imagined goals].	1
a quick search shows several related work in this domain, e.g., ‘an online incremental learning vector quantization’.	1
a proper related work section must be added to discussion the previous literature on understanding dropout.	1
a possibly related work is _early methods for detecting adversarial images_ (2016) since it uses covariance matrix information for detecting adversarial examples.	1
a minor point related to this one is that in the text style transfer related work subsection, there's even a reference to an mt paper as an example.	1
a few additional suggestions for related work: noisy channel approaches (eg, the neural noisy channel, yu et al, iclr 2017); decipherment (eg, beyond parallel data: joint word alignment and decipherment improves machine translation, emnlp 2014  yes, from smt days, but still); other joint modeling work (kermit: generative insertionbased modeling for sequences, chan et al, 2019).	1
9. more related work:  work that injects syntactic information into word representations in a supervised way, such as [1,2]  work that shows that word embeddings contain different kinds of information (syntactic/semantic), and propose simle linear transformations to uncover them.	1
7. it may be necessary to include these conditional face video generation works in the related work.	1
6. include major deep ad works [10, 6, 5, 7, 3] into the related work.	1
5. the related work section is quite light on other approaches to reducing model size, such as knowledge distillation or quantization?	1
5. it might be useful to refine the related work section.	1
5. it is stated that the paper is “the first to demonstrate flows across time steps for video data”, however, the related work by kumar et al. proposes a somewhat similar model in which conditional flows are used to model video data.	1
5) there is related work that you may need to consider: vaswani et al 2019, 'fast and faster convergence of sgd for overparameterized models (and an accelerated perceptron)' in aistats 2019. i think the paper still needs lots of work to be ready.	1
4. please consider separating out the description of related work into its own section.	1
4. it is essential to compare the method with other related works for bert and transformer compression, including quantisationbased, factorisationbased, pruning, knowledge distillation papers such as: prato, gabriele, ella charlaix, and mehdi rezagholizadeh.	1
4. inaccurate descriptions of some prior work: the related work includes certain statements that i believe aren't accurate.	1
4) the related work section is quite thin, and there are several other works that could be cited; currently they seem to be focused on just 'gradientsimilarity based continual learning' with a few other continual learning works.	1
4) the related work section is quite thin, and there are several other works that could be cited; currently they seem to be focused on just 'gradientsimilarity based continual learning' with a few other continual learning works.	1
4) in related work, authors mentioned the reinforce algorithm by williams et al 1992 is expensive.	1
3. in related work, deep svdd, anogan are introduced.	1
3. i found the related work well presented with most relevant papers, although i do think the kalman vae approach is highly relevant which needs to be cited and discussed.	1
3. i found the related work well presented with most relevant papers, although i do think the kalman vae approach is highly relevant which needs to be cited and discussed.	1
3. i believe, there is a factual mistake and arguable diminishing of the current state of the art in the related work section: the authors state, that both pcgan and pointflow models 'inhabit gan settings'.	1
3) there are several issues with the claims made by the paper about related work:  'we focus on selfattention in vision models, and we combine it with convolution, which as far as we know, are the first to do [...] while this is applied differently at each spatial location, we show that it is translation equivariant'.	1
3) considering there are a plenty of improvements of flow models, it is neccesary for the proposed method to compare with, at least for some methods explained in the related work section.	1
2. there is a related work [2] of reducing the privacy leakage of the feature representation, which also takes a view from the informationtheoretic view (i.e. a maximum entropy approach).	1
2. the related work includes major works from all the related lines of research (deep anomaly detection; ood detection using side information; adversarial examples/training) 3. useful hyperparameter selection criterion based on effective rank if no ood validation data is available.	1
2. the related work could be enhanced, while the preliminaries could be reduced.	1
2. related work: the paper talks about introducing a new ‘format’ of evidence (structured text) and talks about ‘unstructured text’ as the only ‘other’ format of evidence.	1
2. related work can be improved.	0
2. first paragraph in related work is very unrelated to the current subject, please remove.	1
2) the related work doesn’t discuss the latest papers which suggest why and in what ways the current search strategies are based for weightsharing based nas approaches.	1
2) i found some issues with section 2.2. a) first a comment on related work.	1
1.4. figure 3(c) visualizes that 2. related work: 2.1. the comparison to related work could be improved.	1
1) feature matching loss (eq 2) is presented as a novel contribution without referring to related work in semisupervised learning literature.	1
? authors provide the relevant related work and elegantly show how their work connects to the existing literature.	1
(see related work comments below.)	1
(d) there are a lot of things that needed explanation, especially in the algorithm (4) related work : (a) the related work section is just a dump of citations without giving any context for where the proposed work lies in the spectrum of these works.	1
(c) more on baselines and related work: in addition to [1], different variation of ensemble methods have been serving as active baselines in this field and i recommend adding one as a baseline.	1
(4) overview sections to motivate your solutions and your setup (i.e. an introduction, related work)	1
(2) with point 1, more related works on vae for domain adaptation need to be discussed.	1
#### minor:  spellings: 'pratical' > 'practical' (pg1, abstract); 'varible' > 'variable' (pg 3); 'simplifies' > 'simplify' (pg6, optimization of llc)  [2] seems to be a related work, as instead of using the global prior, they identify the task first (similar to localized prior), and then utilize it for better performance.	1
## feedback for improvement more related work: ' learning decomposed value functions for extrinsic and intrinsic rewards have been discussed in (burda et al, 2018b), though in their work a single policy is being learned. '	1
# related work my main concern with the related work section is that there a lot of literature on risk sensitive and optimism in the face of uncertainty (which is a subset of your method when c>0) in control, bandits, and some on 'reinforcement learning' that has been neglected.	1
with regards to inference networks on bnns, please cite 'latent projection bnns: avoiding weightspace pathologies by learning latent representations of neural network weights' by pradier et al, which attempts to do this and also discusses related work in more detail than this paper here.	1
with regards to inference networks on bnns, please cite 'latent projection bnns: avoiding weightspace pathologies by learning latent representations of neural network weights' by pradier et al, which attempts to do this and also discusses related work in more detail than this paper here.	1
when discussing related work, please look at the followup publication from hofer et al., which discuss more architectures and use cases: hofer et al., connectivityoptimized representation learning via persistent homology icml 2019  'topological geometry' on p.	1
'we are reaching' > we reach  frequent use of 'indeed' when it doesn't make sense  section 3 repeats the intro, 3.1 and 3.2 are sort of saying the same thing, and are also sort of repetitive of the related work.	1
to what extend your assumptions are comparable to the ones made in the close related work (papers presented in table 1) ?	1
there are some interesting discussions in the related work section.	1
there are some confounding factors in the experiments and there needs to be a better comparison to some related work.	1
there are a number of related works on adaptive spatial attention for faster inference, which can be included in the related work section.	1
the proposed method works with a variety of quantization approaches, such as binary, simple pq or lsq (even if the authors aren't able to report results for this last method due to technical issues as explained in appendix 7.7) weaknesses of the paper:  the related work could be more detailed, see for example: 'spreading vectors for similarity search', sablayrolles et al. ; 'pairwise quantization', babenko et al ; 'unsupervised neural quantization for compresseddomain similarity search', morozov et al. justification of rating: the paper proposes a new loss function that weights the scalar products differently according to their importance than can be applied to a wide range of existing quantization methods.	1
the paper needs to respect [1, 2] in the related work and show relations.	1
the paper is oblivious to a large body of related work in the area of relational learning and invariant/equivariant deep learning.	1
the paper could discuss more on related papers on program synthesis in the related work section as the main experiment is in this work.	1
the authors might be interested in related work on video generation with decoupled appearance and dynamics models, such as [1].	1
some related work references are dispersed in the introduction, in section 2, in the beginning of section 3.2, in the end of section 3.3 and in a few other places.	1
related work: how does this work relate to random search/evolutionary computation?	1
questions/comments: 1. please add a related work section.	1
page 3, related work: nedic at al. nedic et al. (2017) > nedic et al. (2017).	1
p.2: some of the related work discussion repeats content from the introduction  p.3: 'summaries' > 'summarizes'  p.3: what does that mean: 'has a high breakdown point of 50%'?	1
metz’19, metalearning update rules for unsupervised representation learning, is a conceptually relevant work that proposes to metalearn loss functions for unsupervised learning (and there is more recent related work on this topic too).	1
many very relevant and historically important papers are omitted from the related work section: e.g., hermann and blunsom's work, chandar et al., soyer et al., vulic and moens, gouws et al., levy et al., to name only a few.	1
it might be more useful to explain cem before the related work section or just moving the related work to the end.	1
in the related work section for dynamic neural networks, the authors claimed that 'most dynamic networks methods sacrifice accuracy in exchange of adaption in inference', but it seems to be quite overclaimed.	1
in section 5 qualitative analysis, the authors are also doing human evaluation like other methods in evaluation type4 of their related works.	1
in related work, there is a single paragraph (3rd) on work that explores similar tasks.	1
i'd suggest the related work section be broken into several paragraphs.	1
i suggest adding a related work section  consider moving lemmas 1 and 2 to the appendix, they don’t add much understanding in my view.	1
figure 4: labels (all text except plot titles) are impossible to read in print  section 3 could be placed before section 2, laying the mathematical framework, and then following the discussion with related work  there is redundant content in sections 2 and 3  i am happy with the authors response and changed the score accordingly	1
consider adding training times for more transparency  consider adding parameter counts in experiment tables  the related work subsection 2.3 is rather poor compared to existing work.	1
consider adding related work subsection on argmin optimization and metalearning.	1
authors fail to compile relevant works, particularly in semisupervised segmentation, leading to a very weak related work section.	1
a recent related work: “cross attention networks for fewshot classification.	1
a closely related work is the nlm model [1], which can perfectly generalized to new tasks.	1
but the reviewer is completely out of this neural network quantization area, and thus not very familiar with the related works.	0
the note in the related work section doesn't paint a clear enough picture.	0
review tl;dr: weak reject, for three main reasons: (i) while the existing literature around vaes, betavaes, and ratedistortion theory is mentioned in the related work, the connections are not nearly discussed sufficiently.	0
review tl;dr: weak reject, for three main reasons: (i) while the existing literature around vaes, betavaes, and ratedistortion theory is mentioned in the related work, the connections are not nearly discussed sufficiently.	0
minor comments not taken into account in the review'  section 2.1 'target policy pi via a precollected...' > remove 'a'  the layout of the related works section is a bit hard to follow.	0
i read the author response but i do not think the paper is ready for publication yet without the thorough comparison with related work.	0
the results presented on celeba and imagenet are interesting, in particular using different models is a good idea, however the evaluation relies mostly on a few cases or examples and i would have liked to see more quantitative results, e.g. like in figure 8 appendix f. note on related work: it has been shown (isolating sources of disentanglement in vaes by duvenaud et al., disentangling by factorising by kim et al., challenging common assumptions in the unsupervised learning of disentangled representations by bachem et al.) that betavae is far from optimal for “extrinsic” disentanglement, the text in section 4.1 should take these results into account.	0
## suggestions to improve the paper (for 1) add an experiment where the distractor has more natural dynamics so that there is mi between the distractor positions in consecutive frames (e.g. ball bouncing in the image frame in the background instead of randomly jumping to new positions) (for 2) add an experiment with a rewardprediction only baseline, i.e. only actionconditioned reward prediction so that taskirrelevant parts are ignored by default (i.e. also no reconstruction objective, but also no mi objective) > show how planet performance compares to the so far reported numbers when using this representation for planning (for 4) add details about the architecture, hyperparameters and training schedule, for both the method and all comparisons to the appendix (for 5) add references to related works that use cpcstyle mi objectives for representation learning in the context of rl/skill learning:  [1] nachum et al., iclr 2019  applies cpcstyle objective to hierarchical rl setting  [2] anand et al., neurips 2019  investigates mi objectives for representation learning on a wide range of atari games (don't apply to rl)  [3] gregor et al., neurips 2019  while the main proposed model is generative they compare to a contrastive version that uses cpc to learn predictive representations (don't use it for rl)  [4] guo et al., arxiv 2018  similar investigation to [3] of cpcstyle objective for representation learning in rl environments (don't use it for rl)  it should also be mentioned that the original cpc paper already showed that adding cpcstyle auxiliary loss to rl improves performance (even though they did not compare to other modelbased methods)  add qualitative rollouts for predictions from the planet predictive network both with and without distractor to the appendix ## minor edit suggestions  'learning latent dynamics from pixels', hafner et al. is cited twice in the reference section  it might help to add the reward prediction module to fig 3 or mention in the caption that it is omitted, it is only described later in the text and was confusing for me on first sight [novelty]: okay [technical novelty]: minor [experimental design]: okay [potential impact]: high ####################### [overall recommendation]: weakreject  i am inclined to accept this paper but am not fully convinced that the random distractors provide a good intuition about how the proposed method would behave with more natural distractors.	0
second, the paper has some room for improvement in terms of clarity, to name a few: 1) authors can strengthen the motivation for multiviews learning in related work; 2) formula 1 for softmax is wrong; 3) contrastive lstm and contrastive tree lstm are not clearly defined in the paper, although the former should refer to quickthoughts and the latter means the proposed method; 4) in qualitative analysis, for the last example, there is exactly the same candidate with similarity score 0.012. according to cosine similarity, wouldn’t this be 0 and also show up in the baseline model regardless of the embeddings?	0
major comments:  authors need to include more related work and describe the main related paper they mention (peterson et al 2018) as well as describe how their work fits in with previous work  while the idea here is novel and impactful, the experiments used to explain the importance of superordinate labels do have not much compelling information and are not well described  4.2 plots for visualization are mentioned to be in the appendix, but are not there minor comments:  fig2 large subordinate group text would help  lots of typos throughout and grammar mistakes o typo ‘use vgg16’ and then ‘vgg16’ in same paragraph bottom of page 4 o typo top of page 2 “convolutional neural network(cnn)” o appendix list – ‘banna’ typo under fruit o page 1 intro ‘for both behavioral and computer vision’ doesn’t really make sense o page 3 top section ‘new one’ should be ‘new ones’ o bottom of page 3 ‘room from improvement’ o last line of conclusion – ‘classificacation’ consensus: this is a very interesting and potentially impactful idea, but the experiments used to defend and explain the importance of superordinate labels are relatively weak.	0
major comments:  authors need to include more related work and describe the main related paper they mention (peterson et al 2018) as well as describe how their work fits in with previous work  while the idea here is novel and impactful, the experiments used to explain the importance of superordinate labels do have not much compelling information and are not well described  4.2 plots for visualization are mentioned to be in the appendix, but are not there minor comments:  fig2 large subordinate group text would help  lots of typos throughout and grammar mistakes o typo ‘use vgg16’ and then ‘vgg16’ in same paragraph bottom of page 4 o typo top of page 2 “convolutional neural network(cnn)” o appendix list – ‘banna’ typo under fruit o page 1 intro ‘for both behavioral and computer vision’ doesn’t really make sense o page 3 top section ‘new one’ should be ‘new ones’ o bottom of page 3 ‘room from improvement’ o last line of conclusion – ‘classificacation’ consensus: this is a very interesting and potentially impactful idea, but the experiments used to defend and explain the importance of superordinate labels are relatively weak.	0
another issue is that there is no comparison to other representation learning techniques (like those mentioned in the related work section, or the recent 'unsupervised state representation learning in atari'), nor to a natural and more straightforward variant of the proposed method where z would simply be sampled from a (learned) gaussian distribution z ~ n(mu(x), var(x)), which at first sight seems like an easiertooptimize objective (using the reparameterization trick)… i may be wrong, but then this should probably be explained in the paper (i realize that the proposed approach is more general, but then it should be shown how this extra flexibility can lead to improved results).	0
the whole of section 2 is standard textbook information about quaternions  would it not be more appropriate for that to be in the appendix and the related work to be in the main paper?	0
an improved version of this paper would make clear what the precise contributions are, explain how the related work did not achieve them, and why the specific comparisons were adopted.	0
note that there are more papers on the subject getting published soon such as mulcaire et al. (conll 2019) and liu et al. (conll 2019); while making comparisons to models introduced in those papers is not required, it would be nice to also briefly mention that latest work in the related work section once it gets published.	0
however, it is unfortunate that the paper does not take into account recent related advances in the field, e.g. https://icml.cc/conferences/2019/schedulemultitrack?event=4566 the paper should make this sort of related work review, discuss the differences from it, and perform extensive experimental comparisons.	0
however, it is unfortunate that the paper does not take into account recent related advances in the field, e.g. https://icml.cc/conferences/2019/schedulemultitrack?event=4566 the paper should make this sort of related work review, discuss the differences from it, and perform extensive experimental comparisons.	0
this paper should be rejected because (1) this method only combines existing techs, such as stochastic generative hashing (eq.1 and eq. 6), and lacks novelty; (2) lack of introduction to related work and baselines, (3) the experiments results can not support the claim, i.e. the effectiveness of cgh in marketing area, and (4) paper writing is awful and very hard to follow.	0
these methods are acknowledged in the related work, but i think they should be taken into consideration when describing this “critical limitation.” while not having an encoder does indeed hinder or prevent the use of an implicit model for inference, i think stability, mode dropping, and mode collapse are more prominent issues with gans.	0
the related work section focuses on gradient compression techniques (which tackle low bandwidth, not latency) and asynchronous sgd (which is more prone to congestion, with a single parameter server), but seems to overlook that sparse communication techniques already exist (this fact should at least be mentioned).	0
p4: followed < follow, n_{m1} < n_{m1} p67: section 6.1 should be in a related work section, and not under the experiment section.	0
other minor comments not related to decision: ' 'concrete autoencoders for differentiable feature selection and reconstruction' by abid et al. (2019) targets unsupervised feature selection but has enough similarities in the approach that it should be considered related work. '	0
minor comments / typos / suggestions (no influence on my rating):  infogan (chen et al., 2016) does not require a labeled dataset, the corresponding sentence in related work should be reformulated a bit.	0
i notice that this paper has been cited briefly in the small related work section at the end, but this really should feature earlier as it's not a great look to pass off an older method as something new (although this may be unintentional).	0
i notice that this paper has been cited briefly in the small related work section at the end, but this really should feature earlier as it's not a great look to pass off an older method as something new (although this may be unintentional).	0
however, the related work is not always well described, the experiments lack important comparisons, and the practical effects of pcgrad should be explained in more details instead of focusing on a proof for a convex case.	0
for example  in the introduction  'another closely related work is the the information…' in section 2  “in order to overcome this disadvantages' in section 2.20  'in optimization, it should be achieved by maximizing the information between z and z.'	0
especially, section 2.3., should not be a part of related work but should be integrated either to section 1 (introduction) or section 3.	0
disclaimer: i am not too familiar with this area of research and the related work and so my comments and evaluation should be taken into account in that context.	0
but the authors should not ignore all the finitesample bound results in their related work section, especially for those who achieving minimax rates.	0
5. the related work should add a discussion about stochastic sequential models such as kalman vae etc. paragraph 3 motivates your contribution as vae does not model sequential information.	0
this is not a paper where the related work section should be delegated to the appendix.	0
lack of algorithmic novelty is not an issue but the authors should at least discuss similarities to lml (amos 2019) in a clear manner in related work.	0
however, there are a few weak points which should explain my overall score: 1. the proposed gsm model is not new and only reuses building blocks from the related work.	0
4. i have not followed this topic much but it seems to me that there should be more related work on modelling annotators' competence and item difficulty for crowdsourced annotations.	0
(c.f point 2. of the decision section) i think that it is important to emphasize that in your work c_k are randomly sampled and then fixed (it is much more clear in [15], but i do not think that the reader should know the related work to realize that).	0
the references that 'are' listed in the related work are not properly reviewed: the authors aim to not compare with them claiming that they require retraining.	0
the references that 'are' listed in the related work are not properly reviewed: the authors aim to not compare with them claiming that they require retraining.	0
most paragraphs in the introduction section review the related work and background but do not introduce what assumption and strategy the proposed method adopted.	0
most paragraphs in the introduction section review the related work and background but do not introduce what assumption and strategy the proposed method adopted.	0
2) while my research is sufficiently close to review the paper, i’m not an expert on label noise specifically, so i cannot comment much on novelty and related work questions.	0
2) while my research is sufficiently close to review the paper, i’m not an expert on label noise specifically, so i cannot comment much on novelty and related work questions.	0
1. safegarding is the key point of this paper, but the authors did not review related works on safegarding.	0
i find the further experiments performed by the authors of very good quality overall, but i'm still not particularly satisfied by their `argument that the codebase itself is distinct enough from separate related work.	0
typo: 'they main takeaway' > 'the main takeaway' strengths:  good related work  somewhat complete evaluation weaknesses:  no analysis with so many hyparparameters (reg lambda, number of concepts), and thus not sure about the validity of the simulation  idea is interesting but straightforward  not very interpretable results	0
while the idea is interesting, the paper lacks precision in key areas and the method is not placed in context among related work.	0
thus, the related work session is so general and does not tackle the close models in details.	0
this is a well written paper but, in its current form, it isn't above the acceptance bar: (i) the idea of using consistency terms as regularizer is not novel and related works on consistency losses have not been adequately cited; (ii) the experiments are in general well executed but are not quite comparable with the stateoftheart.	0
things to improve: there are plenty of works related to graph autoencoders and graph generative models that are not mentioned in the related work.	0
these methods are not mentioned in the motivation or related work, which makes it hard to say this paper is wellplaced in the literature.	0
the three most pressing issues are as follows: 1. the proposed algorithm is not situated relative to related work.	0
the second contribution of learning a sampler given a density estimate is interesting but likely suffers from all the instabilities of gan training, and does not compare to related work on distilling energybased models.	0
the related work section does not include sample specificity method.	0
the related work in this paper is not enough.	0
the rebuttal does not address my major concern (motivation), nor does it discuss its relationship with related work.	0
the paper makes some claims on novelty which 1) partially overlap with prior work, or 2) it does not cite related work while it leans on its findings.	0
the paper makes some claims on novelty which 1) partially overlap with prior work, or 2) it does not cite related work while it leans on its findings.	0
the paper is not easy to read, and mixes various terms without introducing them (e.g presynaptic activity is used to introduce the method but never introduced, not even in related work).	0
the paper discussed many related works, but it's not clear why the specific methods were chosen for comparisons.	0
the notation is introduced in section 2, the background section, which is after the discussion of related work in section 1, where the notation is already used without being introduced.	0
the main concern that i have with the paper is the experiment depth: in specific, the paper does span a number of related works, but it does not empirically expose the systems comparison in sufficient detail.	0
the introduction and related work sections are incomplete and not very informative.	0
the description of dqfd and ddpgfd in the related work is not accurate.	0
the central points are:  the paper has errors,  the paper does not respect some related work and has been published previously in parts,  the paper has a claim that is unsupported in my view,  the paper is overcrowded with annoying marketing language; the word 'novel' appears 16 times according to my pdf viewer.	0
strengths:  the biological motivation is quite clear  architecture is simpler than that of previous related work (hgru) weaknesses:  not clear what the objectives/contributions are  no advancement of state of the art in computer vision  no novel insights about brain function  motivation of the 'texturized challenge' is unclear  performance on bsds500 is far from state of the art  value of the qualitative analysis on stylized imagenet is unclear overall, i'm not sure what the goal of this paper is.	0
related work:  learning for gradient descent: i am surprised these papers are not mentioned although they are quite relevant.	0
overall i think this is an interesting paper, however i am not familiar with all the related work.	0
noveltywise, i don't have enough background to tell if this is much of a leap from related work that has already proposed learning certain parameters of quantizers (but different parameters, or not the exact 2 proposed by the authors).	0
not including it in the related work is somewhat surprising to me.	0
more generally, there’s quite a few very relevant related works which are not cited here (see list below for a nonexhaustive list). '	0
more generally, there’s quite a few very relevant related works which are not cited here (see list below for a nonexhaustive list). '	0
minors: 1. the last paragraph 'we note that...' in the related work seems to be unrelated to the paper.	0
minor comments: 1. the summarization of the existing related work is not consistent throughout the paper.	0
minor comments  contrary to the summary in the related work section, kumar’19 does not use variational inference and operates purely on the normalizing flows technique.	0
many of which are not mentioned in the related work.	0
major comments ============= 1. the presented approach is very similar to chen et al, which is discussed in the related work section but not used as a baseline.	0
likewise, the experimental results here do not compare against any of the hierarchical learning approaches discussed in the related work section.	0
it seems like the fewshot experiments are kind of tacked on as an afterthought; the intro doesn't mention these and there are methods (e.g. logit matching) used here that are not mentioned in the intro/related work.	0
it reads as if the paper was written a while ago and the intro was not updated, since there is a lot of related work using the same concept.	0
it is listed in the related work that 'huang et al. (2017) applied realnvp (dinh et al., 2017) to learn the prior', which means the idea using the learned realnvp prior is not a new idea.	0
it does not compare with other related work.	0
it also gives the feeling that kottur et al. is the only valid experimental setting, which is not the case (at the authors pointed out in the related work section).	0
in the related work i'm not sure the concept of generations is right.	0
in sum, i think though the paper makes contribution on exploring better flow models but the novelty is relatively weak, the discussion and comparison of related work is insufficient and the experiments are not convincing or have mistakes.	0
in my opinion, the introduction and related work sections do not reflect what is proposed in the paper.	0
i think it's better not to spend so much of the related work section on this.	0
i must note that i am not familiar enough with the related work to judge the novelty of this work.	0
i am not very familiar with the related work but this seems to be sufficient number of baselines to assess the effectiveness of the approach.	0
i am not familiar enough with related work to evaluate this statement, but given it’s true, this is an interesting application of these ideas.	0
i also noticed several places throughout the paper where citations or related work seem to be misunderstood:  1st page, 2nd paragraph: this is not what griffiths (2010) is about, and is not really an appropriate use of the term “inductive bias”  2nd page, contribution 1: the paper claims that it is not dealing with a partially observable setting, but this is exactly what the paper is doing.	0
however, the novelty of this algorithm is not strong, given that the similar idea of 'predicting the behavior of other agents' can be found in related work with discrete action spaces.	0
however, the authors do not mention important reference (bai et al, 2014) until the very end of the paper in their conclusion: 'we notice some related work dealing with continuous rewards in this area'.	0
however, i don't think the paper in its current form has clear enough takeaways or strong enough results to make a publishable contribution  in particular, it's not clear that the model in fact advances our ability to capture composition, nor do the results clearly advance the state of the art, and the contextualization with respect to related work is too minimal.	0
however, i do have some concerns about the treatment/comparison to related work and i think without this it's not ready for publication.	0
furthermore, there is not even a related work section in the paper.	0
currently the related work is described extremely briefly and fairly obliquely, and it is not clear how exactly this work differs from other work that has involved prediction at multiple linguistic levels (or work on composition).	0
but the clear baseline is hartford et al. 2018 which also doesn't use side information for inductive matrix completion; and yet it is not mentioned in either the introduction or the related work sections.	0
as described in the related work section, the bbrt is closely related to jin et al. however, it is not clearly described what the major improvement over jin et al is.	0
although there is a reference, batch augmentation is not just related work but an important element of one of the two suggested training regimes (d).	0
additionally, in table 1 the method is compared with weak baselines (no da, flip, crop, but not the combination of flip and crop which is standard on cifar10) and it is not compared with any other approach (and there are several as shown in related work).	0
additional comments (do not affect score) it might be worthwhile to move the related work section to the beginning of the paper, either merged with the introduction or immediately after.	0
a symptomatic example of the lack of paper positioning is the related works section which does not even give a single reference !	0
a lack of many relevant citations indicates that the authors are not familiar with the related work done in this field over the past three years.	0
4. the experiment comparison is not complete given there are many related work in this area.	0
4. some related work in memoryaugmented lstms was not mentioned or compared with, e.g. rmc [santoro et al. 2018] and e3dlstm [wang et al. 2019].	0
3) the related work is not well cited.	0
3) the related work is not well cited.	0
3) the related work comparison is not sufficient.	0
2. why were more baselines from the related work not included?	0
2. the contribution of the paper seems not significant, as the idea of utilizing anchors to reduce the number of parameters to be inferred has been widely studies in the related work.	0
1. since many concepts are not from the machine learning domain, further and more detailed touch on related work are very beneficial.	0
[weaknesses] 'related work' the descriptions of the related work are not comprehensive.	0
with the above in mind, one thing that was conceptually unclear to me is that one of the main advantages of the proposed approach, according to the authors, when compared to some of the cited related work, is that this approach can generate intermediate representations and not just the final output with most resemblance to the reference picture.	0
with the above in mind, one thing that was conceptually unclear to me is that one of the main advantages of the proposed approach, according to the authors, when compared to some of the cited related work, is that this approach can generate intermediate representations and not just the final output with most resemblance to the reference picture.	0
two closelyrelated works are not cited: [li&hoiem, “reducing overconfident errors outside the known distribution” 2019] uses auxiliary dataset for ensemble distillation.	0
the introduction could be written to be more helpful, such as providing more context on why the obtained experimental results are important (e.g. getting stateoftheart results on the datasets studied in the experiments)  the related work contrasts with previous work which is not clear because the precise contribution has not been stated at the point.	0
related work does not seem very comprehensive.	0
related work at the last sentence of the introduction is not discussed correctly.	0
program synthesis on assembly languages: riscv [6], etc. 'related work' the descriptions of the related work are not comprehensive.	0
page 3, related work: pp model is not defined.	0
in 2. related work, saliencybased explanations, the paper refers to whitebox models but does not offer explanations as to why mask is chosen over other methods (gradcam, guided backprop etc).	0
experiments are not sufficient as the paper indicated in related work 'multiscale representations', this work belongs to the image pyramid method category.	0
the related work doesn't provide any discussion regarding that.	0
no related work.	0
limited awareness of related work. '	0
i found the related work discussion a bit incomplete.	0
the paper would be greatly improved by adding:  an intuitive paragraph in the intro that explains a concrete example of ds high level, but with enough details for the reader to grasp the idea)  adding a new section right after related work (and before the current '3.	0
in general, it would be good to be more thorough on how this paper is similar to related work and how it differs.	0
reasons to accept:  strong empirical results  thorough treatment of baselines and related work reasons to reject:  incremental contribution (especially compared to tsai et al., 2019)  writing lacks sufficient technical detail	0
even though the idea is interesting, i am inclined to reject this paper because there are many unclear details, the related work is insufficient and the paper needs a thorough proofreading in english.	0
moreover, the section on tcav should be in the related work, whereas how it is used for this specific case would be described in 3.3.	0
as for section 2 (related works), instead of mentioning so many works in literature, i would recommend you to cite review papers which can hold more information without taking much too much space.	0
as for section 2 (related works), instead of mentioning so many works in literature, i would recommend you to cite review papers which can hold more information without taking much too much space.	0
i would prefer this over the ‘qualitative results’ and some of the repetition in the intro to related work sections.	0
however, i must admit i fail to see the connection to attention, in the sense of the methods referred to as related work in section 2. if the authors feel their paper is indeed related to attention, i would encourage them to elaborate on this connection further, clarifying how exactly their method is related to those approaches cited in section 2. secondly, section 3 could be improved by more clearly separating original contributions from prior work.	0
however, i must admit i fail to see the connection to attention, in the sense of the methods referred to as related work in section 2. if the authors feel their paper is indeed related to attention, i would encourage them to elaborate on this connection further, clarifying how exactly their method is related to those approaches cited in section 2. secondly, section 3 could be improved by more clearly separating original contributions from prior work.	0
for related work, i would argue that an important class of algorithms to mention are rl methods based on imitating some sort of policy improvement procedure.	0
to push this review over the edge, the authors should address these papers in the related work, and discuss how this paper's method compares.	0
to push this review over the edge, the authors should address these papers in the related work, and discuss how this paper's method compares.	0
for instance, it disrupts the flow of the paper by having related works / lit review while describing the model (you should put this in a separate section).	0
when talking about weak supervision, the paper 'weakly supervised object recognition with convolutional neural networks' by oquab should also be mentioned in the related work section.	0
this should be an additional section in related work.	0
this paper should be discussed in more detail in the related work.	0
these methods should also be cited as related work and potentially use as baselines (squeezeandexcitation for example).	0
these methods should also be cited as related work and potentially use as baselines (squeezeandexcitation for example).	0
the second comment is that the paper should acknowledge the work of the geiger et al more explicitly, and cite as well the related work of spiegler et al (https://arxiv.org/abs/1810.09665) rather explicitly!	0
the second comment is that the paper should acknowledge the work of the geiger et al more explicitly, and cite as well the related work of spiegler et al (https://arxiv.org/abs/1810.09665) rather explicitly!	0
the related work should probably mention the recent cobra architecture [1], which also uses unsupervised scene decomposition combined with modelbased rl.	0
the related work should be first in order to understand the relevance of this paper.	0
the related work section should be updated to discuss the novelty of this work.	0
the related work section should also discuss and compare/contrast to gail, i was surprised that wasn't in there, especially since you also use a discriminator to differentiate expert and agent actions.	0
the properties of critical points of deep linear networks have been studied in many literatures, the authors should provide detailed comparison and discussion between the derived results and these related work in the surrounding text of theorems.	0
the latter two sections also have some information that should go in the related work (aka introduction).	0
the differences between this work and [1] should be elaborated more in the related work, since they are closely related.	0
the authors should have learned their work and addressed the difference between the proposed model and these work in the related work section.	0
the authors should have a more comprehensive related work section, which includes discussion on this part.	0
the authors should explore the differences among these tasks and maybe provide a related work for the utilization of hierarchical structure in nlp [1,2,3,4].	0
the authors should build a proper 'related work' section.	0
the authors need to include some discussion of this related work and probably should revise their model name so that it doesn’t seem like a totally new class of model.	0
the authors are suggested that they should give a subtitle of each categories of work in the related work section.	0
small remarks and questions for authors: 1. citation of valsesia at al. in the related work should be reorganized to be consistent with other citations.	0
small remarks and questions for authors: 1. citation of valsesia at al. in the related work should be reorganized to be consistent with other citations.	0
other points the related work section should be expanded by discussing relationships to: bai, song, feihu zhang, and philip hs torr.	0
org, 2017. as there is a lot of similarity in the motivations, you should discuss that line of research in your related work.	0
novelty, contribution and related work'' the authors should highlight better their main contribution novelty of the proposed method compared to their baseline.                  	0
main argument:  i think the results in section 3.3 should be put into context and mention related work.	0
lastly, i think [1] should be cited as related work about continual learning for proposing taskfree continual learning, which is very similar to the setting in this paper.	0
lastly, i think [1] should be cited as related work about continual learning for proposing taskfree continual learning, which is very similar to the setting in this paper.	0
it's largely the centerpiece of the (already cited) work of xu et al. (iclr 2019), and i believe that its relevance and relation to the authors' work should be better stressed in the related work section. '	0
it's largely the centerpiece of the (already cited) work of xu et al. (iclr 2019), and i believe that its relevance and relation to the authors' work should be better stressed in the related work section. '	0
in the related work section you should mention the use of bayesian utility theory to guiding exploration, e.g., https://arxiv.org/abs/1807.09647, also some of part of this recent book draft may be relevant: http://www.cse.chalmers.se/~chrdimi/downloads/book.pdf	0
in addition, the paper should also discuss its connections to other multitask learning approaches in the related work section.	0
i think there is a lot of material in the appendix that should really be in the main paper  i'm happy for the proofs to be in the appendix but i think it is a bit wrong to essentially violate the page restrictions by moving important related work into the appendix.	0
i think the physics dataset is also a contribution, so its originality & impact should be discussed in comparison to related work.	0
i think maybe the paper should involve some related work here regarding theory of compressive coding besides bafna et al. (2018).	0
here's a very closelyrelated work that should be cited and discussed: wang, xin.	0
here's a very closelyrelated work that should be cited and discussed: wang, xin.	0
for example, in the second half of sec.2 introducing two kinds of learning with rejection models, it should be included in a “related work” part.	0
for completeness, [1] should be included in the related work discussion.	0
either these should be included in the related work, or the authors should make it explicit that this work only deals with ‘textual’ evidence.	0
earlier descriptions of the tlstm should become a separate section called related work or background, or at least being clearly marked as previous work.	0
comments: 1. as regards the related work, i think that some references should be included.	0
comments/suggestions: —i think that coverage mechanisms used in nmt (tu et al., 2016) and summarization (see et al., 2017) should be included in the section of related work.	0
as one main contribution of this paper is in terms of the theoretical convergence guarantees, the related work should precisely mention the recent progress in this area and (maybe) point out the difference compared to the prior work.	0
and 'datadriven planning via imitation learning sanjiban choudhury, mohak bhardwaj, sankalp arora, ashish kapoor†, gireeja ranade, sebastian scherer and debadeepta dey', ijrr 2018. at least the last paper should be cited and discussed in related work.	0
and 'datadriven planning via imitation learning sanjiban choudhury, mohak bhardwaj, sankalp arora, ashish kapoor†, gireeja ranade, sebastian scherer and debadeepta dey', ijrr 2018. at least the last paper should be cited and discussed in related work.	0
a related work section with no related works in it appears to have a limited interest to me... this section should at least introduce other works in the field of graph embedding, such as those reported as baselines.	0
a lot of the context and background that was sent to the appendix should be included in the main paper, particularly the relation to related work edits: double ‘the’ in abstract “linear complexity in the the data “	0
7. some closely related work should be discussed in the paper, such as [1] 'decorrelated batch normalization.'	0
6. the differences from a closely related work [3] should be discussed.	0
