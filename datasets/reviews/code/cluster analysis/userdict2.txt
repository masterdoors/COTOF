activation
activation function
natural language process
additive noise
autoencoder
Autoencoders
average firing rate
average sum-of-squares error
backpropagation
basis
basis feature vectors
batch gradient ascent
Bayesian regularization method
Bernoulli random variable
bias term
binary classfication
class labels
concatenation
conjugate gradient
contiguous groups
convex optimization software
convolution
cost function
covariance matrix
DC component
decorrelation
degeneracy
demensionality reduction
derivative
diagonal
diffusion of gradients
eigenvalue
eigenvector
error term
feature matrix
feature standardization
feedforward architectures
feedforward neural network
feedforward pass
fine-tuned
first-order feature
forward pass
forward propagation
Gaussian prior
generative model
gradient descent
Greedy layer-wise training
grouping matrix
Hadamard product
Hessian matrix 	Hessian
hidden layer
hidden units
Hierarchical grouping
higher-order features
highly non-convex optimization problem
histogram
hyperbolic tangent
hypothesis
identity activation function
IID
illumination
inactive
independent component analysis
input domains
input layer
intensity
intercept term
KL divergence
KL divergence
k-Means
learning rate
least squares
linear correspondence
linear superposition
line-search algorithm
local mean subtraction
local optima
logistic regression
loss function
low-pass filtering
magnitude
MAP
maximum likelihood estimation
mean
MFCC	Mel
multi-class classification
neural networks
neuron
Newton's method
non-convex function
non-linear feature
norm
norm bounded
norm constrained
normalization
numerical roundoff errors
numerically checking
numerically reliable
object detection
objective function
off-by-one error
orthogonalization
output layer
overall cost function
over-complete basis
over-fitting
parts of objects
part-whole decompostion
PCA
penalty term
per-example mean subtraction
pooling
pretrain
principal components analysis
quadratic constraints
RBMs
reconstruction based models
reconstruction cost
reconstruction term
redundant
reflection matrix
regularization
regularization term
rescaling
robust
run
second-order feature
sigmoid activation function
significant digits
singular value
singular vector
smoothed L1 penalty
Smoothed topographic L1 sparsity penalty
smoothing
Softmax Regresson
sorted in decreasing order
source features
sparse autoencoder
Sparsity
sparsity parameter
sparsity penalty
square function
squared-error
stationary
stationary stochastic process
step-size
supervised learning
symmetric positive semi-definite matrix
symmetry breaking
tanh function
the average activation
the derivative checking method
the empirical distribution
the energy function
the Lagrange dual
the log likelihood	      
the pixel intensity value	
the rate of convergence	        
topographic cost term	       
topographic ordered	      
transformation	               
translation invariant	        
trivial answer	            
under-complete basis	       
unrolling 	                
unsupervised learning	  
variance	                 
vecotrized implementation	
vectorization	             
visual cortex	            
weight decay	        
weighted average	         
whitening	             
zero-mean	     
Accumulated error backpropagation	
Activation Function	
Adaptive Resonance Theory/ART	
Addictive model	
Adversarial Networks	
Affine Layer	
Affinity matrix	
Agent	
Algorithm	
Alpha-beta pruning	
Anomaly detection
Approximation	
Area Under ROC Curve／AUC	Roc 
Artificial General Intelligence/AGI
Artificial Intelligence/AI	
Association analysis	
Attention mechanism	
Attribute conditional independence assumption	
Attribute space	
Attribute value
Autoencoder	
Automatic speech recognition	
Automatic summarization
Average gradient
Average-Pooling
Backpropagation Through Time
Backpropagation/BP
Base learner	
Base learning algorithm	
Batch Normalization/BN	
Bayes decision rule	
Bayes Model Averaging／BMA	
Bayes optimal classifier	
Bayesian decision theory	
Bayesian network	
Between-class scatter matrix	
Bias	
Bias-variance decomposition	
Bias-Variance Dilemma	
Bi-directional Long-Short Term Memory/Bi-LSTM	
Binary classification	
Binomial test	
Bi-partition	
Boltzmann machine
Bootstrap sampling	
Bootstrapping	
Break-Event Point／BEP	
Calibration	
Cascade-Correlation	
Categorical attribute	
Class-conditional probability	
Classification and regression tree/CART	
Classifier	
Class-imbalance
Closed -form	
Cluster	
Cluster analysis
Clustering
Clustering ensemble	
Co-adapting	
Coding matrix	
COLT	
Committee-based learning	
Competitive learning	
Component learner	
Comprehensibility
Computation Cost	
Computational Linguistics	
Computer vision	
Concept drift	
Concept Learning System /CLS	
Conditional entropy
Conditional mutual information	
Conditional Probability Table／CPT	
Conditional random field/CRF	
Conditional risk	
Confidence	
Confusion matrix	
Connection weight	
Connectionism	
Consistency	
Contingency table	 
Continuous attribute	 
Convergence	 
Conversational agent 
Convex quadratic programming	 
Convexity	 
Convolutional neural network/CNN	 
Co-occurrence	 
Correlation coefficient	 
Cosine similarity	 
Cost curve	 
Cost Function	 
Cost matrix	 
Cost-sensitive	 
Cross entropy	 
Cross validation	 
Crowdsourcing	 
Curse of dimensionality	 
Cut point	 
Cutting plane algorithm	 
Data mining	 
Data set	 
Decision Boundary	 
Decision stump	 
Decision tree	 
Deduction	 
Deep Belief Network	 
Deep Convolutional Generative Adversarial Network/DCGAN	 
Deep learning	 
Deep neural network/DNN	 
Deep Q-Learning	 
Deep Q-Network	 
Density estimation	 
Density-based clustering	 
Differentiable neural computer	 
Dimensionality reduction algorithm	 
Directed edge	 
Disagreement measure	 
Discriminative model	 
Discriminator	 
Distance measure	 
Distance metric learning	 
Distribution	 
Divergence	 
Diversity measure	 
Domain adaption	 
Downsampling	 
D-separation （Directed separation）	 
Dual problem	 
Dummy node	 
Dynamic Fusion	 
Dynamic programming	 
Eigenvalue decomposition	 
Embedding	 
Emotional analysis	 
Empirical conditional entropy	 
Empirical entropy	 
Empirical error	 
Empirical risk	 
End-to-End	 
Energy-based model	 
Ensemble learning	 
Ensemble pruning	 
Error Correcting Output Codes／ECOC	 
Error rate	 
Error-ambiguity decomposition	 
Euclidean distance	 
Evolutionary computation	 
Expectation-Maximization	 
Expected loss	 
Exploding Gradient Problem 
Exponential loss function	 
Extreme Learning Machine/ELM	 
Factorization	 
False negative	 
False positive	 
False Positive Rate/FPR 
Feature engineering 
Feature selection 
Feature vector 
Featured Learning 
Feedforward Neural Networks/FNN 
Fine-tuning	 
Flipping output 
Fluctuation 
Forward stagewise algorithm 
Frequentist 
Full-rank matrix 
Functional neuron 
Gain ratio 
Game theory 
Gaussian kernel function 
Gaussian Mixture Model 
General Problem Solving	 
Generalization	 
Generalization error	 
Generalization error bound	 
Generalized Lagrange function	 
Generalized linear model	 
Generalized Rayleigh quotient	 
Generative Adversarial Networks/GAN	 
Generative Model	 
Generator	 
Genetic Algorithm/GA	 
Gibbs sampling	 
Gini index	 
Global minimum	 
Global Optimization	 
Gradient boosting	 
Gradient Descent	 
Graph theory	 
Ground-truth	 
Hard margin	 
Hard voting	 
Harmonic mean	 
Hesse matrix	 
Hidden dynamic model	 
Hidden layer	 
Hidden Markov Model/HMM	 
Hierarchical clustering	 
Hilbert space	 
Hinge loss function	 
Hold-out	 
Homogeneous	 
Hybrid computing	 
Hyperparameter 
Hypothesis	 
Hypothesis test	 
ICML	 
Improved iterative scaling/IIS	 
Incremental learning	 
Independent and identically distributed/i.i.d.	 
Independent Component Analysis/ICA	 
Indicator function	 
Individual learner	 
Induction	 
Inductive bias	 
Inductive learning	 
Inductive Logic Programming／ILP	 
Information entropy	 
Information gain	 
Input layer	 
Insensitive loss 
Inter-cluster similarity 
International Conference for Machine Learning/ICML 
Intra-cluster similarity	 
Intrinsic value	 
Isometric Mapping/Isomap	 
Isotonic regression 
Iterative Dichotomiser 
Kernel method 
Kernel trick 
Kernelized Linear Discriminant Analysis／KLDA 
K-fold cross validation 
K-Means Clustering 
K-Nearest Neighbours Algorithm/KNN 
Knowledge base 
Knowledge Representation 
Label space	 
Lagrange duality	 
Lagrange multiplier 
Laplace smoothing	 
Laplacian correction	 
Latent Dirichlet Allocation 
Latent semantic analysis	 
Latent variable 
Lazy learning	 
Learner	 
Learning by analogy	 
Learning rate	 
Learning Vector Quantization/LVQ	 
Least squares regression tree	 
Leave-One-Out/LOO	 
linear chain conditional random field	 
Linear Discriminant Analysis／LDA	 
Linear model	 
Linear Regression	 
Link function	 
Local Markov property	 
Local minimum	 
Log likelihood	 
Log odds／logit	 
Logistic Regression	Logistic  
Log-likelihood	 
Log-linear regression	 
Long-Short Term Memory/LSTM	 
Loss function	 
Machine translation/MT	 
Macron-P	 
Macron-R	 
Majority voting	 
Manifold assumption	 
Manifold learning	 
Margin theory	 
Marginal distribution	 
Marginal independence	 
Marginalization	 
Markov Chain Monte Carlo/MCMC	 
Markov Random Field 
Maximal clique	 
Maximum Likelihood Estimation/MLE	 
Maximum margin	 
Maximum weighted spanning tree 
Max-Pooling	 
Mean squared error	 
Meta-learner	 
Metric learning 
Micro-P	 
Micro-R 
Minimal Description Length/MDL 
Minimax game	 
Misclassification cost	 
Mixture of experts 
Momentum 
Moral graph	 
Multi-class classification 
Multi-document summarization	 
Multi-layer feedforward neural networks 
Multilayer Perceptron/MLP 
Multimodal learning 
Multiple Dimensional Scaling 
Multiple linear regression 
Multi-response Linear Regression ／MLR 
Mutual information 
Naive bayes 
Naive Bayes Classifier 
Named entity recognition 
Nash equilibrium 
Natural language generation/NLG 
Natural language processing 
Negative class 
Negative correlation 
Negative Log Likelihood 
Neighbourhood Component Analysis/NCA 
Neural Machine Translation 
Neural Turing Machine	 
Newton method	 
NIPS	 
No Free Lunch Theorem／NFL 
Noise-contrastive estimation	 
Nominal attribute	 
Non-convex optimization 
Nonlinear model	 
Non-metric distance	 
Non-negative matrix factorization	 
Non-ordinal attribute 
Non-Saturating Game	 
Norm	 
Normalization	 
Nuclear norm	 
Numerical attribute 
Objective function	 
Oblique decision tree	 
Occam’s razor	 
Odds	 
Off-Policy	 
One shot learning	 
One-Dependent Estimator／ODE 
On-Policy 
Ordinal attribute 
Out-of-bag estimate	 
Output layer 
Output smearing	 
Overfitting	 
Oversampling	 
Paired t-test	 
Pairwise	 
Pairwise Markov property	 
Parameter	 
Parameter estimation	 
Parameter tuning 
Parse tree 
Particle Swarm Optimization/PSO 
Part-of-speech tagging	 
Perceptron 
Performance measure 
Plug and Play Generative Network 
Plurality voting 
Polarity detection 
Polynomial kernel function 
Pooling 
Positive class 
Positive definite matrix 
Post-hoc test 
Post-pruning 
potential function 
Precision 
Prepruning 
Principal component analysis/PCA 
Principle of multiple explanations 
Prior 
Probability Graphical Model 
Proximal Gradient Descent/PGD 
Pruning 
Pseudo-label 
Quantized Neural Network 
Quantum computer 
Quantum Computing 
Quasi Newton method 
Radial Basis Function／RBF	 
Random Forest Algorithm	 
Random walk 
Recall	 
Receiver Operating Characteristic/ROC 
Rectified Linear Unit/ReLU	 
Recurrent Neural Network	 
Recursive neural network	 
Reference model 
Regression	 
Regularization	 
Reinforcement learning/RL	 
Representation learning	 
Representer theorem 
reproducing kernel Hilbert space/RKHS 
Re-sampling	 
Rescaling	 
Residual Mapping	 
Residual Network	
Restricted Boltzmann Machine/RBM 
Restricted Isometry Property/RIP	 
Re-weighting 
Robustness 
Root node	 
Rule Engine	 
Rule learning	 
Saddle point	 
Sample space	 
Sampling	 
Score function	 
Self-Driving	 
Self-Organizing Map／SOM	 
Semi-naive Bayes classifiers	 
Semi-Supervised Learning	 
semi-Supervised Support Vector Machine	 
Sentiment analysis	 
Separating hyperplane	 
Sigmoid function	 
Similarity measure	 
Simulated annealing	 
Simultaneous localization and mapping	 
Singular Value Decomposition	 
Slack variables	 
Smoothing	 
Soft margin	 
Soft margin maximization	 
Soft voting	 
Sparse representation	 
Sparsity 
Specialization 
Spectral Clustering 
Speech Recognition 
Splitting variable 
Squashing function	 
Stability-plasticity dilemma	 
Statistical learning	 
Status feature function	 
Stochastic gradient descent	 
Stratified sampling	 
Structural risk	 
Structural risk minimization/SRM 
Subspace 
Supervised learning 
support vector expansion 
Support Vector Machine/SVM 
Surrogat loss	 
Surrogate function	 
Symbolic learning 
Symbolism 
Synset 
T-Distribution Stochastic Neighbour Embedding/t-SNE	 
Tensor 
Tensor Processing Units/TPU	 
The least square method 
Threshold 
Threshold logic unit 
Threshold-moving 
Time Step 
Tokenization 
Training error 
Training instance 
Transductive learning 
Transfer learning 
Treebank 
Tria-by-error 
True negative 
True positive 
True Positive Rate/TPR 
Turing Machine 
Twice-learning 
Underfitting 
Undersampling 
Understandability 
Unequal cost 
Unit-step function	 
Univariate decision tree	 
Unsupervised learning	 
Unsupervised layer-wise training 
Upsampling 
Vanishing Gradient Problem 
Variational inference 
VC Theory 
Version space 
Viterbi algorithm	 
Von Neumann architecture	 
Wasserstein GAN/WGAN	 
Weak learner	 
Weight	 
Weight sharing 
Weighted voting	 
Within-class scatter matrix	 
Word embedding	 
Word sense disambiguation	 
Zero-data learning	 
Zero-shot learning