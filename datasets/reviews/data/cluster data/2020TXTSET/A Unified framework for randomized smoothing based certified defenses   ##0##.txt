Randomized smoothing, which was recently proved to be a certified defensive technique, has received considerable attention due to its scalability to large datasets and neural networks. However, several important questions still remain unanswered in the existing frameworks, such as (i) whether Gaussian mechanism is an optimal choice for certifying -normed robustness, and (ii) whether randomized smoothing can certify -normed robustness (on high-dimensional datasets like ImageNet). To answer these questions, we introduce a {em unified} and {em self-contained} framework to study randomized smoothing-based certified defenses, where we mainly focus on the two most popular norms in adversarial machine learning, {em i.e.,} and norm. We answer the above two questions by first demonstrating that Gaussian mechanism and Exponential mechanism are the (near) optimal options to certify the and -normed robustness. We further show that the largest radius certified by randomized smoothing is upper bounded by , where is the dimensionality of the data. This theoretical finding suggests that certifying -normed robustness by randomized smoothing may not be scalable to high-dimensional data. The veracity of our framework and analysis is verified by extensive evaluations on CIFAR10 and ImageNet. Certificated Defense, Randomized Smoothing, A Unified and Self-Contained Framework