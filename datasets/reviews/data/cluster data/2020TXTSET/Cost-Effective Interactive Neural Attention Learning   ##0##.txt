We propose a novel interactive attention learning framework which we refer to as Interactive Attention Learning (IAL), in which the human annotators interactively manipulate the allocated attentions to correct the modelâ€™s behavior, by updating the attention-generating model without having to retrain the network. For efficient update of the attention generator without retraining, we propose a novel attention mechanism Neural Attention Process (NAP), which can generate stochastic attentions based on scarce training instances, and can incorporate new training instances without retraining. Further, to minimize human interaction cost, we propose a cost-effective algorithm that selects the most negative training instances that yield incorrect and non-intuitive interpretation with influence function and re-rank the attentions on the input features by their uncertainties, such that the annotators label the instances and attentions that are more influential to the prediction first. We validate IAL on multiple datasets from the healthcare domain, on which it not only significantly outperforms other baselines, but also achieves explicitly trained attention for interpretability that agrees well with human interpretation without expensive human labeling procedure. interactive learning, neural process, attention mechanism, interpretable machine learning, influence functions, uncertainty.