In this paper, we ask for the main factors that determine a classifier s decision making and uncover such factors by studying latent codes produced by auto-encoding frameworks. To deliver an explanation of a classifier s behaviour, we propose a method that provides series of examples highlighting semantic differences between the classifier s decisions. We generate these examples through interpolations in latent space. We introduce and formalize the notion of a semantic stochastic path, as a suitable stochastic process defined in feature space via latent code interpolations. We then introduce the concept of semantic Lagrangians as a way to incorporate the desired classifier s behaviour and find that the solution of the associated variational problem allows for highlighting differences in the classifier decision. Very importantly, within our framework the classifier is used as a black-box, and only its evaluation is required. Variational Auto Encoders, Interpolations, Explanations, Stochastic Processes