We present a novel black-box adversarial attack algorithm with state-of-the-art model evasion rates for query efficiency under and metrics. It exploits a 	extit{sign-based}, rather than magnitude-based, gradient estimation approach that shifts the gradient estimation from continuous to binary black-box optimization. It adaptively constructs queries to estimate the gradient, one query relying upon the previous, rather than re-estimating the gradient each step with random query construction. Its reliance on sign bits yields a smaller memory footprint and it requires neither hyperparameter tuning or dimensionality reduction. Further, its theoretical performance is guaranteed and it can characterize adversarial subspaces better than white-box gradient-aligned subspaces. On two public black-box attack challenges and a model robustly trained against transfer attacks, the algorithm s evasion rates surpass all submitted attacks. For a suite of published models, the algorithm is less failure-prone while spending fewer queries versus the best combination of state of art algorithms. For example, it evades a standard MNIST model using just queries on average. Similar performance is observed on a standard IMAGENET model with an average of queries. Black-box adversarial attack models, Deep Nets, Adversarial Examples, Black-Box Optimization, Zeroth-Order Optimization